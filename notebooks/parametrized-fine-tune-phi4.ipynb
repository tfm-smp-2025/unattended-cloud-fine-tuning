{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a3406b7d",
      "metadata": {
        "id": "a3406b7d"
      },
      "source": [
        "# Model evaluation notebook"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Jupyter version\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# GColab version\n",
        "MODEL = 'phi4:14b' # @param [\"gemma2:2b\", \"gemma2:9b\", \"gemma3:12b\", \"mistral:7b\", \"mixtral:8x7b\", \"phi:2.7b\", \"phi4:14b\", \"deepseek-r1:7b\"] {allow-input: true}\n",
        "MODEL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dPqIJib05A9c",
        "outputId": "095409fe-a1f2-4645-a1f3-76ec90ffe6a7"
      },
      "id": "dPqIJib05A9c",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'phi4:14b'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LORA_RANK = 16 # @param {type:\"slider\", min:8, max:128, step:8}\n",
        "LORA_ALPHA = 16 # @param {type:\"slider\", min:8, max:128, step:8}\n",
        "LORA_RANK_STABILIZED = False # @param {type:\"boolean\"}\n",
        "LORA_DROPOUT = 0 # @param {type:\"slider\", min:0, max:0.5, step:0.05}\n",
        "LORA_BIAS = \"none\" # @param [\"none\", \"all\", \"lora_only\"]\n",
        "LEARNING_RATE = 1e-4 # @param {type:\"number\"}\n",
        "LOAD_IN_4_BIT = False # @param {type:\"boolean\"}\n",
        "MAX_EPOCHS = 2 # @param {\"type\":\"slider\",\"min\":1,\"max\":50,\"step\":1}\n",
        "\n",
        "import datetime\n",
        "RUN_CODE = (f\"r{LORA_RANK}_a{LORA_ALPHA}_s{int(LORA_RANK_STABILIZED)}\"\n",
        "            + f\"_d{LORA_DROPOUT}_b{LORA_BIAS}_l{LEARNING_RATE}_4b{LOAD_IN_4_BIT}\"\n",
        "            + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        ")\n",
        "RUN_CODE"
      ],
      "metadata": {
        "id": "531SRYOKVqsz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4e421807-3490-4961-e765-06d4b3feef96"
      },
      "id": "531SRYOKVqsz",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start time\n",
        "!date"
      ],
      "metadata": {
        "id": "1sQhHMM3hH56",
        "outputId": "a0e66426-4173-4dde-a413-efadaef1637d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1sQhHMM3hH56",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri May 16 04:01:22 PM UTC 2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "_xDYWzO-Yayb"
      },
      "id": "_xDYWzO-Yayb"
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "def get_secret(prompt, secret_name, secret_input=True):\n",
        "  try:\n",
        "    from google.colab import userdata\n",
        "    result = userdata.get(secret_name)\n",
        "    assert result is not None\n",
        "  except:\n",
        "    if secret_input:\n",
        "      result = getpass(prompt)\n",
        "    else:\n",
        "      result = input(prompt)\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "oZ3dny5NzRvz"
      },
      "id": "oZ3dny5NzRvz",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install required libraries"
      ],
      "metadata": {
        "id": "nlO-cFvcrGbi"
      },
      "id": "nlO-cFvcrGbi"
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth\n",
        "    !pip install -U transformers"
      ],
      "metadata": {
        "id": "JqVfnROiLBuM"
      },
      "id": "JqVfnROiLBuM",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load unsloth ASAP for better optimizations\n",
        "from unsloth import FastLanguageModel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iei_MdVaLD3",
        "outputId": "bd1e06d6-4d3e-457d-df79-3fdcb8a6ef8a"
      },
      "id": "9iei_MdVaLD3",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qU\n",
        "!uv pip install -q bitsandbytes transformers peft accelerate scipy einops evaluate trl rouge_score numpy\n",
        "!uv pip install -qU datasets"
      ],
      "metadata": {
        "id": "IU9NpO2KrF7R"
      },
      "id": "IU9NpO2KrF7R",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Log in to your W&B account\n",
        "import wandb\n",
        "import random\n",
        "import math\n",
        "import os"
      ],
      "metadata": {
        "id": "LqZV62kKrcP-"
      },
      "id": "LqZV62kKrcP-",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login(key=get_secret('W&B key: ', 'TFM_WAND_TOKEN'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_SvJujbrd_8",
        "outputId": "f3988269-cb2e-45b4-8ccf-7ce4f6dbd1f8"
      },
      "id": "b_SvJujbrd_8",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msergiomportela\u001b[0m (\u001b[33msergiomportela-universitat-oberta-de-catalunya\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"WANDB_PROJECT\"] = \"fine-tune-tfm-2025-tests\"  # name your W&B project\n",
        "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"  # log all model checkpoints"
      ],
      "metadata": {
        "id": "2_Ug2dz4rhJc"
      },
      "id": "2_Ug2dz4rhJc",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    GenerationConfig\n",
        ")\n",
        "from tqdm import tqdm\n",
        "from trl import SFTTrainer\n",
        "import torch\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from huggingface_hub import interpreter_login\n",
        "from huggingface_hub import login as hf_login\n",
        "\n",
        "hf_login(token=get_secret('Hugging Face token: ', 'TFM_HUGGINGFACE_TOKEN'))"
      ],
      "metadata": {
        "id": "zHIwyuEqrln4"
      },
      "id": "zHIwyuEqrln4",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "22002ef2-6649-45fd-8352-52104f456f98",
      "metadata": {
        "id": "22002ef2-6649-45fd-8352-52104f456f98"
      },
      "source": [
        "### Prepare code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "544f2f5c-c999-43fb-b8a1-21294ebb08fb",
      "metadata": {
        "id": "544f2f5c-c999-43fb-b8a1-21294ebb08fb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('src'):\n",
        "  import urllib\n",
        "\n",
        "  user = get_secret('User name: ', 'TFM_GH_USER')\n",
        "  password = get_secret('Password: ', 'TFM_GH_TOKEN')\n",
        "  password = urllib.parse.quote(password) # your password is converted into url format\n",
        "  repopath = \"tfm-smp-2025/fine-tuning\"\n",
        "\n",
        "  !git clone https://\"$user\":\"$password\"@github.com/\"$repopath\" src\n",
        "\n",
        "  del password"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update code, if needed\n",
        "!cd src && git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccqEW_Hl7K79",
        "outputId": "236cf08c-8797-4bf9-aa90-d645b0ee3d5b"
      },
      "id": "ccqEW_Hl7K79",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Credentials"
      ],
      "metadata": {
        "id": "GByJJ-qSbYmx"
      },
      "id": "GByJJ-qSbYmx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Result pusher setup"
      ],
      "metadata": {
        "id": "plEBsG9meCvj"
      },
      "id": "plEBsG9meCvj"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if (\n",
        "    (not os.path.exists(os.path.expanduser(\"~/.ssh/id_rsa\")))\n",
        "    or (not os.path.exists(os.path.expanduser(\"~/.ssh/known_hosts\")))\n",
        "):\n",
        "  SSHKEY = get_secret('Result pusher SSH key: ', 'TFM_SSH_PUSHER_KEY')\n",
        "\n",
        "  !mkdir ~/.ssh\n",
        "\n",
        "  # Read locally with `cat ~/.ssh/result-pusher|tr '\\n' '$';echo`\n",
        "  with open(os.path.expanduser(\"~/.ssh/id_rsa\"), 'wt') as f:\n",
        "    f.write(SSHKEY.replace('$', '\\n'))\n",
        "\n",
        "  !chmod 0600 ~/.ssh/id_rsa\n",
        "  !ssh-keygen -y -f ~/.ssh/id_rsa > ~/.ssh/id_rsa.pub\n",
        "  !chmod 0600 ~/.ssh/id_rsa.pub\n",
        "\n",
        "  # This won't copy the client key (not needed), but it will initialize the server's on the client\n",
        "  !ssh-copy-id -i ~/.ssh/id_rsa -o StrictHostKeyChecking=accept-new result-pusher@kb.tfm.codigoparallevar.com\n",
        "\n",
        "  del SSHKEY"
      ],
      "metadata": {
        "id": "rkFM-Yd5eFhd"
      },
      "id": "rkFM-Yd5eFhd",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pull datasets"
      ],
      "metadata": {
        "id": "sZS0n93jC6B2"
      },
      "id": "sZS0n93jC6B2"
    },
    {
      "cell_type": "code",
      "source": [
        "# !python3 src/scripts/pull_datasets.py"
      ],
      "metadata": {
        "id": "pqqvRJAIC4dl"
      },
      "id": "pqqvRJAIC4dl",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "978e116d-b24b-4752-9ded-145d88e46209",
      "metadata": {
        "id": "978e116d-b24b-4752-9ded-145d88e46209"
      },
      "source": [
        "## Run fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compute_dtype = getattr(torch, \"float16\")\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type='nf4',\n",
        "        bnb_4bit_compute_dtype=compute_dtype,\n",
        "        bnb_4bit_use_double_quant=False,\n",
        "    )"
      ],
      "metadata": {
        "id": "6muhkiHDYvWC"
      },
      "id": "6muhkiHDYvWC",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name='microsoft/phi-4'\n",
        "model_name = 'unsloth/Phi-4'  # Unsloth's version\n",
        "model_name = \"unsloth/Phi-4-unsloth-bnb-4bit\"  # Phi-4 Unsloth Dynamic 4-bit Quant\n",
        "device_map = {\"\": 0}\n",
        "\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Phi-4\",\n",
        "    max_seq_length = 16384, # max_seq_length,\n",
        "    load_in_4bit = LOAD_IN_4_BIT, # load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ],
      "metadata": {
        "id": "RaA5vvvDBD21",
        "outputId": "af614e98-a6a7-4bc5-a5f6-337c0060e15b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201,
          "referenced_widgets": [
            "f2ae0fc01f144e5abb61ee4f07da543c",
            "0d7cecb4c23b4938beca8ca49b916857",
            "8572b231e9d740169f41b3cc5ecfbbb5",
            "cbec1310a9d74e81b4f27d0a65a89579",
            "f18650ee034f412e96e1614787230e6c",
            "a8ee243a77cb42439e6f7211ab16a715",
            "63684edfd26246bfa692b49052f8c3a2",
            "5942188f8db24f6a88841efe36279726",
            "044af4bec7dc4d598639f015ad5b48d6",
            "acf0da2f3ad34aa5b2acff691eebc6df",
            "732aab9b26d04312b52d76b3cee8b47e"
          ]
        }
      },
      "id": "RaA5vvvDBD21",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.5.4: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2ae0fc01f144e5abb61ee4f07da543c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name,trust_remote_code=True,padding_side=\"left\") # ,add_eos_token=True,add_bos_token=True,use_fast=False)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "B9sa9ZsxsPqy"
      },
      "id": "B9sa9ZsxsPqy",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def load_jsonl(path):\n",
        "  with open(path) as f:\n",
        "    return [\n",
        "      json.loads(line)\n",
        "      for line in f\n",
        "    ]\n",
        "\n",
        "def regen_jsonl(path):\n",
        "  with open(path) as f:\n",
        "    data = [\n",
        "      json.loads(line)\n",
        "      for line in f\n",
        "    ]\n",
        "  with open(path, 'w') as f:\n",
        "    for line in data:\n",
        "      if isinstance(line, list):\n",
        "        f.write(json.dumps({\"messages\": line}) + '\\n')\n",
        "      else:\n",
        "        f.write(json.dumps(line) + '\\n')\n",
        "\n",
        "regen_jsonl(\"fine-tuning-test.jsonl\")\n",
        "regen_jsonl(\"fine-tuning-data.jsonl\")"
      ],
      "metadata": {
        "id": "GTc4b59ZRdAk"
      },
      "id": "GTc4b59ZRdAk",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import datasets\n",
        "\n",
        "dataset = datasets.load_dataset(\"json\", data_files={\n",
        "    \"test\": \"fine-tuning-test.jsonl\",\n",
        "    \"train\": \"fine-tuning-data.jsonl\",\n",
        "}, )\n",
        "dataset # ['test'][0]"
      ],
      "metadata": {
        "id": "JL9YVVvPsPoL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255,
          "referenced_widgets": [
            "cf41a0b9066a4bd8a0e4ab1e47f4e94c",
            "f479cb3fd0e74156b0918d8562a47731",
            "a4f2051325db4bfdbf5fda2ad96a67b6",
            "35d580a4df68436b9df9a769013013b0",
            "757ead5323f74a19913dbbe9668f58b5",
            "0eaaf95da5934438aa5c280f9e63107f",
            "e4d21809fb164bc1ad46bc3eee3065d8",
            "47070c2def2f48c9aa3b2308ccc42849",
            "ae3af0b4c5ff42c1b3a975d6147f2a4b",
            "ed96aeb46651497f9fe075d29d2daaa7",
            "1e42f91116b248a4b8c026b234626c80",
            "831e25ad067e4e0190747ab8d5313424",
            "1e3bb4e9ef0e44c5ba2de9376d41301f",
            "67797f951f0d4b4eab16d5699b000386",
            "8152c3d5f3244db287153bff581a8622",
            "cc45141440ca46adabe3a6916cd14de0",
            "b91a038fde144336bb7ce9f099286d95",
            "6f93859797074e8985d01c2cc9367a47",
            "8ab38593c5474022a0c0d866393f6dcd",
            "ce1aba6870f2421d8dae830e899abbf6",
            "094f46266bb846e192a5dc3c1ff9fe4d",
            "b9345cf940484a9bb400fa811eba39ce"
          ]
        },
        "outputId": "0528f343-d91b-4943-b119-9ddabf7acb6d"
      },
      "id": "JL9YVVvPsPoL",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf41a0b9066a4bd8a0e4ab1e47f4e94c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f479cb3fd0e74156b0918d8562a47731"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    test: Dataset({\n",
              "        features: ['messages'],\n",
              "        num_rows: 10\n",
              "    })\n",
              "    train: Dataset({\n",
              "        features: ['messages'],\n",
              "        num_rows: 2200\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n1 fine-tuning-*.jsonl"
      ],
      "metadata": {
        "id": "idGPLdbaGfYF",
        "outputId": "a6221ed3-dab3-45e9-a4c0-891f7ecb0f98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "idGPLdbaGfYF",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> fine-tuning-data.jsonl <==\n",
            "{\"messages\": [{\"actor\": \"user\", \"text\": \"Extract the nouns from this natural language query.\\n\\n> List the team for which Doug Acomb played ?\\n\\nLet's reason step by step. Identify the nouns on the query, skip the ones that can be solved by a SPARQL verb (ignore, for example, \\\"count\\\" or \\\"number of\\\"), and output a json list like this.\\n\\n```json\\n[\\n    \\\"entity1\\\",\\n    \\\"entity2\\\",\\n    ...\\n    \\\"entityN\\\"\\n]\\n```\"}, {\"actor\": \"assistant\", \"text\": \"```json\\n[\\n    \\\"List\\\",\\n    \\\"team\\\",\\n    \\\"Doug Acomb\\\",\\n    \\\"played\\\"\\n]\\n```\"}, {\"actor\": \"user\", \"text\": \"\\nThis are some examples on how the available properties can be used:\\n\\n### Subject: <http://dbpedia.org/resource/Doug_Acomb> ; Predicate: <http://dbpedia.org/ontology/formerTeam>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Doug_Acomb> <http://dbpedia.org/ontology/formerTeam> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Doug_Acomb> ; Predicate: <http://dbpedia.org/property/playedFor>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Doug_Acomb> <http://dbpedia.org/property/playedFor> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Doug_McCombs> ; Predicate: <http://dbpedia.org/property/notableInstruments>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Doug_McCombs> <http://dbpedia.org/property/notableInstruments> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Doug_Cosbie> ; Predicate: <http://dbpedia.org/ontology/debutTeam>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Doug_Cosbie> <http://dbpedia.org/ontology/debutTeam> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Doug_Cosbie> ; Predicate: <http://dbpedia.org/property/debutteam>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Doug_Cosbie> <http://dbpedia.org/property/debutteam> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Doug_Cosbie> ; Predicate: <http://dbpedia.org/ontology/formerTeam>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Doug_Cosbie> <http://dbpedia.org/ontology/formerTeam> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Doug_Asad> ; Predicate: <http://dbpedia.org/ontology/debutTeam>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Doug_Asad> <http://dbpedia.org/ontology/debutTeam> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Doug_Asad> ; Predicate: <http://dbpedia.org/property/debutteam>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Doug_Asad> <http://dbpedia.org/property/debutteam> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Doug_Asad> ; Predicate: <http://dbpedia.org/ontology/formerTeam>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Doug_Asad> <http://dbpedia.org/ontology/formerTeam> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Doug_Wycoff> ; Predicate: <http://dbpedia.org/ontology/formerTeam>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Doug_Wycoff> <http://dbpedia.org/ontology/formerTeam> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Douglas_Cobo> ; Predicate: <http://dbpedia.org/ontology/team>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Douglas_Cobo> <http://dbpedia.org/ontology/team> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Doug_Wimbish> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Doug_Wimbish> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Doug_Wimbish> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Doug_Wimbish> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Doug_Rougvie__8> ; Predicate: <http://dbpedia.org/ontology/team>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Doug_Rougvie__8> <http://dbpedia.org/ontology/team> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Doug_Colman> ; Predicate: <http://dbpedia.org/ontology/debutTeam>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Doug_Colman> <http://dbpedia.org/ontology/debutTeam> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Doug_Colman> ; Predicate: <http://dbpedia.org/property/debutteam>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Doug_Colman> <http://dbpedia.org/property/debutteam> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Doug_Colman> ; Predicate: <http://dbpedia.org/ontology/formerTeam>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Doug_Colman> <http://dbpedia.org/ontology/formerTeam> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Don_McComb> ; Predicate: <http://dbpedia.org/ontology/formerTeam>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Don_McComb> <http://dbpedia.org/ontology/formerTeam> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Douglas_Cobo__8> ; Predicate: <http://dbpedia.org/ontology/team>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Douglas_Cobo__8> <http://dbpedia.org/ontology/team> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Doug_Anthony> ; Predicate: <http://dbpedia.org/property/constituencyMp>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Doug_Anthony> <http://dbpedia.org/property/constituencyMp> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/David_McComb> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/David_McComb> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/David_McComb> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/David_McComb> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Doug_Rougvie> ; Predicate: <http://dbpedia.org/property/nationalteam>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Doug_Rougvie> <http://dbpedia.org/property/nationalteam> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Doug_Rougvie> ; Predicate: <http://dbpedia.org/ontology/team>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Doug_Rougvie> <http://dbpedia.org/ontology/team> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/You_Been_Played> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/You_Been_Played> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/You_Been_Played> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/You_Been_Played> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Enjoy_(play)> ; Predicate: <http://dbpedia.org/ontology/characterInPlay>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Enjoy_(play)> <http://dbpedia.org/ontology/characterInPlay> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Enjoy_(play)> ; Predicate: <http://dbpedia.org/ontology/settingOfPlay>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Enjoy_(play)> <http://dbpedia.org/ontology/settingOfPlay> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/1_+_1_Play_n_Fun> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/1_+_1_Play_n_Fun> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/1_+_1_Play_n_Fun> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/1_+_1_Play_n_Fun> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Game_(play)> ; Predicate: <http://dbpedia.org/ontology/settingOfPlay>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Game_(play)> <http://dbpedia.org/ontology/settingOfPlay> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Game_(play)> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Game_(play)> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Game_(play)> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Game_(play)> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/This_Lil'_Game_We_Play> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/This_Lil'_Game_We_Play> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/This_Lil'_Game_We_Play> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/This_Lil'_Game_We_Play> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/2Play> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/2Play> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/2Play> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/2Play> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Playaz_of_da_Game> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Playaz_of_da_Game> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Playaz_of_da_Game> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Playaz_of_da_Game> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Playaz_N_the_Game> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Playaz_N_the_Game> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Playaz_N_the_Game> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Playaz_N_the_Game> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Playing_Me> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Playing_Me> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Playing_Me> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Playing_Me> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Played_on_Pepper> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Played_on_Pepper> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Played_on_Pepper> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Played_on_Pepper> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Played_on_Pepper> ; Predicate: <http://dbpedia.org/property/recorded>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Played_on_Pepper> <http://dbpedia.org/property/recorded> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Games_People_Play_(The_Spinners_song)> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Games_People_Play_(The_Spinners_song)> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Games_People_Play_(The_Spinners_song)> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Games_People_Play_(The_Spinners_song)> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Hey_Ash,_Whatcha_Playin'%3F> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Hey_Ash,_Whatcha_Playin'%3F> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Hey_Ash,_Whatcha_Playin'%3F> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Hey_Ash,_Whatcha_Playin'%3F> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/We_Came_to_Play> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/We_Came_to_Play> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/We_Came_to_Play> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/We_Came_to_Play> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/It's_Only_a_Play> ; Predicate: <http://dbpedia.org/ontology/characterInPlay>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/It's_Only_a_Play> <http://dbpedia.org/ontology/characterInPlay> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/It's_Only_a_Play> ; Predicate: <http://dbpedia.org/ontology/settingOfPlay>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/It's_Only_a_Play> <http://dbpedia.org/ontology/settingOfPlay> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/It's_Only_a_Play> ; Predicate: <http://dbpedia.org/ontology/subjectOfPlay>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/It's_Only_a_Play> <http://dbpedia.org/ontology/subjectOfPlay> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/You_Played_Yourself> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/You_Played_Yourself> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/You_Played_Yourself> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/You_Played_Yourself> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Team_Rezofficial> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Team_Rezofficial> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Team_Rezofficial> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Team_Rezofficial> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Team_Me> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Team_Me> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Team_Me> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Team_Me> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/S.C.A.T.:_Special_Cybernetic_Attack_Team> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/S.C.A.T.:_Special_Cybernetic_Attack_Team> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/S.C.A.T.:_Special_Cybernetic_Attack_Team> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/S.C.A.T.:_Special_Cybernetic_Attack_Team> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/TeamAWESOME!> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/TeamAWESOME!> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/TeamAWESOME!> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/TeamAWESOME!> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Team_Rytger> ; Predicate: <http://dbpedia.org/property/teamname>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Team_Rytger> <http://dbpedia.org/property/teamname> ?object }\\n```\\n\\n### Object: <http://dbpedia.org/resource/Team_Rytger> ; Predicate: <http://dbpedia.org/ontology/team>\\n\\n```sparql\\nSELECT DISTINCT ?subject WHERE { ?subject <http://dbpedia.org/ontology/team> <http://dbpedia.org/resource/Team_Rytger> }\\n```\\n\\n### Object: <http://dbpedia.org/resource/Team_Rytger> ; Predicate: <http://dbpedia.org/property/currentteam>\\n\\n```sparql\\nSELECT DISTINCT ?subject WHERE { ?subject <http://dbpedia.org/property/currentteam> <http://dbpedia.org/resource/Team_Rytger> }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Team9> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Team9> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Team9> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Team9> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_A_List_(album)> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_A_List_(album)> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_A_List_(album)> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_A_List_(album)> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Lista> ; Predicate: <http://dbpedia.org/property/areaTotalKm>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Lista> <http://dbpedia.org/property/areaTotalKm> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Michael_Lista> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Michael_Lista> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Michael_Lista> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Michael_Lista> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/1985\\u20131990:_The_A_List> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/1985\\u20131990:_The_A_List> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/1985\\u20131990:_The_A_List> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/1985\\u20131990:_The_A_List> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_List_(album)> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_List_(album)> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_List_(album)> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_List_(album)> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Robert_List> ; Predicate: <http://dbpedia.org/property/order>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Robert_List> <http://dbpedia.org/property/order> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Robert_List> ; Predicate: <http://dbpedia.org/ontology/orderInOffice>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Robert_List> <http://dbpedia.org/ontology/orderInOffice> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Lista_ficki> ; Predicate: <http://dbpedia.org/ontology/order>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Lista_ficki> <http://dbpedia.org/ontology/order> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Lista_ficki> ; Predicate: <http://dbpedia.org/property/classis>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Lista_ficki> <http://dbpedia.org/property/classis> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Listary> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Listary> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Listary> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Listary> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Listaller> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Listaller> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Listaller> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Listaller> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Honesty_(Write_Me_a_List)> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Honesty_(Write_Me_a_List)> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Honesty_(Write_Me_a_List)> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Honesty_(Write_Me_a_List)> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\nOf the ones given, which predicates will be useful to solve it?\\n\\nConsider it's better to query directly on IRIs and avoid filtering whenever possible. DO NOT generate any query yet.\\n\"}, {\"actor\": \"assistant\", \"text\": \"These are the predicates useful to solve this query:\\n- From subject <http://dbpedia.org/resource/Doug_Acomb>, through predicate <http://dbpedia.org/property/playedFor>\\n\"}, {\"actor\": \"user\", \"text\": \"What are the subject IRIs that will be handy to solve this query? STILL DO NOT generate any query yet.\"}, {\"actor\": \"assistant\", \"text\": \"These are the IRIs useful to solve this query:\\n- http://dbpedia.org/resource/Doug_Acomb\\n- http://dbpedia.org/property/playedFor\\n\"}, {\"actor\": \"user\", \"text\": \"\\nConstruct a SPARQL query to solve it on a single query, keep it simple and avoid unnecessary conditions. If it's an item list just do a SELECT, but if it's numeric you might need to use a verb like COUNT(), and if it's boolean you might need to use ASK.\\n\\nRemember to avoid querying by label, use the IRIs and relations presented before, not others. DO NOT even use common types like `name` or `type` unless they were explicitly allowed.\\n\\nQuery to solve:\\n> List the team for which Doug Acomb played ?\"}, {\"actor\": \"assistant\", \"text\": \"```sparql\\n SELECT DISTINCT ?uri WHERE { <http://dbpedia.org/resource/Doug_Acomb> <http://dbpedia.org/property/playedFor> ?uri } \\n```\"}]}\n",
            "\n",
            "==> fine-tuning-test.jsonl <==\n",
            "{\"messages\": [{\"actor\": \"user\", \"text\": \"Extract the nouns from this natural language query.\\n\\n> Whose network's parent organisation is Comcast?\\n\\nLet's reason step by step. Identify the nouns on the query, skip the ones that can be solved by a SPARQL verb (ignore, for example, \\\"count\\\" or \\\"number of\\\"), and output a json list like this.\\n\\n```json\\n[\\n    \\\"entity1\\\",\\n    \\\"entity2\\\",\\n    ...\\n    \\\"entityN\\\"\\n]\\n```\"}, {\"actor\": \"assistant\", \"text\": \"```json\\n[\\n    \\\"network\\\",\\n    \\\"parent organisation\\\",\\n    \\\"Comcast\\\"\\n]\\n```\"}, {\"actor\": \"user\", \"text\": \"\\nThis are some examples on how the available properties can be used:\\n\\n### Subject: <http://dbpedia.org/resource/Network_Ten> ; Predicate: <http://dbpedia.org/ontology/broadcastNetwork>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Network_Ten> <http://dbpedia.org/ontology/broadcastNetwork> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Network_Ten> ; Predicate: <http://dbpedia.org/property/broadcastArea>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Network_Ten> <http://dbpedia.org/property/broadcastArea> ?object }\\n```\\n\\n### Object: <http://dbpedia.org/resource/Network_Ten> ; Predicate: <http://dbpedia.org/ontology/broadcastNetwork>\\n\\n```sparql\\nSELECT DISTINCT ?subject WHERE { ?subject <http://dbpedia.org/ontology/broadcastNetwork> <http://dbpedia.org/resource/Network_Ten> }\\n```\\n\\n### Object: <http://dbpedia.org/resource/Network_Ten> ; Predicate: <http://dbpedia.org/ontology/network>\\n\\n```sparql\\nSELECT DISTINCT ?subject WHERE { ?subject <http://dbpedia.org/ontology/network> <http://dbpedia.org/resource/Network_Ten> }\\n```\\n\\n### Object: <http://dbpedia.org/resource/Network_Ten> ; Predicate: <http://dbpedia.org/property/network>\\n\\n```sparql\\nSELECT DISTINCT ?subject WHERE { ?subject <http://dbpedia.org/property/network> <http://dbpedia.org/resource/Network_Ten> }\\n```\\n\\n### Object: <http://dbpedia.org/resource/Network_Ten> ; Predicate: <http://dbpedia.org/ontology/formerBroadcastNetwork>\\n\\n```sparql\\nSELECT DISTINCT ?subject WHERE { ?subject <http://dbpedia.org/ontology/formerBroadcastNetwork> <http://dbpedia.org/resource/Network_Ten> }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Unison_Networks> ; Predicate: <http://dbpedia.org/ontology/netIncome>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Unison_Networks> <http://dbpedia.org/ontology/netIncome> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Comcast> ; Predicate: <http://dbpedia.org/ontology/netIncome>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Comcast> <http://dbpedia.org/ontology/netIncome> ?object }\\n```\\n\\n### Object: <http://dbpedia.org/resource/Comcast> ; Predicate: <http://dbpedia.org/property/parent>\\n\\n```sparql\\nSELECT DISTINCT ?subject WHERE { ?subject <http://dbpedia.org/property/parent> <http://dbpedia.org/resource/Comcast> }\\n```\\n\\n### Object: <http://dbpedia.org/resource/Comcast> ; Predicate: <http://dbpedia.org/ontology/broadcastNetwork>\\n\\n```sparql\\nSELECT DISTINCT ?subject WHERE { ?subject <http://dbpedia.org/ontology/broadcastNetwork> <http://dbpedia.org/resource/Comcast> }\\n```\\n\\n### Object: <http://dbpedia.org/resource/Comcast> ; Predicate: <http://dbpedia.org/property/network>\\n\\n```sparql\\nSELECT DISTINCT ?subject WHERE { ?subject <http://dbpedia.org/property/network> <http://dbpedia.org/resource/Comcast> }\\n```\\n\\n### Object: <http://dbpedia.org/resource/Comcast> ; Predicate: <http://dbpedia.org/ontology/parentOrganisation>\\n\\n```sparql\\nSELECT DISTINCT ?subject WHERE { ?subject <http://dbpedia.org/ontology/parentOrganisation> <http://dbpedia.org/resource/Comcast> }\\n```\\n\\n### Object: <http://dbpedia.org/resource/Comcast> ; Predicate: <http://dbpedia.org/ontology/network>\\n\\n```sparql\\nSELECT DISTINCT ?subject WHERE { ?subject <http://dbpedia.org/ontology/network> <http://dbpedia.org/resource/Comcast> }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Comcast_Business> ; Predicate: <http://dbpedia.org/property/parent>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Comcast_Business> <http://dbpedia.org/property/parent> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Comcast_Television> ; Predicate: <http://dbpedia.org/ontology/broadcastArea>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Comcast_Television> <http://dbpedia.org/ontology/broadcastArea> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Comcast_Television> ; Predicate: <http://dbpedia.org/property/broadcastArea>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Comcast_Television> <http://dbpedia.org/property/broadcastArea> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_Comcast_Network> ; Predicate: <http://dbpedia.org/ontology/broadcastArea>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_Comcast_Network> <http://dbpedia.org/ontology/broadcastArea> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_Comcast_Network> ; Predicate: <http://dbpedia.org/property/broadcastArea>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_Comcast_Network> <http://dbpedia.org/property/broadcastArea> ?object }\\n```\\n\\n### Object: <http://dbpedia.org/resource/The_Comcast_Network> ; Predicate: <http://dbpedia.org/ontology/broadcastNetwork>\\n\\n```sparql\\nSELECT DISTINCT ?subject WHERE { ?subject <http://dbpedia.org/ontology/broadcastNetwork> <http://dbpedia.org/resource/The_Comcast_Network> }\\n```\\n\\n### Object: <http://dbpedia.org/resource/The_Comcast_Network> ; Predicate: <http://dbpedia.org/ontology/network>\\n\\n```sparql\\nSELECT DISTINCT ?subject WHERE { ?subject <http://dbpedia.org/ontology/network> <http://dbpedia.org/resource/The_Comcast_Network> }\\n```\\n\\n### Object: <http://dbpedia.org/resource/The_Comcast_Network> ; Predicate: <http://dbpedia.org/property/network>\\n\\n```sparql\\nSELECT DISTINCT ?subject WHERE { ?subject <http://dbpedia.org/property/network> <http://dbpedia.org/resource/The_Comcast_Network> }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Comcast_Interactive_Media> ; Predicate: <http://dbpedia.org/property/parent>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Comcast_Interactive_Media> <http://dbpedia.org/property/parent> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Comcast_Cable> ; Predicate: <http://dbpedia.org/property/parent>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Comcast_Cable> <http://dbpedia.org/property/parent> ?object }\\n```\\n\\n### Object: <http://dbpedia.org/resource/Comcast_Cable> ; Predicate: <http://dbpedia.org/property/parent>\\n\\n```sparql\\nSELECT DISTINCT ?subject WHERE { ?subject <http://dbpedia.org/property/parent> <http://dbpedia.org/resource/Comcast_Cable> }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Comcast_Spotlight> ; Predicate: <http://dbpedia.org/property/parent>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Comcast_Spotlight> <http://dbpedia.org/property/parent> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Comcast_C2_Charleston> ; Predicate: <http://dbpedia.org/ontology/broadcastNetwork>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Comcast_C2_Charleston> <http://dbpedia.org/ontology/broadcastNetwork> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Parent-Craft> ; Predicate: <http://dbpedia.org/ontology/network>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Parent-Craft> <http://dbpedia.org/ontology/network> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_Parent_Game> ; Predicate: <http://dbpedia.org/ontology/network>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_Parent_Game> <http://dbpedia.org/ontology/network> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_Parent_Game> ; Predicate: <http://dbpedia.org/property/network>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_Parent_Game> <http://dbpedia.org/property/network> ?object }\\n```\\n\\nOf the ones given, which predicates will be useful to solve it?\\n\\nConsider it's better to query directly on IRIs and avoid filtering whenever possible. DO NOT generate any query yet.\\n\"}, {\"actor\": \"assistant\", \"text\": \"These are the predicates useful to solve this query:\\n- Through predicate <http://dbpedia.org/ontology/parentOrganisation> to object <http://dbpedia.org/resource/Comcast>\\n- Through predicate <http://dbpedia.org/ontology/network> to object <http://dbpedia.org/resource/Comcast>\\n\"}, {\"actor\": \"user\", \"text\": \"What are the subject IRIs that will be handy to solve this query? STILL DO NOT generate any query yet.\"}, {\"actor\": \"assistant\", \"text\": \"These are the IRIs useful to solve this query:\\n- http://dbpedia.org/ontology/parentOrganisation\\n- http://dbpedia.org/resource/Comcast\\n- http://dbpedia.org/ontology/network\\n\"}, {\"actor\": \"user\", \"text\": \"\\nConstruct a SPARQL query to solve it on a single query, keep it simple and avoid unnecessary conditions. If it's an item list just do a SELECT, but if it's numeric you might need to use a verb like COUNT(), and if it's boolean you might need to use ASK.\\n\\nRemember to avoid querying by label, use the IRIs and relations presented before, not others. DO NOT even use common types like `name` or `type` unless they were explicitly allowed.\\n\\nQuery to solve:\\n> Whose network's parent organisation is Comcast?\"}, {\"actor\": \"assistant\", \"text\": \"```sparql\\nSELECT DISTINCT ?uri WHERE { ?x <http://dbpedia.org/ontology/parentOrganisation> <http://dbpedia.org/resource/Comcast> . ?uri <http://dbpedia.org/ontology/network> ?x  . }\\n```\"}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][0]"
      ],
      "metadata": {
        "id": "I6ZrpbqtsUap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2041858c-b0e0-4141-da1f-c40af0725f54"
      },
      "id": "I6ZrpbqtsUap",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [{'actor': 'user',\n",
              "   'text': 'Extract the nouns from this natural language query.\\n\\n> How many movies did Stanley Kubrick direct?\\n\\nLet\\'s reason step by step. Identify the nouns on the query, skip the ones that can be solved by a SPARQL verb (ignore, for example, \"count\" or \"number of\"), and output a json list like this.\\n\\n```json\\n[\\n    \"entity1\",\\n    \"entity2\",\\n    ...\\n    \"entityN\"\\n]\\n```'},\n",
              "  {'actor': 'assistant',\n",
              "   'text': '```json\\n[\\n    \"movies\",\\n    \"Stanley Kubrick\",\\n    \"direct\"\\n]\\n```'},\n",
              "  {'actor': 'user',\n",
              "   'text': \"\\nThis are some examples on how the available properties can be used:\\n\\n### Subject: <http://dbpedia.org/resource/Direct_selling> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_selling> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_marketing> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_marketing> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_Axecess> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_Axecess> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_Axecess> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_Axecess> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_Axecess> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_Axecess> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_(EP)> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_(EP)> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_(EP)> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_(EP)> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_(EP)> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_(EP)> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_style> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_style> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_product> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_product> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_Influence> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_Influence> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_Influence> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_Influence> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_Influence> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_Influence> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_Contact> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_Contact> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_Contact> ; Predicate: <http://dbpedia.org/property/starring>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_Contact> <http://dbpedia.org/property/starring> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_Contact> ; Predicate: <http://dbpedia.org/ontology/starring>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_Contact> <http://dbpedia.org/ontology/starring> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_Line> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_Line> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_Group> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_Group> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_Agents> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_Agents> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_action> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_action> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_market> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_market> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_Star> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_Star> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_mode> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_mode> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_process> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_process> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Shaw_Direct> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Shaw_Direct> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Shop_Direct> ; Predicate: <http://dbpedia.org/ontology/division>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Shop_Direct> <http://dbpedia.org/ontology/division> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Shop_Direct> ; Predicate: <http://dbpedia.org/property/divisions>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Shop_Direct> <http://dbpedia.org/property/divisions> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Shop_Direct> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Shop_Direct> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/First_Direct> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/First_Direct> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_Fly> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_Fly> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Directi> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Directi> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Sports_Direct> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Sports_Direct> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/En_Directo> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/En_Directo> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/En_Directo> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/En_Directo> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/En_Directo> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/En_Directo> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Chemist_Direct> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Chemist_Direct> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_Marketing_Ass'n_v._Brohl> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_Marketing_Ass'n_v._Brohl> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/In_Kind_Direct> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/In_Kind_Direct> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_Cut_Direct> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_Cut_Direct> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_Cut_Direct> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_Cut_Direct> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Directo_USA> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Directo_USA> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_Action_Everywhere> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_Action_Everywhere> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Direct_case> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Direct_case> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Stanley_Kubrick> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Stanley_Kubrick> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Object: <http://dbpedia.org/resource/Stanley_Kubrick> ; Predicate: <http://dbpedia.org/ontology/cinematography>\\n\\n```sparql\\nSELECT DISTINCT ?subject WHERE { ?subject <http://dbpedia.org/ontology/cinematography> <http://dbpedia.org/resource/Stanley_Kubrick> }\\n```\\n\\n### Object: <http://dbpedia.org/resource/Stanley_Kubrick> ; Predicate: <http://dbpedia.org/ontology/director>\\n\\n```sparql\\nSELECT DISTINCT ?subject WHERE { ?subject <http://dbpedia.org/ontology/director> <http://dbpedia.org/resource/Stanley_Kubrick> }\\n```\\n\\n### Object: <http://dbpedia.org/resource/Stanley_Kubrick> ; Predicate: <http://dbpedia.org/property/director>\\n\\n```sparql\\nSELECT DISTINCT ?subject WHERE { ?subject <http://dbpedia.org/property/director> <http://dbpedia.org/resource/Stanley_Kubrick> }\\n```\\n\\n### Object: <http://dbpedia.org/resource/Stanley_Kubrick> ; Predicate: <http://dbpedia.org/property/starring>\\n\\n```sparql\\nSELECT DISTINCT ?subject WHERE { ?subject <http://dbpedia.org/property/starring> <http://dbpedia.org/resource/Stanley_Kubrick> }\\n```\\n\\n### Object: <http://dbpedia.org/resource/Stanley_Kubrick> ; Predicate: <http://dbpedia.org/ontology/starring>\\n\\n```sparql\\nSELECT DISTINCT ?subject WHERE { ?subject <http://dbpedia.org/ontology/starring> <http://dbpedia.org/resource/Stanley_Kubrick> }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Influence_of_Stanley_Kubrick> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Influence_of_Stanley_Kubrick> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Stanley_Kubrick's_Boxes> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Stanley_Kubrick's_Boxes> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Stanley_Kubrick's_Boxes> ; Predicate: <http://dbpedia.org/ontology/director>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Stanley_Kubrick's_Boxes> <http://dbpedia.org/ontology/director> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Stanley_Kubrick's_Boxes> ; Predicate: <http://dbpedia.org/property/director>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Stanley_Kubrick's_Boxes> <http://dbpedia.org/property/director> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Stanley_Kubrick's_Boxes> ; Predicate: <http://dbpedia.org/property/starring>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Stanley_Kubrick's_Boxes> <http://dbpedia.org/property/starring> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Stanley_Kubrick's_Boxes> ; Predicate: <http://dbpedia.org/ontology/starring>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Stanley_Kubrick's_Boxes> <http://dbpedia.org/ontology/starring> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Stanley_Kubrick's_Boxes> ; Predicate: <http://dbpedia.org/property/cinematography>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Stanley_Kubrick's_Boxes> <http://dbpedia.org/property/cinematography> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Stanley_Kubrick:_A_Life_in_Pictures> ; Predicate: <http://dbpedia.org/property/director>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Stanley_Kubrick:_A_Life_in_Pictures> <http://dbpedia.org/property/director> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Stanley_Kubrick:_A_Life_in_Pictures> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Stanley_Kubrick:_A_Life_in_Pictures> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Stanley_Kubrick:_A_Life_in_Pictures> ; Predicate: <http://dbpedia.org/ontology/director>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Stanley_Kubrick:_A_Life_in_Pictures> <http://dbpedia.org/ontology/director> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Vivian_Kubrick> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Vivian_Kubrick> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Colour_Me_Kubrick> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Colour_Me_Kubrick> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Colour_Me_Kubrick> ; Predicate: <http://dbpedia.org/ontology/director>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Colour_Me_Kubrick> <http://dbpedia.org/ontology/director> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Colour_Me_Kubrick> ; Predicate: <http://dbpedia.org/property/director>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Colour_Me_Kubrick> <http://dbpedia.org/property/director> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Colour_Me_Kubrick> ; Predicate: <http://dbpedia.org/property/starring>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Colour_Me_Kubrick> <http://dbpedia.org/property/starring> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Colour_Me_Kubrick> ; Predicate: <http://dbpedia.org/ontology/starring>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Colour_Me_Kubrick> <http://dbpedia.org/ontology/starring> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Christiane_Kubrick> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Christiane_Kubrick> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Object: <http://dbpedia.org/resource/Christiane_Kubrick> ; Predicate: <http://dbpedia.org/property/starring>\\n\\n```sparql\\nSELECT DISTINCT ?subject WHERE { ?subject <http://dbpedia.org/property/starring> <http://dbpedia.org/resource/Christiane_Kubrick> }\\n```\\n\\n### Object: <http://dbpedia.org/resource/Christiane_Kubrick> ; Predicate: <http://dbpedia.org/ontology/starring>\\n\\n```sparql\\nSELECT DISTINCT ?subject WHERE { ?subject <http://dbpedia.org/ontology/starring> <http://dbpedia.org/resource/Christiane_Kubrick> }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Kubrick_the_Dog> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Kubrick_the_Dog> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Stanislav_Kulish> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Stanislav_Kulish> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_Shining_(miniseries)> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_Shining_(miniseries)> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_Shining_(miniseries)> ; Predicate: <http://dbpedia.org/ontology/director>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_Shining_(miniseries)> <http://dbpedia.org/ontology/director> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_Shining_(miniseries)> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_Shining_(miniseries)> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_Shining_(miniseries)> ; Predicate: <http://dbpedia.org/property/director>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_Shining_(miniseries)> <http://dbpedia.org/property/director> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_Shining_(miniseries)> ; Predicate: <http://dbpedia.org/ontology/numberOfEpisodes>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_Shining_(miniseries)> <http://dbpedia.org/ontology/numberOfEpisodes> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_Shining_(miniseries)> ; Predicate: <http://dbpedia.org/property/starring>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_Shining_(miniseries)> <http://dbpedia.org/property/starring> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_Shining_(miniseries)> ; Predicate: <http://dbpedia.org/ontology/starring>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_Shining_(miniseries)> <http://dbpedia.org/ontology/starring> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_Shining_(miniseries)> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_Shining_(miniseries)> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Colour_Me_Kubrick_(soundtrack)> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Colour_Me_Kubrick_(soundtrack)> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Colour_Me_Kubrick_(soundtrack)> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Colour_Me_Kubrick_(soundtrack)> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Colour_Me_Kubrick_(soundtrack)> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Colour_Me_Kubrick_(soundtrack)> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_Shining_(film)> ; Predicate: <http://dbpedia.org/ontology/cinematography>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_Shining_(film)> <http://dbpedia.org/ontology/cinematography> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_Shining_(film)> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_Shining_(film)> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_Shining_(film)> ; Predicate: <http://dbpedia.org/ontology/director>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_Shining_(film)> <http://dbpedia.org/ontology/director> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_Shining_(film)> ; Predicate: <http://dbpedia.org/property/director>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_Shining_(film)> <http://dbpedia.org/property/director> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_Shining_(film)> ; Predicate: <http://dbpedia.org/property/cinematography>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_Shining_(film)> <http://dbpedia.org/property/cinematography> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Stanley_(1984_film)> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Stanley_(1984_film)> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Stanley_(1984_film)> ; Predicate: <http://dbpedia.org/ontology/director>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Stanley_(1984_film)> <http://dbpedia.org/ontology/director> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Stanley_(1984_film)> ; Predicate: <http://dbpedia.org/property/director>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Stanley_(1984_film)> <http://dbpedia.org/property/director> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Stanley_(1984_film)> ; Predicate: <http://dbpedia.org/property/starring>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Stanley_(1984_film)> <http://dbpedia.org/property/starring> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Stanley_(1984_film)> ; Predicate: <http://dbpedia.org/ontology/starring>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Stanley_(1984_film)> <http://dbpedia.org/ontology/starring> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Plato_von_Ustinov> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Plato_von_Ustinov> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Khrushchev:_The_Man_and_His_Era> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Khrushchev:_The_Man_and_His_Era> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Khrushchev:_The_Man_and_His_Era> ; Predicate: <http://dbpedia.org/ontology/dcc>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Khrushchev:_The_Man_and_His_Era> <http://dbpedia.org/ontology/dcc> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/Stanley_King> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/Stanley_King> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_Shining_(Violent_J_album)> ; Predicate: <http://dbpedia.org/ontology/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_Shining_(Violent_J_album)> <http://dbpedia.org/ontology/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_Shining_(Violent_J_album)> ; Predicate: <http://dbpedia.org/property/genre>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_Shining_(Violent_J_album)> <http://dbpedia.org/property/genre> ?object }\\n```\\n\\n### Subject: <http://dbpedia.org/resource/The_Shining_(Violent_J_album)> ; Predicate: <http://www.w3.org/ns/prov#wasDerivedFrom>\\n\\n```sparql\\nSELECT DISTINCT ?object WHERE { <http://dbpedia.org/resource/The_Shining_(Violent_J_album)> <http://www.w3.org/ns/prov#wasDerivedFrom> ?object }\\n```\\n\\nOf the ones given, which predicates will be useful to solve it?\\n\\nConsider it's better to query directly on IRIs and avoid filtering whenever possible. DO NOT generate any query yet.\\n\"},\n",
              "  {'actor': 'assistant',\n",
              "   'text': 'These are the predicates useful to solve this query:\\n- Through predicate <http://dbpedia.org/ontology/director> to object <http://dbpedia.org/resource/Stanley_Kubrick>\\n'},\n",
              "  {'actor': 'user',\n",
              "   'text': 'What are the subject IRIs that will be handy to solve this query? STILL DO NOT generate any query yet.'},\n",
              "  {'actor': 'assistant',\n",
              "   'text': 'These are the IRIs useful to solve this query:\\n- http://dbpedia.org/ontology/director\\n- http://dbpedia.org/resource/Stanley_Kubrick\\n'},\n",
              "  {'actor': 'user',\n",
              "   'text': \"\\nConstruct a SPARQL query to solve it on a single query, keep it simple and avoid unnecessary conditions. If it's an item list just do a SELECT, but if it's numeric you might need to use a verb like COUNT(), and if it's boolean you might need to use ASK.\\n\\nRemember to avoid querying by label, use the IRIs and relations presented before, not others. DO NOT even use common types like `name` or `type` unless they were explicitly allowed.\\n\\nQuery to solve:\\n> How many movies did Stanley Kubrick direct?\"},\n",
              "  {'actor': 'assistant',\n",
              "   'text': '```sparql\\nSELECT DISTINCT COUNT(?uri) WHERE {?uri <http://dbpedia.org/ontology/director> <http://dbpedia.org/resource/Stanley_Kubrick>  . }\\n```'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from transformers import set_seed\n",
        "seed = 42\n",
        "set_seed(seed)\n",
        "\n",
        "index = 0\n",
        "\n",
        "conversation = dataset['train'][index]\n",
        "\n",
        "import re\n",
        "\n",
        "PARSE_IM_RE = re.compile(r'<\\|im_start\\|>([^<]+)<\\|im_sep\\|>(([^<]|<[^|])*)<\\|im_end\\|>')\n",
        "\n",
        "# Generate output\n",
        "def gen(model, conversation, max_length, skip_last=True):\n",
        "    conversation_steps = []\n",
        "    for idx, step in enumerate(conversation['messages']):\n",
        "        # TODO: Check that these tokens are correct\n",
        "        if idx < (len(conversation['messages']) - 1) or not skip_last:\n",
        "          conversation_steps.append(f\"<|im_start|>{step['actor']}<|im_sep|>{step['text']}<|im_end|>\")\n",
        "        else:\n",
        "          assert step['actor'] == 'assistant'\n",
        "\n",
        "    inputs = tokenizer('\\n'.join(conversation_steps), return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(**inputs, max_length=max_length)\n",
        "    return ''.join(tokenizer.batch_decode(outputs)).split('<|endoftext|>')[0] # , skip_special_tokens=True)\n",
        "\n",
        "def parse_out(output):\n",
        "  results = []\n",
        "  for chunk in PARSE_IM_RE.findall(output):\n",
        "    results.append((chunk[0], chunk[1]))\n",
        "  return results\n",
        "\n",
        "res = gen(model, conversation, 8000,)\n",
        "output = parse_out(res)\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "# print(f'INPUT PROMPT:\\n{formatted_prompt}')\n",
        "# print(dash_line)\n",
        "print(f'BASELINE OUTPUT:\\n{conversation[\"messages\"][-1][\"text\"]}\\n')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - ZERO SHOT:\\n{output[-1][1]}')"
      ],
      "metadata": {
        "id": "xaYPgaN6sWOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2aa939a-42c0-483a-b738-4d8afea24d2a"
      },
      "id": "xaYPgaN6sWOa",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BASELINE OUTPUT:\n",
            "```sparql\n",
            "SELECT DISTINCT COUNT(?uri) WHERE {?uri <http://dbpedia.org/ontology/director> <http://dbpedia.org/resource/Stanley_Kubrick>  . }\n",
            "```\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "To find out how many movies Stanley Kubrick directed, you can use the following SPARQL query:\n",
            "\n",
            "```sparql\n",
            "SELECT (COUNT(?movie) AS ?numberOfMovies) WHERE {\n",
            "    ?movie <http://dbpedia.org/ontology/director> <http://dbpedia.org/resource/Stanley_Kubrick> .\n",
            "    ?movie <http://dbpedia.org/ontology/genre> <http://dbpedia.org/resource/Film> .\n",
            "}\n",
            "```\n",
            "\n",
            "This query counts the number of movies (`?movie`) where Stanley Kubrick is listed as the director and the genre is \"Film\".\n",
            "CPU times: user 9.55 s, sys: 310 ms, total: 9.86 s\n",
            "Wall time: 9.87 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt_formats(sample):\n",
        "    \"\"\"\n",
        "    Preparate a sample for prompt creation.\n",
        "    :param sample: Sample dictionnary\n",
        "    \"\"\"\n",
        "    batch = []\n",
        "    for conversation in sample['messages']:\n",
        "      conversation_steps = []\n",
        "      for step in conversation:\n",
        "          # TODO: Check that these tokens are correct\n",
        "          conversation_steps.append(f\"<|im_start|>{step['actor']}<|im_sep|>{step['text']}<|im_end|>\")\n",
        "      batch.append('\\n'.join(conversation_steps))\n",
        "    return {\"text\": batch}"
      ],
      "metadata": {
        "id": "OUiZcjj1saGB"
      },
      "id": "OUiZcjj1saGB",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "# SOURCE https://github.com/databrickslabs/dolly/blob/master/training/trainer.py\n",
        "def get_max_length(model):\n",
        "    conf = model.config\n",
        "    max_length = None\n",
        "    for length_setting in [\"n_positions\", \"max_position_embeddings\", \"seq_length\"]:\n",
        "        max_length = getattr(model.config, length_setting, None)\n",
        "        if max_length:\n",
        "            print(f\"Found max lenth: {max_length}\")\n",
        "            break\n",
        "    if not max_length:\n",
        "        max_length = 1024\n",
        "        print(f\"Using default max length: {max_length}\")\n",
        "    return max_length\n",
        "\n",
        "\n",
        "def preprocess_batch(batch, tokenizer, max_length):\n",
        "    \"\"\"\n",
        "    Tokenizing a batch\n",
        "    \"\"\"\n",
        "    return tokenizer(\n",
        "        batch[\"text\"],\n",
        "        max_length=max_length,\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "# SOURCE https://github.com/databrickslabs/dolly/blob/master/training/trainer.py\n",
        "def preprocess_dataset(tokenizer: AutoTokenizer, max_length: int,seed, dataset):\n",
        "    \"\"\"Format & tokenize it so it is ready for training\n",
        "    :param tokenizer (AutoTokenizer): Model Tokenizer\n",
        "    :param max_length (int): Maximum number of tokens to emit from tokenizer\n",
        "    \"\"\"\n",
        "\n",
        "    # Add prompt to each sample\n",
        "    print(\"Preprocessing dataset...\")\n",
        "    dataset = dataset.map(create_prompt_formats, batched=True)\n",
        "    print(\"DS\", dataset)\n",
        "\n",
        "    # Apply preprocessing to each batch of the dataset & and remove 'instruction', 'context', 'response', 'category' fields\n",
        "    # _preprocessing_function = partial(preprocess_batch, max_length=max_length, tokenizer=tokenizer)\n",
        "    dataset = dataset.map(\n",
        "        # _preprocessing_function,\n",
        "        lambda x: tokenizer(x['text'], truncation=False, max_length=max_length),\n",
        "        batched=True,\n",
        "        # remove_columns=['user', 'assistant'],\n",
        "    )\n",
        "\n",
        "    # Filter out samples that have input_ids exceeding max_length\n",
        "    dataset = dataset.filter(lambda sample: len(sample[\"input_ids\"]) < max_length)\n",
        "\n",
        "    # Shuffle dataset\n",
        "    dataset = dataset.shuffle(seed=seed)\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "7L9Iup-wscc6"
      },
      "id": "7L9Iup-wscc6",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Pre-process dataset\n",
        "max_length = get_max_length(model)\n",
        "print(max_length)\n",
        "\n",
        "train_dataset = preprocess_dataset(tokenizer, max_length,seed, dataset['train'])\n",
        "eval_dataset = preprocess_dataset(tokenizer, max_length,seed, dataset['test'])"
      ],
      "metadata": {
        "id": "Fvx-1ZJxseaK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585,
          "referenced_widgets": [
            "33dd891cbd664755b6ecd27e928f8cbc",
            "faf3c584b400404ea51a2941abdf386e",
            "8ce6567801f64e67a983a924d703e29c",
            "84a652b31cb5494d85474ab3540cc495",
            "4b13ffe8270d424f989508dc4c970771",
            "edfe38cdfc4f47bebcdfcc80028280a6",
            "a7c6a0e7ce004c05a32ac74a0d01a0d9",
            "ce8853d2d3b9432eae29f6b53873382c",
            "e656ac76c93841ab885440c20446b8e2",
            "ad32bba0912442d0b060e77eb112941a",
            "c2d1ce316e1a41e4ab3908435b89a2e2",
            "3c37b6993ecc446db2dc5d746740afdd",
            "15344078c7884086aa8e2d02dc84ad99",
            "a604fdbb0f73499a82ff7dd5cded6a94",
            "6e380d56244a4f3182f5184d61f48c6c",
            "b216049803e34e4da8658cb73541d9e2",
            "ec1bc30bc07c421ba907067e76af1468",
            "1b2ac1f103e2468dad395f89b422c295",
            "7d99a03c1870432fa51673562575afc9",
            "5bec0d13e6c044f89edf5fd6ec4f48b5",
            "5585d52d1b7b4c878d2758f890de720d",
            "eeaafd0cc7c24593bf3c082abcaec67c",
            "0e60a5dcb2b54f65b8a8b8a21b5351c1",
            "b07bc3f29d9f4b009e55676da5255b28",
            "8ca404ca254a4ee89d5b11f90b8c25df",
            "b08098d580fc417f8c2e03b7b4151a16",
            "e67dc36f9bc346c8b3496df486844318",
            "ebf81f588de4427e840f915f76899904",
            "a5460fb158dd466891b68ef227e05137",
            "b3532daa9ad84be5bb739cb05e44978f",
            "3f25d0b5631949a3b36cafd59f9e9696",
            "902b043560ee49068cc1a2c124abf0e4",
            "d7c732fd4bf44bd18eb15a85e9362075",
            "e550b537515446a898ed4486c66e802f",
            "7f325849bbfd422aa6042ad90bb33f62",
            "1f726dd291a04598aadf70ad01a533eb",
            "1b3a9d74e0714994b47729e364a73fb9",
            "5e037ad3ea9d43eea24b4a3da0b1562d",
            "23082ccbb3514e20bde3bae0b816c45a",
            "134b255f433540b9ad29756548865eb4",
            "b4cf457752d847a4b4e49e1c5e84505e",
            "cfbb2a4e7c6547c7b2f68d614ab4d3a8",
            "9e1183f49ae04988ae061d0442cc6ba6",
            "f6cdd7c1e28b485d8fc6bbf7034eb4f4",
            "fafb116911f44c5a903c74b669d4de18",
            "0e1b76f88ffd49ed92eb936896b4faa4",
            "cf68ad9049bd46018262af06ec08a703",
            "344098131b3d4feaa41c36e93a18c26d",
            "a1f226ab8ff643d79484ef24575c4ac1",
            "8483b62b218b4771bd910257be6c54ba",
            "68ebb47f46484c33bd6c0567b69297e8",
            "05032c967be64a0b98d64235b2fc00ff",
            "674f46ff32d94a588db46a82f172ce5f",
            "5da0a147c4f64077b304f2c8ce483a43",
            "9997a3198a6d42389082196ba5901445",
            "8d3c46b3ee954c17aa570bab9e414663",
            "4900dd6397524ec38bb3974f9d6e7bdd",
            "040a096bf83c4a6094301547c4223c5b",
            "df7fcb3cd9a0440892fb21bddff646de",
            "0055b6e3fa114511b5f40f0bb4340744",
            "274c449c40a4407194849347c5908063",
            "0a3534d1e7c64ed997a83c8963244b4d",
            "6667f9868a66486eba943d39d4fc0c9e",
            "6efbd171c2164e64b01870dbe9b21c3e",
            "154a1affbf204fbc8e9ee324678d3c94",
            "9a176c27c3454cf4b5b9fab6f8bbfe60"
          ]
        },
        "outputId": "8dade5f5-4ad3-4371-9812-a468c44bc8c3"
      },
      "id": "Fvx-1ZJxseaK",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found max lenth: 16384\n",
            "16384\n",
            "Preprocessing dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33dd891cbd664755b6ecd27e928f8cbc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DS Dataset({\n",
            "    features: ['messages', 'text'],\n",
            "    num_rows: 2200\n",
            "})\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c37b6993ecc446db2dc5d746740afdd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/2200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e60a5dcb2b54f65b8a8b8a21b5351c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e550b537515446a898ed4486c66e802f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DS Dataset({\n",
            "    features: ['messages', 'text'],\n",
            "    num_rows: 10\n",
            "})\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fafb116911f44c5a903c74b669d4de18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d3c46b3ee954c17aa570bab9e414663"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = LORA_RANK, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = LORA_ALPHA,\n",
        "    lora_dropout = LORA_DROPOUT, # Supports any, but = 0 is optimized\n",
        "    bias = LORA_BIAS,    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 42,\n",
        "    use_rslora = LORA_RANK_STABILIZED,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIPcJzBjOMez",
        "outputId": "c3e3f952-cef2-4416-b20a-03d7e0c82d54"
      },
      "id": "YIPcJzBjOMez",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.5.4 patched 40 layers with 40 QKV layers, 40 O layers and 40 MLP layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training"
      ],
      "metadata": {
        "id": "51xnl9xesgEX"
      },
      "id": "51xnl9xesgEX",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 2 - Using the prepare_model_for_kbit_training method from PEFT\n",
        "# # Preparing the Model for QLoRA\n",
        "# original_model = prepare_model_for_kbit_training(original_model)"
      ],
      "metadata": {
        "id": "OyHC1nZ2shIo"
      },
      "id": "OyHC1nZ2shIo",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config = LoraConfig(\n",
        "#     r=32, # Rank\n",
        "#     lora_alpha=16,\n",
        "#     target_modules=[\n",
        "#         # \"q_proj\",  # Not found, ignored\n",
        "#         # \"k_proj\",  # Not found, ignored\n",
        "#         # \"v_proj\",  # Not found, ignored\n",
        "#         \"o_proj\",\n",
        "#         # \"gate_proj\", # Not found, ignored\n",
        "#         # \"up_proj\", # Not found, ignored\n",
        "#         \"down_proj\"\n",
        "#         ],\n",
        "#     bias=\"none\",\n",
        "#     lora_dropout=0.2,\n",
        "#     task_type=\"CAUSAL_LM\",\n",
        "# )\n",
        "\n",
        "# # 1 - Enabling gradient checkpointing to reduce memory usage during fine-tuning\n",
        "# original_model.gradient_checkpointing_enable()\n",
        "\n",
        "# peft_model = get_peft_model(original_model, config)"
      ],
      "metadata": {
        "id": "wX4ySk2xsiLB"
      },
      "id": "wX4ySk2xsiLB",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "6VmN9_bpsjxh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9da22c1f-d66c-4556-8354-0784c8efc58b"
      },
      "id": "6VmN9_bpsjxh",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 65,536,000 || all params: 14,725,043,200 || trainable%: 0.4451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = f'./fine-tuned/' + RUN_CODE\n",
        "import transformers\n",
        "\n",
        "peft_training_args = TrainingArguments(\n",
        "    output_dir = output_dir,\n",
        "    warmup_steps=1,\n",
        "    per_device_train_batch_size=1, #\n",
        "    per_device_eval_batch_size=1, # same as above\n",
        "    gradient_accumulation_steps=1,\n",
        "    num_train_epochs=MAX_EPOCHS,\n",
        "    # max_steps=MAX_STEPS, # If given a MAX_STEPS, not all data is trained\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    save_steps=100, # For `load_best_model_at_end=True` must be same as `eval_steps`\n",
        "    eval_steps=100, # This is what takes most of the time! More steps between evals means faster training\n",
        "    do_eval=True,\n",
        "    logging_steps=25,\n",
        "    logging_dir=\"./logs\",\n",
        "    eval_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    load_best_model_at_end=True,\n",
        "    gradient_checkpointing=True,\n",
        "    report_to=\"wandb\",\n",
        "    overwrite_output_dir = 'True',\n",
        "    group_by_length=True,\n",
        ")\n",
        "\n",
        "model.config.use_cache = False\n",
        "\n",
        "peft_trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    args=peft_training_args,\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n"
      ],
      "metadata": {
        "id": "zOfBzJcSsk7r"
      },
      "id": "zOfBzJcSsk7r",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = peft_trainer.train()"
      ],
      "metadata": {
        "id": "XhAnDiqWsopC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "09dd386d-46b8-48d0-9071-07288d022846"
      },
      "id": "XhAnDiqWsopC",
      "execution_count": 33,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 1,635 | Num Epochs = 2 | Total steps = 3,270\n",
            "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 1\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 1 x 1) = 1\n",
            " \"-____-\"     Trainable parameters = 65,536,000/14,725,043,200 (0.45% trained)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250516_160328-96lqsrqw</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sergiomportela-universitat-oberta-de-catalunya/fine-tune-tfm-2025-tests/runs/96lqsrqw' target=\"_blank\">./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601</a></strong> to <a href='https://wandb.ai/sergiomportela-universitat-oberta-de-catalunya/fine-tune-tfm-2025-tests' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/sergiomportela-universitat-oberta-de-catalunya/fine-tune-tfm-2025-tests' target=\"_blank\">https://wandb.ai/sergiomportela-universitat-oberta-de-catalunya/fine-tune-tfm-2025-tests</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/sergiomportela-universitat-oberta-de-catalunya/fine-tune-tfm-2025-tests/runs/96lqsrqw' target=\"_blank\">https://wandb.ai/sergiomportela-universitat-oberta-de-catalunya/fine-tune-tfm-2025-tests/runs/96lqsrqw</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='468' max='3270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 468/3270 32:42 < 3:16:42, 0.24 it/s, Epoch 0.29/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.133700</td>\n",
              "      <td>0.131901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.108600</td>\n",
              "      <td>0.126010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.105400</td>\n",
              "      <td>0.129648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.108000</td>\n",
              "      <td>0.119499</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100)... Done. 0.9s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200)... Done. 0.9s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300)... Done. 0.9s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400)... Done. 0.9s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3270' max='3270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3270/3270 3:36:52, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.133700</td>\n",
              "      <td>0.131901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.108600</td>\n",
              "      <td>0.126010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.105400</td>\n",
              "      <td>0.129648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.108000</td>\n",
              "      <td>0.119499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.119000</td>\n",
              "      <td>0.119138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.111200</td>\n",
              "      <td>0.116130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.100800</td>\n",
              "      <td>0.114543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.108200</td>\n",
              "      <td>0.111563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.116400</td>\n",
              "      <td>0.109905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.112900</td>\n",
              "      <td>0.112030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.092800</td>\n",
              "      <td>0.111249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.095800</td>\n",
              "      <td>0.110746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.089100</td>\n",
              "      <td>0.108411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.097600</td>\n",
              "      <td>0.107085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.094400</td>\n",
              "      <td>0.105584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.092200</td>\n",
              "      <td>0.105528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.075200</td>\n",
              "      <td>0.105889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.071900</td>\n",
              "      <td>0.107672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.067100</td>\n",
              "      <td>0.109283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.106756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.072100</td>\n",
              "      <td>0.106719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.069700</td>\n",
              "      <td>0.107027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.068800</td>\n",
              "      <td>0.108348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.055800</td>\n",
              "      <td>0.106923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.072200</td>\n",
              "      <td>0.107267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.073300</td>\n",
              "      <td>0.107590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.066800</td>\n",
              "      <td>0.106657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.066500</td>\n",
              "      <td>0.106196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.067800</td>\n",
              "      <td>0.105751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.063000</td>\n",
              "      <td>0.106031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.066300</td>\n",
              "      <td>0.105493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.063900</td>\n",
              "      <td>0.105690</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500)... Done. 0.8s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600)... Done. 0.9s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700)... Done. 0.9s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800)... Done. 1.0s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900)... Done. 0.9s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000)... Done. 1.0s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100)... Done. 1.0s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200)... Done. 1.0s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300)... Done. 1.0s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400)... Done. 1.0s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500)... Done. 0.9s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600)... Done. 1.0s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700)... Done. 1.0s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800)... Done. 0.9s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900)... Done. 0.9s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000)... Done. 1.0s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100)... Done. 1.4s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200)... Done. 0.9s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300)... Done. 0.8s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400)... Done. 1.0s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500)... Done. 1.0s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600)... Done. 1.0s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700)... Done. 0.9s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800)... Done. 1.0s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900)... Done. 0.8s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000)... Done. 1.0s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100)... Done. 0.9s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200)... Done. 1.0s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270)... Done. 0.8s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test results"
      ],
      "metadata": {
        "id": "IV8jEvtsstf9"
      },
      "id": "IV8jEvtsstf9"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from transformers import set_seed\n",
        "seed = 42\n",
        "set_seed(seed)\n",
        "\n",
        "index = 0\n",
        "\n",
        "conversation = dataset['train'][index]\n",
        "\n",
        "import re\n",
        "\n",
        "PARSE_IM_RE = re.compile(r'<\\|im_start\\|>([^<]+)<\\|im_sep\\|>(([^<]|<[^|])*)<\\|im_end\\|>')\n",
        "\n",
        "# Generate output\n",
        "def gen(model, conversation, max_length, skip_last=True):\n",
        "    conversation_steps = []\n",
        "    for idx, step in enumerate(conversation['messages']):\n",
        "        # TODO: Check that these tokens are correct\n",
        "        if idx < (len(conversation['messages']) - 1) or not skip_last:\n",
        "          conversation_steps.append(f\"<|im_start|>{step['actor']}<|im_sep|>{step['text']}<|im_end|>\")\n",
        "        else:\n",
        "          assert step['actor'] == 'assistant'\n",
        "\n",
        "    inputs = tokenizer('\\n'.join(conversation_steps), return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(**inputs, max_length=max_length)\n",
        "    return ''.join(tokenizer.batch_decode(outputs)).split('<|endoftext|>')[0] # , skip_special_tokens=True)\n",
        "\n",
        "def parse_out(output):\n",
        "  results = []\n",
        "  for chunk in PARSE_IM_RE.findall(output):\n",
        "    results.append((chunk[0], chunk[1]))\n",
        "  return results\n",
        "\n",
        "res = gen(model, conversation, 1000,)\n",
        "output = parse_out(res)\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "# print(f'INPUT PROMPT:\\n{formatted_prompt}')\n",
        "# print(dash_line)\n",
        "print(f'BASELINE OUTPUT:\\n{conversation[\"messages\"][-1][\"text\"]}\\n')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - ZERO SHOT:\\n{output[-1][1]}')"
      ],
      "metadata": {
        "id": "CIimEZxRsurD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "123444d2-7866-4d06-a3a2-7a3e34a2ba6c"
      },
      "id": "CIimEZxRsurD",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input length of input_ids is 7798, but `max_length` is set to 1000. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mgen\u001b[0;34m(model, conversation, max_length, skip_last)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1873\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1874\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1875\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1876\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36munsloth_fast_generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m     \u001b[0;31m# Mixed precision autocast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1581\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1582\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[1;32m   2319\u001b[0m             \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logits_to_keep\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2321\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_generated_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_default_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2323\u001b[0m         \u001b[0;31m# 7. Prepare the cache.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_validate_generated_length\u001b[0;34m(self, generation_config, input_ids_length, has_default_max_length)\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_ids_length\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m             \u001b[0minput_ids_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"decoder_input_ids\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1555\u001b[0m                 \u001b[0;34mf\"Input length of {input_ids_string} is {input_ids_length}, but `max_length` is set to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m                 \u001b[0;34mf\" {generation_config.max_length}. This can lead to unexpected behavior. You should consider\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input length of input_ids is 7798, but `max_length` is set to 1000. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload results"
      ],
      "metadata": {
        "id": "JuybOrBZYV6b"
      },
      "id": "JuybOrBZYV6b"
    },
    {
      "cell_type": "code",
      "source": [
        "!rsync -HPrz --mkpath \\\n",
        "  fine-tuned \\\n",
        "  result-pusher@kb.tfm.codigoparallevar.com:fine-tuning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otTphZSUYXN8",
        "outputId": "f3c03448-9e03-4986-eb64-eb2c879fc24d"
      },
      "id": "otTphZSUYXN8",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sending incremental file list\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1550/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1555/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/README.md\n",
            "          5,087 100%    0.00kB/s    0:00:00 (xfr#1, to-chk=428/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/adapter_config.json\n",
            "            843 100%  823.24kB/s    0:00:00 (xfr#2, to-chk=427/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/adapter_model.safetensors\n",
            "    262,219,392 100%   16.03MB/s    0:00:15 (xfr#3, to-chk=426/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/merges.txt\n",
            "        916,646 100%    2.11MB/s    0:00:00 (xfr#4, to-chk=425/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/optimizer.pt\n",
            "    133,784,532 100%   15.94MB/s    0:00:08 (xfr#5, to-chk=424/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/rng_state.pth\n",
            "         14,244 100%   15.24kB/s    0:00:00 (xfr#6, to-chk=423/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/scheduler.pt\n",
            "          1,064 100%    1.14kB/s    0:00:00 (xfr#7, to-chk=422/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/special_tokens_map.json\n",
            "            456 100%    0.49kB/s    0:00:00 (xfr#8, to-chk=421/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/tokenizer.json\n",
            "      7,153,264 100%    6.42MB/s    0:00:01 (xfr#9, to-chk=420/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/tokenizer_config.json\n",
            "         17,987 100%  351.31kB/s    0:00:00 (xfr#10, to-chk=419/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/trainer_state.json\n",
            "          1,791 100%   34.98kB/s    0:00:00 (xfr#11, to-chk=418/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/training_args.bin\n",
            "          5,304 100%  103.59kB/s    0:00:00 (xfr#12, to-chk=417/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/vocab.json\n",
            "      1,612,637 100%   19.72MB/s    0:00:00 (xfr#13, to-chk=416/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/README.md\n",
            "          5,087 100%   61.33kB/s    0:00:00 (xfr#14, to-chk=415/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/adapter_config.json\n",
            "            843 100%   10.16kB/s    0:00:00 (xfr#15, to-chk=414/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/adapter_model.safetensors\n",
            "    262,219,392 100%   16.59MB/s    0:00:15 (xfr#16, to-chk=413/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/merges.txt\n",
            "        916,646 100%  980.46kB/s    0:00:00 (xfr#17, to-chk=412/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/optimizer.pt\n",
            "    133,785,108 100%   15.02MB/s    0:00:08 (xfr#18, to-chk=411/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/rng_state.pth\n",
            "         14,244 100%   35.94kB/s    0:00:00 (xfr#19, to-chk=410/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/scheduler.pt\n",
            "          1,064 100%    2.68kB/s    0:00:00 (xfr#20, to-chk=409/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/special_tokens_map.json\n",
            "            456 100%    1.15kB/s    0:00:00 (xfr#21, to-chk=408/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/tokenizer.json\n",
            "      7,153,264 100%   15.06MB/s    0:00:00 (xfr#22, to-chk=407/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/tokenizer_config.json\n",
            "         17,987 100%   38.78kB/s    0:00:00 (xfr#23, to-chk=406/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/trainer_state.json\n",
            "          9,974 100%   21.50kB/s    0:00:00 (xfr#24, to-chk=405/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/training_args.bin\n",
            "          5,304 100%   11.41kB/s    0:00:00 (xfr#25, to-chk=404/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/vocab.json\n",
            "      1,612,637 100%    2.92MB/s    0:00:00 (xfr#26, to-chk=403/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/README.md\n",
            "          5,087 100%    9.39kB/s    0:00:00 (xfr#27, to-chk=402/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/adapter_config.json\n",
            "            843 100%    1.56kB/s    0:00:00 (xfr#28, to-chk=401/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/adapter_model.safetensors\n",
            "    262,219,392 100%   16.18MB/s    0:00:15 (xfr#29, to-chk=400/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/merges.txt\n",
            "        916,646 100%    3.14MB/s    0:00:00 (xfr#30, to-chk=399/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/optimizer.pt\n",
            "    133,785,108 100%   15.87MB/s    0:00:08 (xfr#31, to-chk=398/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/rng_state.pth\n",
            "         14,244 100%   17.97kB/s    0:00:00 (xfr#32, to-chk=397/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/scheduler.pt\n",
            "          1,064 100%    1.34kB/s    0:00:00 (xfr#33, to-chk=396/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/special_tokens_map.json\n",
            "            456 100%    0.58kB/s    0:00:00 (xfr#34, to-chk=395/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/tokenizer.json\n",
            "      7,153,264 100%    7.50MB/s    0:00:00 (xfr#35, to-chk=394/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/tokenizer_config.json\n",
            "         17,987 100%   19.30kB/s    0:00:00 (xfr#36, to-chk=393/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/trainer_state.json\n",
            "         10,885 100%   11.67kB/s    0:00:00 (xfr#37, to-chk=392/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/training_args.bin\n",
            "          5,304 100%    5.69kB/s    0:00:00 (xfr#38, to-chk=391/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/vocab.json\n",
            "      1,612,637 100%    1.64MB/s    0:00:00 (xfr#39, to-chk=390/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/README.md\n",
            "          5,087 100%    5.29kB/s    0:00:00 (xfr#40, to-chk=389/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/adapter_config.json\n",
            "            843 100%    0.88kB/s    0:00:00 (xfr#41, to-chk=388/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/adapter_model.safetensors\n",
            "    262,219,392 100%   15.67MB/s    0:00:15 (xfr#42, to-chk=387/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/merges.txt\n",
            "        916,646 100%    1.12MB/s    0:00:00 (xfr#43, to-chk=386/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/optimizer.pt\n",
            "    133,785,108 100%   15.25MB/s    0:00:08 (xfr#44, to-chk=385/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/rng_state.pth\n",
            "         14,244 100%   54.34kB/s    0:00:00 (xfr#45, to-chk=384/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/scheduler.pt\n",
            "          1,064 100%    4.06kB/s    0:00:00 (xfr#46, to-chk=383/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/special_tokens_map.json\n",
            "            456 100%    1.74kB/s    0:00:00 (xfr#47, to-chk=382/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/tokenizer.json\n",
            "      7,153,264 100%   21.39MB/s    0:00:00 (xfr#48, to-chk=381/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/tokenizer_config.json\n",
            "         17,987 100%   55.06kB/s    0:00:00 (xfr#49, to-chk=380/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/trainer_state.json\n",
            "         11,801 100%   36.13kB/s    0:00:00 (xfr#50, to-chk=379/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/training_args.bin\n",
            "          5,304 100%   16.19kB/s    0:00:00 (xfr#51, to-chk=378/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/vocab.json\n",
            "      1,612,637 100%    3.92MB/s    0:00:00 (xfr#52, to-chk=377/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/README.md\n",
            "          5,087 100%   12.64kB/s    0:00:00 (xfr#53, to-chk=376/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/adapter_config.json\n",
            "            843 100%    2.09kB/s    0:00:00 (xfr#54, to-chk=375/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/adapter_model.safetensors\n",
            "    262,219,392 100%   16.29MB/s    0:00:15 (xfr#55, to-chk=374/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/merges.txt\n",
            "        916,646 100%    5.27MB/s    0:00:00 (xfr#56, to-chk=373/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/optimizer.pt\n",
            "    133,785,108 100%   16.48MB/s    0:00:07 (xfr#57, to-chk=372/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/rng_state.pth\n",
            "         14,244 100%   21.20kB/s    0:00:00 (xfr#58, to-chk=371/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/scheduler.pt\n",
            "          1,064 100%    1.58kB/s    0:00:00 (xfr#59, to-chk=370/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/special_tokens_map.json\n",
            "            456 100%    0.68kB/s    0:00:00 (xfr#60, to-chk=369/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/tokenizer.json\n",
            "      7,153,264 100%    8.80MB/s    0:00:00 (xfr#61, to-chk=368/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/tokenizer_config.json\n",
            "         17,987 100%   22.67kB/s    0:00:00 (xfr#62, to-chk=367/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/trainer_state.json\n",
            "         12,712 100%   16.02kB/s    0:00:00 (xfr#63, to-chk=366/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/training_args.bin\n",
            "          5,304 100%    6.68kB/s    0:00:00 (xfr#64, to-chk=365/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/vocab.json\n",
            "      1,612,637 100%    1.92MB/s    0:00:00 (xfr#65, to-chk=364/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/README.md\n",
            "          5,087 100%    6.18kB/s    0:00:00 (xfr#66, to-chk=363/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/adapter_config.json\n",
            "            843 100%    1.02kB/s    0:00:00 (xfr#67, to-chk=362/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/adapter_model.safetensors\n",
            "    262,219,392 100%   15.89MB/s    0:00:15 (xfr#68, to-chk=361/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/merges.txt\n",
            "        916,646 100%    1.37MB/s    0:00:00 (xfr#69, to-chk=360/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/optimizer.pt\n",
            "    133,785,108 100%   15.01MB/s    0:00:08 (xfr#70, to-chk=359/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/rng_state.pth\n",
            "         14,244 100%   36.41kB/s    0:00:00 (xfr#71, to-chk=358/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/scheduler.pt\n",
            "          1,064 100%    2.71kB/s    0:00:00 (xfr#72, to-chk=357/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/special_tokens_map.json\n",
            "            456 100%    1.16kB/s    0:00:00 (xfr#73, to-chk=356/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/tokenizer.json\n",
            "      7,153,264 100%   15.33MB/s    0:00:00 (xfr#74, to-chk=355/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/tokenizer_config.json\n",
            "         17,987 100%   39.38kB/s    0:00:00 (xfr#75, to-chk=354/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/trainer_state.json\n",
            "         13,629 100%   29.71kB/s    0:00:00 (xfr#76, to-chk=353/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/training_args.bin\n",
            "          5,304 100%   11.56kB/s    0:00:00 (xfr#77, to-chk=352/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/vocab.json\n",
            "      1,612,637 100%    2.99MB/s    0:00:00 (xfr#78, to-chk=351/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/README.md\n",
            "          5,087 100%    9.61kB/s    0:00:00 (xfr#79, to-chk=350/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/adapter_config.json\n",
            "            843 100%    1.59kB/s    0:00:00 (xfr#80, to-chk=349/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/adapter_model.safetensors\n",
            "    262,219,392 100%   16.16MB/s    0:00:15 (xfr#81, to-chk=348/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/merges.txt\n",
            "        916,646 100%    2.78MB/s    0:00:00 (xfr#82, to-chk=347/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/optimizer.pt\n",
            "    133,785,108 100%   16.15MB/s    0:00:07 (xfr#83, to-chk=346/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/rng_state.pth\n",
            "         14,244 100%   17.22kB/s    0:00:00 (xfr#84, to-chk=345/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/scheduler.pt\n",
            "          1,064 100%    1.29kB/s    0:00:00 (xfr#85, to-chk=344/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/special_tokens_map.json\n",
            "            456 100%    0.55kB/s    0:00:00 (xfr#86, to-chk=343/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/tokenizer.json\n",
            "      7,153,264 100%    7.38MB/s    0:00:00 (xfr#87, to-chk=342/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/tokenizer_config.json\n",
            "         17,987 100%   18.99kB/s    0:00:00 (xfr#88, to-chk=341/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/trainer_state.json\n",
            "         14,545 100%   15.36kB/s    0:00:00 (xfr#89, to-chk=340/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/training_args.bin\n",
            "          5,304 100%    5.60kB/s    0:00:00 (xfr#90, to-chk=339/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/vocab.json\n",
            "      1,612,637 100%    1.62MB/s    0:00:00 (xfr#91, to-chk=338/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/README.md\n",
            "          5,087 100%    5.23kB/s    0:00:00 (xfr#92, to-chk=337/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/adapter_config.json\n",
            "            843 100%    0.87kB/s    0:00:00 (xfr#93, to-chk=336/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/adapter_model.safetensors\n",
            "    262,219,392 100%   15.75MB/s    0:00:15 (xfr#94, to-chk=335/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/merges.txt\n",
            "        916,646 100%    1.13MB/s    0:00:00 (xfr#95, to-chk=334/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/optimizer.pt\n",
            "    133,785,108 100%   15.27MB/s    0:00:08 (xfr#96, to-chk=333/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/rng_state.pth\n",
            "         14,244 100%   54.76kB/s    0:00:00 (xfr#97, to-chk=332/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/scheduler.pt\n",
            "          1,064 100%    4.09kB/s    0:00:00 (xfr#98, to-chk=331/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/special_tokens_map.json\n",
            "            456 100%    1.75kB/s    0:00:00 (xfr#99, to-chk=330/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/tokenizer.json\n",
            "      7,153,264 100%   22.37MB/s    0:00:00 (xfr#100, to-chk=329/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/tokenizer_config.json\n",
            "         17,987 100%   57.59kB/s    0:00:00 (xfr#101, to-chk=328/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/trainer_state.json\n",
            "         15,456 100%   49.33kB/s    0:00:00 (xfr#102, to-chk=327/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/training_args.bin\n",
            "          5,304 100%   16.93kB/s    0:00:00 (xfr#103, to-chk=326/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/vocab.json\n",
            "      1,612,637 100%    3.96MB/s    0:00:00 (xfr#104, to-chk=325/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/README.md\n",
            "          5,087 100%   12.80kB/s    0:00:00 (xfr#105, to-chk=324/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/adapter_config.json\n",
            "            843 100%    2.12kB/s    0:00:00 (xfr#106, to-chk=323/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/adapter_model.safetensors\n",
            "    262,219,392 100%   16.30MB/s    0:00:15 (xfr#107, to-chk=322/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/merges.txt\n",
            "        916,646 100%    6.07MB/s    0:00:00 (xfr#108, to-chk=321/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/optimizer.pt\n",
            "    133,785,108 100%   15.94MB/s    0:00:08 (xfr#109, to-chk=320/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/rng_state.pth\n",
            "         14,244 100%   15.63kB/s    0:00:00 (xfr#110, to-chk=319/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/scheduler.pt\n",
            "          1,064 100%    1.17kB/s    0:00:00 (xfr#111, to-chk=318/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/special_tokens_map.json\n",
            "            456 100%    0.50kB/s    0:00:00 (xfr#112, to-chk=317/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/tokenizer.json\n",
            "      7,153,264 100%    7.34MB/s    0:00:00 (xfr#113, to-chk=316/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/tokenizer_config.json\n",
            "         17,987 100%   18.89kB/s    0:00:00 (xfr#114, to-chk=315/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/trainer_state.json\n",
            "         16,369 100%   17.19kB/s    0:00:00 (xfr#115, to-chk=314/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/training_args.bin\n",
            "          5,304 100%    5.57kB/s    0:00:00 (xfr#116, to-chk=313/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/vocab.json\n",
            "      1,612,637 100%    1.51MB/s    0:00:01 (xfr#117, to-chk=312/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/README.md\n",
            "          5,087 100%  993.55kB/s    0:00:00 (xfr#118, to-chk=311/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/adapter_config.json\n",
            "            843 100%  164.65kB/s    0:00:00 (xfr#119, to-chk=310/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/adapter_model.safetensors\n",
            "    262,219,392 100%   16.71MB/s    0:00:14 (xfr#120, to-chk=309/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/merges.txt\n",
            "        916,646 100%    1.11MB/s    0:00:00 (xfr#121, to-chk=308/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/optimizer.pt\n",
            "    133,785,108 100%   15.24MB/s    0:00:08 (xfr#122, to-chk=307/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/rng_state.pth\n",
            "         14,244 100%   53.09kB/s    0:00:00 (xfr#123, to-chk=306/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/scheduler.pt\n",
            "          1,064 100%    3.97kB/s    0:00:00 (xfr#124, to-chk=305/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/special_tokens_map.json\n",
            "            456 100%    1.70kB/s    0:00:00 (xfr#125, to-chk=304/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/tokenizer.json\n",
            "      7,153,264 100%   17.77MB/s    0:00:00 (xfr#126, to-chk=303/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/tokenizer_config.json\n",
            "         17,987 100%   45.62kB/s    0:00:00 (xfr#127, to-chk=302/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/trainer_state.json\n",
            "         17,283 100%   43.84kB/s    0:00:00 (xfr#128, to-chk=301/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/training_args.bin\n",
            "          5,304 100%   13.45kB/s    0:00:00 (xfr#129, to-chk=300/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/vocab.json\n",
            "      1,612,637 100%    3.79MB/s    0:00:00 (xfr#130, to-chk=299/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/README.md\n",
            "          5,087 100%   12.24kB/s    0:00:00 (xfr#131, to-chk=298/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/adapter_config.json\n",
            "            843 100%    2.03kB/s    0:00:00 (xfr#132, to-chk=297/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/adapter_model.safetensors\n",
            "    262,219,392 100%   16.30MB/s    0:00:15 (xfr#133, to-chk=296/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/merges.txt\n",
            "        916,646 100%    5.87MB/s    0:00:00 (xfr#134, to-chk=295/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/optimizer.pt\n",
            "    133,785,108 100%   16.48MB/s    0:00:07 (xfr#135, to-chk=294/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/rng_state.pth\n",
            "         14,244 100%   21.77kB/s    0:00:00 (xfr#136, to-chk=293/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/scheduler.pt\n",
            "          1,064 100%    1.63kB/s    0:00:00 (xfr#137, to-chk=292/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/special_tokens_map.json\n",
            "            456 100%    0.70kB/s    0:00:00 (xfr#138, to-chk=291/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/tokenizer.json\n",
            "      7,153,264 100%    8.96MB/s    0:00:00 (xfr#139, to-chk=290/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/tokenizer_config.json\n",
            "         17,987 100%   23.08kB/s    0:00:00 (xfr#140, to-chk=289/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/trainer_state.json\n",
            "         18,193 100%   23.32kB/s    0:00:00 (xfr#141, to-chk=288/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/training_args.bin\n",
            "          5,304 100%    6.80kB/s    0:00:00 (xfr#142, to-chk=287/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/vocab.json\n",
            "      1,612,637 100%    1.96MB/s    0:00:00 (xfr#143, to-chk=286/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/README.md\n",
            "          5,087 100%    6.34kB/s    0:00:00 (xfr#144, to-chk=285/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/adapter_config.json\n",
            "            843 100%    1.05kB/s    0:00:00 (xfr#145, to-chk=284/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/adapter_model.safetensors\n",
            "    262,219,392 100%   15.62MB/s    0:00:16 (xfr#146, to-chk=283/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/merges.txt\n",
            "        916,646 100%    1.06MB/s    0:00:00 (xfr#147, to-chk=282/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/optimizer.pt\n",
            "    133,784,532 100%   15.14MB/s    0:00:08 (xfr#148, to-chk=281/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/rng_state.pth\n",
            "         14,244 100%   50.58kB/s    0:00:00 (xfr#149, to-chk=280/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/scheduler.pt\n",
            "          1,064 100%    3.78kB/s    0:00:00 (xfr#150, to-chk=279/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/special_tokens_map.json\n",
            "            456 100%    1.62kB/s    0:00:00 (xfr#151, to-chk=278/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/tokenizer.json\n",
            "      7,153,264 100%   15.86MB/s    0:00:00 (xfr#152, to-chk=277/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/tokenizer_config.json\n",
            "         17,987 100%   40.85kB/s    0:00:00 (xfr#153, to-chk=276/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/trainer_state.json\n",
            "          2,702 100%    6.14kB/s    0:00:00 (xfr#154, to-chk=275/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/training_args.bin\n",
            "          5,304 100%   12.05kB/s    0:00:00 (xfr#155, to-chk=274/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/vocab.json\n",
            "      1,612,637 100%    3.36MB/s    0:00:00 (xfr#156, to-chk=273/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/README.md\n",
            "          5,087 100%   10.85kB/s    0:00:00 (xfr#157, to-chk=272/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/adapter_config.json\n",
            "            843 100%    1.80kB/s    0:00:00 (xfr#158, to-chk=271/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/adapter_model.safetensors\n",
            "    262,219,392 100%   16.26MB/s    0:00:15 (xfr#159, to-chk=270/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/merges.txt\n",
            "        916,646 100%    3.43MB/s    0:00:00 (xfr#160, to-chk=269/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/optimizer.pt\n",
            "    133,785,108 100%   16.46MB/s    0:00:07 (xfr#161, to-chk=268/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/rng_state.pth\n",
            "         14,244 100%   21.50kB/s    0:00:00 (xfr#162, to-chk=267/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/scheduler.pt\n",
            "          1,064 100%    1.61kB/s    0:00:00 (xfr#163, to-chk=266/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/special_tokens_map.json\n",
            "            456 100%    0.69kB/s    0:00:00 (xfr#164, to-chk=265/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/tokenizer.json\n",
            "      7,153,264 100%    8.72MB/s    0:00:00 (xfr#165, to-chk=264/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/tokenizer_config.json\n",
            "         17,987 100%   22.46kB/s    0:00:00 (xfr#166, to-chk=263/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/trainer_state.json\n",
            "         19,106 100%   23.86kB/s    0:00:00 (xfr#167, to-chk=262/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/training_args.bin\n",
            "          5,304 100%    6.62kB/s    0:00:00 (xfr#168, to-chk=261/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/vocab.json\n",
            "      1,612,637 100%    1.91MB/s    0:00:00 (xfr#169, to-chk=260/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/README.md\n",
            "          5,087 100%    6.18kB/s    0:00:00 (xfr#170, to-chk=259/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/adapter_config.json\n",
            "            843 100%    1.02kB/s    0:00:00 (xfr#171, to-chk=258/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/adapter_model.safetensors\n",
            "    262,219,392 100%   15.79MB/s    0:00:15 (xfr#172, to-chk=257/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/merges.txt\n",
            "        916,646 100%    1.35MB/s    0:00:00 (xfr#173, to-chk=256/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/optimizer.pt\n",
            "    133,785,108 100%   15.67MB/s    0:00:08 (xfr#174, to-chk=255/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/rng_state.pth\n",
            "         14,244 100%  448.71kB/s    0:00:00 (xfr#175, to-chk=254/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/scheduler.pt\n",
            "          1,064 100%   33.52kB/s    0:00:00 (xfr#176, to-chk=253/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/special_tokens_map.json\n",
            "            456 100%   14.36kB/s    0:00:00 (xfr#177, to-chk=252/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/tokenizer.json\n",
            "      7,153,264 100%   42.11MB/s    0:00:00 (xfr#178, to-chk=251/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/tokenizer_config.json\n",
            "         17,987 100%  108.43kB/s    0:00:00 (xfr#179, to-chk=250/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/trainer_state.json\n",
            "         20,015 100%  120.65kB/s    0:00:00 (xfr#180, to-chk=249/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/training_args.bin\n",
            "          5,304 100%   31.97kB/s    0:00:00 (xfr#181, to-chk=248/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/vocab.json\n",
            "      1,612,637 100%    8.40MB/s    0:00:00 (xfr#182, to-chk=247/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/README.md\n",
            "          5,087 100%   19.71kB/s    0:00:00 (xfr#183, to-chk=246/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/adapter_config.json\n",
            "            843 100%    3.27kB/s    0:00:00 (xfr#184, to-chk=245/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/adapter_model.safetensors\n",
            "    262,219,392 100%   16.27MB/s    0:00:15 (xfr#185, to-chk=244/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/merges.txt\n",
            "        916,646 100%    3.39MB/s    0:00:00 (xfr#186, to-chk=243/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/optimizer.pt\n",
            "    133,785,108 100%   16.25MB/s    0:00:07 (xfr#187, to-chk=242/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/rng_state.pth\n",
            "         14,244 100%   18.23kB/s    0:00:00 (xfr#188, to-chk=241/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/scheduler.pt\n",
            "          1,064 100%    1.36kB/s    0:00:00 (xfr#189, to-chk=240/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/special_tokens_map.json\n",
            "            456 100%    0.58kB/s    0:00:00 (xfr#190, to-chk=239/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/tokenizer.json\n",
            "      7,153,264 100%    8.50MB/s    0:00:00 (xfr#191, to-chk=238/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/tokenizer_config.json\n",
            "         17,987 100%   21.87kB/s    0:00:00 (xfr#192, to-chk=237/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/trainer_state.json\n",
            "         20,928 100%   25.45kB/s    0:00:00 (xfr#193, to-chk=236/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/training_args.bin\n",
            "          5,304 100%    6.45kB/s    0:00:00 (xfr#194, to-chk=235/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/vocab.json\n",
            "      1,612,637 100%    1.72MB/s    0:00:00 (xfr#195, to-chk=234/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/README.md\n",
            "          5,087 100%    5.55kB/s    0:00:00 (xfr#196, to-chk=233/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/adapter_config.json\n",
            "            843 100%    0.92kB/s    0:00:00 (xfr#197, to-chk=232/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/adapter_model.safetensors\n",
            "    262,219,392 100%   15.79MB/s    0:00:15 (xfr#198, to-chk=231/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/merges.txt\n",
            "        916,646 100%    1.33MB/s    0:00:00 (xfr#199, to-chk=230/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/optimizer.pt\n",
            "    133,785,108 100%   15.48MB/s    0:00:08 (xfr#200, to-chk=229/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/rng_state.pth\n",
            "         14,244 100%  103.04kB/s    0:00:00 (xfr#201, to-chk=228/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/scheduler.pt\n",
            "          1,064 100%    7.70kB/s    0:00:00 (xfr#202, to-chk=227/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/special_tokens_map.json\n",
            "            456 100%    3.30kB/s    0:00:00 (xfr#203, to-chk=226/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/tokenizer.json\n",
            "      7,153,264 100%   25.94MB/s    0:00:00 (xfr#204, to-chk=225/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/tokenizer_config.json\n",
            "         17,987 100%   66.79kB/s    0:00:00 (xfr#205, to-chk=224/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/trainer_state.json\n",
            "         21,845 100%   80.81kB/s    0:00:00 (xfr#206, to-chk=223/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/training_args.bin\n",
            "          5,304 100%   19.62kB/s    0:00:00 (xfr#207, to-chk=222/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/vocab.json\n",
            "      1,612,637 100%    5.40MB/s    0:00:00 (xfr#208, to-chk=221/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/README.md\n",
            "          5,087 100%   17.43kB/s    0:00:00 (xfr#209, to-chk=220/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/adapter_config.json\n",
            "            843 100%    2.89kB/s    0:00:00 (xfr#210, to-chk=219/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/adapter_model.safetensors\n",
            "    262,219,392 100%   16.44MB/s    0:00:15 (xfr#211, to-chk=218/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/merges.txt\n",
            "        916,646 100%    6.78MB/s    0:00:00 (xfr#212, to-chk=217/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/optimizer.pt\n",
            "    133,785,108 100%   16.74MB/s    0:00:07 (xfr#213, to-chk=216/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/rng_state.pth\n",
            "         14,244 100%   26.60kB/s    0:00:00 (xfr#214, to-chk=215/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/scheduler.pt\n",
            "          1,064 100%    1.99kB/s    0:00:00 (xfr#215, to-chk=214/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/special_tokens_map.json\n",
            "            456 100%    0.85kB/s    0:00:00 (xfr#216, to-chk=213/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/tokenizer.json\n",
            "      7,153,264 100%   10.20MB/s    0:00:00 (xfr#217, to-chk=212/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/tokenizer_config.json\n",
            "         17,987 100%   26.26kB/s    0:00:00 (xfr#218, to-chk=211/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/trainer_state.json\n",
            "         22,760 100%   33.22kB/s    0:00:00 (xfr#219, to-chk=210/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/training_args.bin\n",
            "          5,304 100%    7.74kB/s    0:00:00 (xfr#220, to-chk=209/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/vocab.json\n",
            "      1,612,637 100%    2.23MB/s    0:00:00 (xfr#221, to-chk=208/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/README.md\n",
            "          5,087 100%    6.53kB/s    0:00:00 (xfr#222, to-chk=207/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/adapter_config.json\n",
            "            843 100%    1.08kB/s    0:00:00 (xfr#223, to-chk=206/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/adapter_model.safetensors\n",
            "    262,219,392 100%   15.74MB/s    0:00:15 (xfr#224, to-chk=205/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/merges.txt\n",
            "        916,646 100%    1.35MB/s    0:00:00 (xfr#225, to-chk=204/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/optimizer.pt\n",
            "    133,785,108 100%   15.49MB/s    0:00:08 (xfr#226, to-chk=203/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/rng_state.pth\n",
            "         14,244 100%  109.53kB/s    0:00:00 (xfr#227, to-chk=202/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/scheduler.pt\n",
            "          1,064 100%    8.18kB/s    0:00:00 (xfr#228, to-chk=201/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/special_tokens_map.json\n",
            "            456 100%    3.51kB/s    0:00:00 (xfr#229, to-chk=200/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/tokenizer.json\n",
            "      7,153,264 100%   40.61MB/s    0:00:00 (xfr#230, to-chk=199/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/tokenizer_config.json\n",
            "         17,987 100%  104.56kB/s    0:00:00 (xfr#231, to-chk=198/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/trainer_state.json\n",
            "         23,674 100%  137.61kB/s    0:00:00 (xfr#232, to-chk=197/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/training_args.bin\n",
            "          5,304 100%   30.83kB/s    0:00:00 (xfr#233, to-chk=196/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/vocab.json\n",
            "      1,612,637 100%    5.98MB/s    0:00:00 (xfr#234, to-chk=195/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/README.md\n",
            "          5,087 100%   19.33kB/s    0:00:00 (xfr#235, to-chk=194/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/adapter_config.json\n",
            "            843 100%    3.20kB/s    0:00:00 (xfr#236, to-chk=193/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/adapter_model.safetensors\n",
            "    262,219,392 100%   16.44MB/s    0:00:15 (xfr#237, to-chk=192/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/merges.txt\n",
            "        916,646 100%   38.01MB/s    0:00:00 (xfr#238, to-chk=191/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/optimizer.pt\n",
            "    133,785,108 100%   16.76MB/s    0:00:07 (xfr#239, to-chk=190/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/rng_state.pth\n",
            "         14,244 100%   26.55kB/s    0:00:00 (xfr#240, to-chk=189/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/scheduler.pt\n",
            "          1,064 100%    1.98kB/s    0:00:00 (xfr#241, to-chk=188/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/special_tokens_map.json\n",
            "            456 100%    0.85kB/s    0:00:00 (xfr#242, to-chk=187/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/tokenizer.json\n",
            "      7,153,264 100%   10.43MB/s    0:00:00 (xfr#243, to-chk=186/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/tokenizer_config.json\n",
            "         17,987 100%   26.86kB/s    0:00:00 (xfr#244, to-chk=185/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/trainer_state.json\n",
            "         24,583 100%   36.71kB/s    0:00:00 (xfr#245, to-chk=184/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/training_args.bin\n",
            "          5,304 100%    7.92kB/s    0:00:00 (xfr#246, to-chk=183/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/vocab.json\n",
            "      1,612,637 100%    2.28MB/s    0:00:00 (xfr#247, to-chk=182/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/README.md\n",
            "          5,087 100%    7.36kB/s    0:00:00 (xfr#248, to-chk=181/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/adapter_config.json\n",
            "            843 100%    1.22kB/s    0:00:00 (xfr#249, to-chk=180/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/adapter_model.safetensors\n",
            "    262,219,392 100%   16.02MB/s    0:00:15 (xfr#250, to-chk=179/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/merges.txt\n",
            "        916,646 100%    1.70MB/s    0:00:00 (xfr#251, to-chk=178/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/optimizer.pt\n",
            "    133,785,108 100%   15.73MB/s    0:00:08 (xfr#252, to-chk=177/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/rng_state.pth\n",
            "         14,244 100%   13.58MB/s    0:00:00 (xfr#253, to-chk=176/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/scheduler.pt\n",
            "          1,064 100%    1.01MB/s    0:00:00 (xfr#254, to-chk=175/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/special_tokens_map.json\n",
            "            456 100%  445.31kB/s    0:00:00 (xfr#255, to-chk=174/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/tokenizer.json\n",
            "      7,153,264 100%  170.55MB/s    0:00:00 (xfr#256, to-chk=173/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/tokenizer_config.json\n",
            "         17,987 100%  439.14kB/s    0:00:00 (xfr#257, to-chk=172/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/trainer_state.json\n",
            "         25,496 100%  622.46kB/s    0:00:00 (xfr#258, to-chk=171/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/training_args.bin\n",
            "          5,304 100%  126.33kB/s    0:00:00 (xfr#259, to-chk=170/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/vocab.json\n",
            "      1,612,637 100%   11.92MB/s    0:00:00 (xfr#260, to-chk=169/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/README.md\n",
            "          5,087 100%   38.51kB/s    0:00:00 (xfr#261, to-chk=168/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/adapter_config.json\n",
            "            843 100%    6.38kB/s    0:00:00 (xfr#262, to-chk=167/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/adapter_model.safetensors\n",
            "    262,219,392 100%   16.39MB/s    0:00:15 (xfr#263, to-chk=166/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/merges.txt\n",
            "        916,646 100%   54.64MB/s    0:00:00 (xfr#264, to-chk=165/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/optimizer.pt\n",
            "    133,785,108 100%   16.77MB/s    0:00:07 (xfr#265, to-chk=164/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/rng_state.pth\n",
            "         14,244 100%   27.33kB/s    0:00:00 (xfr#266, to-chk=163/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/scheduler.pt\n",
            "          1,064 100%    2.04kB/s    0:00:00 (xfr#267, to-chk=162/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/special_tokens_map.json\n",
            "            456 100%    0.87kB/s    0:00:00 (xfr#268, to-chk=161/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/tokenizer.json\n",
            "      7,153,264 100%   12.40MB/s    0:00:00 (xfr#269, to-chk=160/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/tokenizer_config.json\n",
            "         17,987 100%   31.94kB/s    0:00:00 (xfr#270, to-chk=159/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/trainer_state.json\n",
            "         26,409 100%   46.89kB/s    0:00:00 (xfr#271, to-chk=158/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/training_args.bin\n",
            "          5,304 100%    9.42kB/s    0:00:00 (xfr#272, to-chk=157/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/vocab.json\n",
            "      1,612,637 100%    2.38MB/s    0:00:00 (xfr#273, to-chk=156/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/README.md\n",
            "          5,087 100%    7.69kB/s    0:00:00 (xfr#274, to-chk=155/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/adapter_config.json\n",
            "            843 100%    1.27kB/s    0:00:00 (xfr#275, to-chk=154/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/adapter_model.safetensors\n",
            "    262,219,392 100%   16.04MB/s    0:00:15 (xfr#276, to-chk=153/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/merges.txt\n",
            "        916,646 100%    2.19MB/s    0:00:00 (xfr#277, to-chk=152/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/optimizer.pt\n",
            "    133,785,108 100%   15.96MB/s    0:00:07 (xfr#278, to-chk=151/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/rng_state.pth\n",
            "         14,244 100%   15.58kB/s    0:00:00 (xfr#279, to-chk=150/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/scheduler.pt\n",
            "          1,064 100%    1.16kB/s    0:00:00 (xfr#280, to-chk=149/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/special_tokens_map.json\n",
            "            456 100%    0.50kB/s    0:00:00 (xfr#281, to-chk=148/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/tokenizer.json\n",
            "      7,153,264 100%    6.73MB/s    0:00:01 (xfr#282, to-chk=147/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/tokenizer_config.json\n",
            "         17,987 100%    5.72MB/s    0:00:00 (xfr#283, to-chk=146/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/trainer_state.json\n",
            "         27,322 100%    8.69MB/s    0:00:00 (xfr#284, to-chk=145/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/training_args.bin\n",
            "          5,304 100%    1.69MB/s    0:00:00 (xfr#285, to-chk=144/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/vocab.json\n",
            "      1,612,637 100%   61.52MB/s    0:00:00 (xfr#286, to-chk=143/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/README.md\n",
            "          5,087 100%  198.71kB/s    0:00:00 (xfr#287, to-chk=142/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/adapter_config.json\n",
            "            843 100%   31.66kB/s    0:00:00 (xfr#288, to-chk=141/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/adapter_model.safetensors\n",
            "    262,219,392 100%   16.65MB/s    0:00:15 (xfr#289, to-chk=140/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/merges.txt\n",
            "        916,646 100% 1006.93kB/s    0:00:00 (xfr#290, to-chk=139/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/optimizer.pt\n",
            "    133,785,108 100%   15.04MB/s    0:00:08 (xfr#291, to-chk=138/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/rng_state.pth\n",
            "         14,244 100%   36.61kB/s    0:00:00 (xfr#292, to-chk=137/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/scheduler.pt\n",
            "          1,064 100%    2.73kB/s    0:00:00 (xfr#293, to-chk=136/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/special_tokens_map.json\n",
            "            456 100%    1.17kB/s    0:00:00 (xfr#294, to-chk=135/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/tokenizer.json\n",
            "      7,153,264 100%   13.70MB/s    0:00:00 (xfr#295, to-chk=134/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/tokenizer_config.json\n",
            "         17,987 100%   35.27kB/s    0:00:00 (xfr#296, to-chk=133/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/trainer_state.json\n",
            "          3,613 100%    7.08kB/s    0:00:00 (xfr#297, to-chk=132/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/training_args.bin\n",
            "          5,304 100%   10.40kB/s    0:00:00 (xfr#298, to-chk=131/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/vocab.json\n",
            "      1,612,637 100%    2.91MB/s    0:00:00 (xfr#299, to-chk=130/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/README.md\n",
            "          5,087 100%    9.41kB/s    0:00:00 (xfr#300, to-chk=129/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/adapter_config.json\n",
            "            843 100%    1.56kB/s    0:00:00 (xfr#301, to-chk=128/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/adapter_model.safetensors\n",
            "    262,219,392 100%   15.84MB/s    0:00:15 (xfr#302, to-chk=127/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/merges.txt\n",
            "        916,646 100%    1.35MB/s    0:00:00 (xfr#303, to-chk=126/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/optimizer.pt\n",
            "    133,785,108 100%   15.48MB/s    0:00:08 (xfr#304, to-chk=125/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/rng_state.pth\n",
            "         14,244 100%  108.67kB/s    0:00:00 (xfr#305, to-chk=124/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/scheduler.pt\n",
            "          1,064 100%    8.12kB/s    0:00:00 (xfr#306, to-chk=123/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/special_tokens_map.json\n",
            "            456 100%    3.48kB/s    0:00:00 (xfr#307, to-chk=122/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/tokenizer.json\n",
            "      7,153,264 100%   40.61MB/s    0:00:00 (xfr#308, to-chk=121/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/tokenizer_config.json\n",
            "         17,987 100%  104.56kB/s    0:00:00 (xfr#309, to-chk=120/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/trainer_state.json\n",
            "         28,231 100%  164.10kB/s    0:00:00 (xfr#310, to-chk=119/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/training_args.bin\n",
            "          5,304 100%   30.83kB/s    0:00:00 (xfr#311, to-chk=118/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/vocab.json\n",
            "      1,612,637 100%    5.87MB/s    0:00:00 (xfr#312, to-chk=117/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/README.md\n",
            "          5,087 100%   18.96kB/s    0:00:00 (xfr#313, to-chk=116/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/adapter_config.json\n",
            "            843 100%    3.14kB/s    0:00:00 (xfr#314, to-chk=115/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/adapter_model.safetensors\n",
            "    262,219,392 100%   16.44MB/s    0:00:15 (xfr#315, to-chk=114/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/merges.txt\n",
            "        916,646 100%   58.28MB/s    0:00:00 (xfr#316, to-chk=113/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/optimizer.pt\n",
            "    133,785,108 100%   16.78MB/s    0:00:07 (xfr#317, to-chk=112/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/rng_state.pth\n",
            "         14,244 100%   27.33kB/s    0:00:00 (xfr#318, to-chk=111/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/scheduler.pt\n",
            "          1,064 100%    2.04kB/s    0:00:00 (xfr#319, to-chk=110/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/special_tokens_map.json\n",
            "            456 100%    0.87kB/s    0:00:00 (xfr#320, to-chk=109/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/tokenizer.json\n",
            "      7,153,264 100%   12.43MB/s    0:00:00 (xfr#321, to-chk=108/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/tokenizer_config.json\n",
            "         17,987 100%   32.00kB/s    0:00:00 (xfr#322, to-chk=107/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/trainer_state.json\n",
            "         29,148 100%   51.85kB/s    0:00:00 (xfr#323, to-chk=106/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/training_args.bin\n",
            "          5,304 100%    9.43kB/s    0:00:00 (xfr#324, to-chk=105/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/vocab.json\n",
            "      1,612,637 100%    2.40MB/s    0:00:00 (xfr#325, to-chk=104/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/README.md\n",
            "          5,087 100%    7.75kB/s    0:00:00 (xfr#326, to-chk=103/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/adapter_config.json\n",
            "            843 100%    1.28kB/s    0:00:00 (xfr#327, to-chk=102/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/adapter_model.safetensors\n",
            "    262,219,392 100%   16.15MB/s    0:00:15 (xfr#328, to-chk=101/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/merges.txt\n",
            "        916,646 100%    2.25MB/s    0:00:00 (xfr#329, to-chk=100/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/optimizer.pt\n",
            "    133,785,108 100%   16.22MB/s    0:00:07 (xfr#330, to-chk=99/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/rng_state.pth\n",
            "         14,244 100%   17.97kB/s    0:00:00 (xfr#331, to-chk=98/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/scheduler.pt\n",
            "          1,064 100%    1.34kB/s    0:00:00 (xfr#332, to-chk=97/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/special_tokens_map.json\n",
            "            456 100%    0.58kB/s    0:00:00 (xfr#333, to-chk=96/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/tokenizer.json\n",
            "      7,153,264 100%    7.45MB/s    0:00:00 (xfr#334, to-chk=95/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/tokenizer_config.json\n",
            "         17,987 100%   19.16kB/s    0:00:00 (xfr#335, to-chk=94/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/trainer_state.json\n",
            "         30,062 100%   32.01kB/s    0:00:00 (xfr#336, to-chk=93/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/training_args.bin\n",
            "          5,304 100%    5.65kB/s    0:00:00 (xfr#337, to-chk=92/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/vocab.json\n",
            "      1,612,637 100%    1.64MB/s    0:00:00 (xfr#338, to-chk=91/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/README.md\n",
            "          5,087 100%    5.30kB/s    0:00:00 (xfr#339, to-chk=90/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/adapter_config.json\n",
            "            843 100%    0.88kB/s    0:00:00 (xfr#340, to-chk=89/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/adapter_model.safetensors\n",
            "    262,219,392 100%   15.41MB/s    0:00:16 (xfr#341, to-chk=88/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/merges.txt\n",
            "        916,646 100%   72.85MB/s    0:00:00 (xfr#342, to-chk=87/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/optimizer.pt\n",
            "    133,785,108 100%   17.04MB/s    0:00:07 (xfr#343, to-chk=86/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/rng_state.pth\n",
            "         14,244 100%   34.95kB/s    0:00:00 (xfr#344, to-chk=85/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/scheduler.pt\n",
            "          1,064 100%    2.61kB/s    0:00:00 (xfr#345, to-chk=84/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/special_tokens_map.json\n",
            "            456 100%    1.12kB/s    0:00:00 (xfr#346, to-chk=83/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/tokenizer.json\n",
            "      7,153,264 100%   12.54MB/s    0:00:00 (xfr#347, to-chk=82/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/tokenizer_config.json\n",
            "         17,987 100%   32.29kB/s    0:00:00 (xfr#348, to-chk=81/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/trainer_state.json\n",
            "         30,397 100%   54.57kB/s    0:00:00 (xfr#349, to-chk=80/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/training_args.bin\n",
            "          5,304 100%    9.52kB/s    0:00:00 (xfr#350, to-chk=79/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/vocab.json\n",
            "      1,612,637 100%    2.43MB/s    0:00:00 (xfr#351, to-chk=78/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/README.md\n",
            "          5,087 100%    7.81kB/s    0:00:00 (xfr#352, to-chk=77/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/adapter_config.json\n",
            "            843 100%    1.29kB/s    0:00:00 (xfr#353, to-chk=76/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/adapter_model.safetensors\n",
            "    262,219,392 100%   16.04MB/s    0:00:15 (xfr#354, to-chk=75/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/merges.txt\n",
            "        916,646 100%    2.15MB/s    0:00:00 (xfr#355, to-chk=74/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/optimizer.pt\n",
            "    133,785,108 100%   15.96MB/s    0:00:07 (xfr#356, to-chk=73/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/rng_state.pth\n",
            "         14,244 100%   15.46kB/s    0:00:00 (xfr#357, to-chk=72/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/scheduler.pt\n",
            "          1,064 100%    1.15kB/s    0:00:00 (xfr#358, to-chk=71/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/special_tokens_map.json\n",
            "            456 100%    0.49kB/s    0:00:00 (xfr#359, to-chk=70/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/tokenizer.json\n",
            "      7,153,264 100%    6.66MB/s    0:00:01 (xfr#360, to-chk=69/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/tokenizer_config.json\n",
            "         17,987 100%    1.56MB/s    0:00:00 (xfr#361, to-chk=68/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/trainer_state.json\n",
            "          4,526 100%  401.81kB/s    0:00:00 (xfr#362, to-chk=67/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/training_args.bin\n",
            "          5,304 100%  470.88kB/s    0:00:00 (xfr#363, to-chk=66/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/vocab.json\n",
            "      1,612,637 100%   38.45MB/s    0:00:00 (xfr#364, to-chk=65/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/README.md\n",
            "          5,087 100%  118.28kB/s    0:00:00 (xfr#365, to-chk=64/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/adapter_config.json\n",
            "            843 100%   19.60kB/s    0:00:00 (xfr#366, to-chk=63/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/adapter_model.safetensors\n",
            "    262,219,392 100%   16.69MB/s    0:00:14 (xfr#367, to-chk=62/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/merges.txt\n",
            "        916,646 100% 1003.54kB/s    0:00:00 (xfr#368, to-chk=61/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/optimizer.pt\n",
            "    133,785,108 100%   15.03MB/s    0:00:08 (xfr#369, to-chk=60/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/rng_state.pth\n",
            "         14,244 100%   36.04kB/s    0:00:00 (xfr#370, to-chk=59/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/scheduler.pt\n",
            "          1,064 100%    2.69kB/s    0:00:00 (xfr#371, to-chk=58/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/special_tokens_map.json\n",
            "            456 100%    1.15kB/s    0:00:00 (xfr#372, to-chk=57/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/tokenizer.json\n",
            "      7,153,264 100%   15.30MB/s    0:00:00 (xfr#373, to-chk=56/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/tokenizer_config.json\n",
            "         17,987 100%   39.38kB/s    0:00:00 (xfr#374, to-chk=55/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/trainer_state.json\n",
            "          5,430 100%   11.89kB/s    0:00:00 (xfr#375, to-chk=54/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/training_args.bin\n",
            "          5,304 100%   11.59kB/s    0:00:00 (xfr#376, to-chk=53/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/vocab.json\n",
            "      1,612,637 100%    2.95MB/s    0:00:00 (xfr#377, to-chk=52/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/README.md\n",
            "          5,087 100%    9.52kB/s    0:00:00 (xfr#378, to-chk=51/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/adapter_config.json\n",
            "            843 100%    1.58kB/s    0:00:00 (xfr#379, to-chk=50/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/adapter_model.safetensors\n",
            "    262,219,392 100%   15.97MB/s    0:00:15 (xfr#380, to-chk=49/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/merges.txt\n",
            "        916,646 100%    1.71MB/s    0:00:00 (xfr#381, to-chk=48/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/optimizer.pt\n",
            "    133,785,108 100%   15.74MB/s    0:00:08 (xfr#382, to-chk=47/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/rng_state.pth\n",
            "         14,244 100%    3.40MB/s    0:00:00 (xfr#383, to-chk=46/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/scheduler.pt\n",
            "          1,064 100%  259.77kB/s    0:00:00 (xfr#384, to-chk=45/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/special_tokens_map.json\n",
            "            456 100%  111.33kB/s    0:00:00 (xfr#385, to-chk=44/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/tokenizer.json\n",
            "      7,153,264 100%   98.87MB/s    0:00:00 (xfr#386, to-chk=43/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/tokenizer_config.json\n",
            "         17,987 100%  254.57kB/s    0:00:00 (xfr#387, to-chk=42/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/trainer_state.json\n",
            "          6,338 100%   88.42kB/s    0:00:00 (xfr#388, to-chk=41/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/training_args.bin\n",
            "          5,304 100%   74.00kB/s    0:00:00 (xfr#389, to-chk=40/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/vocab.json\n",
            "      1,612,637 100%   10.99MB/s    0:00:00 (xfr#390, to-chk=39/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/README.md\n",
            "          5,087 100%   35.23kB/s    0:00:00 (xfr#391, to-chk=38/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/adapter_config.json\n",
            "            843 100%    5.84kB/s    0:00:00 (xfr#392, to-chk=37/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/adapter_model.safetensors\n",
            "    262,219,392 100%   16.58MB/s    0:00:15 (xfr#393, to-chk=36/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/merges.txt\n",
            "        916,646 100%  976.19kB/s    0:00:00 (xfr#394, to-chk=35/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/optimizer.pt\n",
            "    133,785,108 100%   15.01MB/s    0:00:08 (xfr#395, to-chk=34/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/rng_state.pth\n",
            "         14,244 100%   34.95kB/s    0:00:00 (xfr#396, to-chk=33/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/scheduler.pt\n",
            "          1,064 100%    2.61kB/s    0:00:00 (xfr#397, to-chk=32/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/special_tokens_map.json\n",
            "            456 100%    1.12kB/s    0:00:00 (xfr#398, to-chk=31/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/tokenizer.json\n",
            "      7,153,264 100%   12.82MB/s    0:00:00 (xfr#399, to-chk=30/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/tokenizer_config.json\n",
            "         17,987 100%   33.02kB/s    0:00:00 (xfr#400, to-chk=29/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/trainer_state.json\n",
            "          7,248 100%   13.30kB/s    0:00:00 (xfr#401, to-chk=28/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/training_args.bin\n",
            "          5,304 100%    9.74kB/s    0:00:00 (xfr#402, to-chk=27/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/vocab.json\n",
            "      1,612,637 100%    2.75MB/s    0:00:00 (xfr#403, to-chk=26/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/README.md\n",
            "          5,087 100%    8.84kB/s    0:00:00 (xfr#404, to-chk=25/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/adapter_config.json\n",
            "            843 100%    1.46kB/s    0:00:00 (xfr#405, to-chk=24/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/adapter_model.safetensors\n",
            "    262,219,392 100%   16.15MB/s    0:00:15 (xfr#406, to-chk=23/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/merges.txt\n",
            "        916,646 100%    2.22MB/s    0:00:00 (xfr#407, to-chk=22/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/optimizer.pt\n",
            "    133,785,108 100%   16.18MB/s    0:00:07 (xfr#408, to-chk=21/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/rng_state.pth\n",
            "         14,244 100%   17.43kB/s    0:00:00 (xfr#409, to-chk=20/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/scheduler.pt\n",
            "          1,064 100%    1.30kB/s    0:00:00 (xfr#410, to-chk=19/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/special_tokens_map.json\n",
            "            456 100%    0.56kB/s    0:00:00 (xfr#411, to-chk=18/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/tokenizer.json\n",
            "      7,153,264 100%    7.22MB/s    0:00:00 (xfr#412, to-chk=17/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/tokenizer_config.json\n",
            "         17,987 100%   18.59kB/s    0:00:00 (xfr#413, to-chk=16/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/trainer_state.json\n",
            "          8,158 100%    8.43kB/s    0:00:00 (xfr#414, to-chk=15/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/training_args.bin\n",
            "          5,304 100%    5.48kB/s    0:00:00 (xfr#415, to-chk=14/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/vocab.json\n",
            "      1,612,637 100%    1.52MB/s    0:00:01 (xfr#416, to-chk=13/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/README.md\n",
            "          5,087 100%    1.62MB/s    0:00:00 (xfr#417, to-chk=12/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/adapter_config.json\n",
            "            843 100%  205.81kB/s    0:00:00 (xfr#418, to-chk=11/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/adapter_model.safetensors\n",
            "    262,219,392 100%   16.53MB/s    0:00:15 (xfr#419, to-chk=10/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/merges.txt\n",
            "        916,646 100%  873.33kB/s    0:00:01 (xfr#420, to-chk=9/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/optimizer.pt\n",
            "    133,785,108 100%   16.78MB/s    0:00:07 (xfr#421, to-chk=8/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/rng_state.pth\n",
            "         14,244 100%   27.12kB/s    0:00:00 (xfr#422, to-chk=7/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/scheduler.pt\n",
            "          1,064 100%    2.03kB/s    0:00:00 (xfr#423, to-chk=6/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/special_tokens_map.json\n",
            "            456 100%    0.87kB/s    0:00:00 (xfr#424, to-chk=5/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/tokenizer.json\n",
            "      7,153,264 100%   11.86MB/s    0:00:00 (xfr#425, to-chk=4/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/tokenizer_config.json\n",
            "         17,987 100%   30.50kB/s    0:00:00 (xfr#426, to-chk=3/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/trainer_state.json\n",
            "          9,063 100%   15.37kB/s    0:00:00 (xfr#427, to-chk=2/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/training_args.bin\n",
            "          5,304 100%    8.99kB/s    0:00:00 (xfr#428, to-chk=1/466)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/vocab.json\n",
            "      1,612,637 100%    2.36MB/s    0:00:00 (xfr#429, to-chk=0/466)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantize and convert"
      ],
      "metadata": {
        "id": "Kw5KsHGZiQPB"
      },
      "id": "Kw5KsHGZiQPB"
    },
    {
      "cell_type": "code",
      "source": [
        "peft_trainer.model.save_pretrained_gguf(\"fine-tuned/\" + RUN_CODE + \"/loadable\", tokenizer, quantization_method = [ \"f16\", \"q4_k_m\", \"q6_k\"])"
      ],
      "metadata": {
        "id": "89LgLZHqiRgP",
        "outputId": "0e7a58c3-669b-421e-aae2-300030253869",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "89LgLZHqiRgP",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n",
            "model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n",
            "Unsloth: Will remove a cached repo with size 29.3G\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 48.94 out of 83.48 RAM for saving.\n",
            "Unsloth: Saving model... This might take 5 minutes ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|â–ˆâ–Œ        | 6/40 [00:00<00:01, 23.26it/s]\n",
            "We will save to Disk and not RAM now.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:55<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Converting llama model. Can use fast conversion = False.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['f16', 'q4_k_m', 'q6_k'] might take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
            "Unsloth: CMAKE detected. Finalizing some steps for installation.\n",
            "Unsloth: [1] Converting model at fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable into f16 GGUF format.\n",
            "The output location will be /content/fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/unsloth.F16.gguf\n",
            "This might take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: loadable\n",
            "INFO:hf-to-gguf:Model architecture: LlamaForCausalLM\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00006.safetensors'\n",
            "INFO:hf-to-gguf:token_embd.weight,           torch.bfloat16 --> F16, shape = {5120, 100352}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00006.safetensors'\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00006.safetensors'\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00004-of-00006.safetensors'\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00005-of-00006.safetensors'\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.32.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.32.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.32.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.32.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.32.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.32.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.32.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.32.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.32.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.33.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.33.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.33.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.33.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.33.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.33.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.33.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.33.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.33.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.34.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.34.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.34.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.34.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.34.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.34.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00006-of-00006.safetensors'\n",
            "INFO:hf-to-gguf:output.weight,               torch.bfloat16 --> F16, shape = {5120, 100352}\n",
            "INFO:hf-to-gguf:blk.34.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.34.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.34.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.35.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.35.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.35.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.35.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.35.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.35.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.35.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.35.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.35.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.36.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.36.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.36.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.36.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.36.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.36.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.36.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.36.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.36.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.37.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.37.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.37.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.37.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.37.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.37.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.37.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.37.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.37.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.38.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.38.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.38.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.38.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.38.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.38.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.38.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.38.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.38.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.39.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.39.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.39.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.39.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.39.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.39.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.39.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.39.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.39.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:output_norm.weight,          torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 16384\n",
            "INFO:hf-to-gguf:gguf: embedding length = 5120\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 17920\n",
            "INFO:hf-to-gguf:gguf: head count = 40\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 10\n",
            "INFO:hf-to-gguf:gguf: rope theta = 250000\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
            "INFO:hf-to-gguf:gguf: file type = 1\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:numexpr.utils:NumExpr defaulting to 12 threads.\n",
            "INFO:hf-to-gguf:'Ã¯Â¿Â½' is encoded and decoded back to 'ï¿½' using AutoTokenizer\n",
            "INFO:gguf.vocab:Adding 100000 merge(s).\n",
            "INFO:gguf.vocab:Setting special token type bos to 100257\n",
            "INFO:gguf.vocab:Setting special token type eos to 100265\n",
            "INFO:gguf.vocab:Setting special token type unk to 5809\n",
            "INFO:gguf.vocab:Setting special token type pad to 100265\n",
            "INFO:gguf.vocab:Setting chat_template to {% for message in messages %}{% if (message['role'] == 'system') %}{{'<|im_start|>system<|im_sep|>' + message['content'] + '<|im_end|>'}}{% elif (message['role'] == 'user') %}{{'<|im_start|>user<|im_sep|>' + message['content'] + '<|im_end|>'}}{% elif (message['role'] == 'assistant') %}{{'<|im_start|>assistant<|im_sep|>' + message['content'] + '<|im_end|>'}}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant<|im_sep|>' }}{% endif %}\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/content/fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/unsloth.F16.gguf: n_tensors = 363, total_size = 29.3G\n",
            "Writing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29.3G/29.3G [04:05<00:00, 119Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to /content/fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/unsloth.F16.gguf\n",
            "Unsloth: Conversion completed! Output location: /content/fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/unsloth.F16.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This might take 20 minutes...\n",
            "main: build = 5409 (6aa892ec)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/unsloth.F16.gguf' to '/content/fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/unsloth.Q4_K_M.gguf' as Q4_K_M using 24 threads\n",
            "llama_model_loader: loaded meta data with 29 key-value pairs and 363 tensors from /content/fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Loadable\n",
            "llama_model_loader: - kv   3:                         general.size_label str              = 15B\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
            "llama_model_loader: - kv   5:                       llama.context_length u32              = 16384\n",
            "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 5120\n",
            "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 17920\n",
            "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 40\n",
            "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 10\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 250000.000000\n",
            "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128\n",
            "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128\n",
            "llama_model_loader: - kv  14:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  15:                           llama.vocab_size u32              = 100352\n",
            "llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  17:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = dbrx\n",
            "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,100352]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,100352]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,100000]  = [\"Ä  Ä \", \"Ä Ä  Ä Ä \", \"i n\", \"Ä  t\",...\n",
            "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 100257\n",
            "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 100265\n",
            "llama_model_loader: - kv  25:            tokenizer.ggml.unknown_token_id u32              = 5809\n",
            "llama_model_loader: - kv  26:            tokenizer.ggml.padding_token_id u32              = 100265\n",
            "llama_model_loader: - kv  27:                    tokenizer.chat_template str              = {% for message in messages %}{% if (m...\n",
            "llama_model_loader: - kv  28:            tokenizer.ggml.add_space_prefix bool             = false\n",
            "llama_model_loader: - type  f32:   81 tensors\n",
            "llama_model_loader: - type  f16:  282 tensors\n",
            "[   1/ 363]                        output.weight - [ 5120, 100352,     1,     1], type =    f16, converting to q6_K .. size =   980.00 MiB ->   401.95 MiB\n",
            "[   2/ 363]                   output_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[   3/ 363]                    token_embd.weight - [ 5120, 100352,     1,     1], type =    f16, converting to q4_K .. size =   980.00 MiB ->   275.62 MiB\n",
            "[   4/ 363]                  blk.0.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[   5/ 363]               blk.0.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[   6/ 363]             blk.0.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[   7/ 363]                  blk.0.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[   8/ 363]                  blk.0.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[   9/ 363]                blk.0.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  10/ 363]                blk.0.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  11/ 363]                blk.0.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  12/ 363]                  blk.0.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  13/ 363]                  blk.1.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  14/ 363]               blk.1.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  15/ 363]             blk.1.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  16/ 363]                  blk.1.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  17/ 363]                  blk.1.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  18/ 363]                blk.1.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  19/ 363]                blk.1.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  20/ 363]                blk.1.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  21/ 363]                  blk.1.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  22/ 363]                  blk.2.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  23/ 363]               blk.2.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  24/ 363]             blk.2.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  25/ 363]                  blk.2.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  26/ 363]                  blk.2.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  27/ 363]                blk.2.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  28/ 363]                blk.2.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  29/ 363]                blk.2.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  30/ 363]                  blk.2.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  31/ 363]                  blk.3.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  32/ 363]               blk.3.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  33/ 363]             blk.3.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  34/ 363]                  blk.3.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  35/ 363]                  blk.3.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  36/ 363]                blk.3.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  37/ 363]                blk.3.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  38/ 363]                blk.3.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  39/ 363]                  blk.3.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  40/ 363]                  blk.4.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  41/ 363]               blk.4.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  42/ 363]             blk.4.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  43/ 363]                  blk.4.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  44/ 363]                  blk.4.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  45/ 363]                blk.4.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  46/ 363]                blk.4.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  47/ 363]                blk.4.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  48/ 363]                  blk.4.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  49/ 363]                  blk.5.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  50/ 363]               blk.5.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  51/ 363]             blk.5.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  52/ 363]                  blk.5.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  53/ 363]                  blk.5.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  54/ 363]                blk.5.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  55/ 363]                blk.5.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  56/ 363]                blk.5.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  57/ 363]                  blk.5.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  58/ 363]                  blk.6.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  59/ 363]               blk.6.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  60/ 363]             blk.6.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  61/ 363]                  blk.6.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  62/ 363]                  blk.6.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  63/ 363]                blk.6.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  64/ 363]                blk.6.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  65/ 363]                blk.6.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  66/ 363]                  blk.6.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  67/ 363]                  blk.7.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  68/ 363]               blk.7.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  69/ 363]             blk.7.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  70/ 363]                  blk.7.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  71/ 363]                  blk.7.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  72/ 363]                blk.7.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  73/ 363]                blk.7.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  74/ 363]                blk.7.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  75/ 363]                  blk.7.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  76/ 363]                  blk.8.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  77/ 363]               blk.8.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  78/ 363]             blk.8.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  79/ 363]                  blk.8.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  80/ 363]                  blk.8.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  81/ 363]                blk.8.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  82/ 363]                blk.8.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  83/ 363]                blk.8.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  84/ 363]                  blk.8.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  85/ 363]                  blk.9.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  86/ 363]               blk.9.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  87/ 363]             blk.9.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  88/ 363]                  blk.9.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  89/ 363]                  blk.9.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  90/ 363]                blk.9.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  91/ 363]                blk.9.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  92/ 363]                blk.9.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  93/ 363]                  blk.9.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  94/ 363]                 blk.10.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  95/ 363]              blk.10.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  96/ 363]            blk.10.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  97/ 363]                 blk.10.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  98/ 363]                 blk.10.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  99/ 363]               blk.10.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 100/ 363]               blk.10.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 101/ 363]               blk.10.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 102/ 363]                 blk.10.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 103/ 363]                 blk.11.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 104/ 363]              blk.11.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 105/ 363]            blk.11.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 106/ 363]                 blk.11.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 107/ 363]                 blk.11.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 108/ 363]               blk.11.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 109/ 363]               blk.11.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 110/ 363]               blk.11.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 111/ 363]                 blk.11.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 112/ 363]                 blk.12.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 113/ 363]              blk.12.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 114/ 363]            blk.12.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 115/ 363]                 blk.12.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 116/ 363]                 blk.12.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 117/ 363]               blk.12.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 118/ 363]               blk.12.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 119/ 363]               blk.12.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 120/ 363]                 blk.12.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 121/ 363]                 blk.13.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 122/ 363]              blk.13.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 123/ 363]            blk.13.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 124/ 363]                 blk.13.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 125/ 363]                 blk.13.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 126/ 363]               blk.13.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 127/ 363]               blk.13.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 128/ 363]               blk.13.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 129/ 363]                 blk.13.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 130/ 363]                 blk.14.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 131/ 363]              blk.14.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 132/ 363]            blk.14.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 133/ 363]                 blk.14.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 134/ 363]                 blk.14.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 135/ 363]               blk.14.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 136/ 363]               blk.14.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 137/ 363]               blk.14.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 138/ 363]                 blk.14.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 139/ 363]                 blk.15.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 140/ 363]              blk.15.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 141/ 363]            blk.15.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 142/ 363]                 blk.15.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 143/ 363]                 blk.15.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 144/ 363]               blk.15.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 145/ 363]               blk.15.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 146/ 363]               blk.15.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 147/ 363]                 blk.15.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 148/ 363]                 blk.16.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 149/ 363]              blk.16.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 150/ 363]            blk.16.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 151/ 363]                 blk.16.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 152/ 363]                 blk.16.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 153/ 363]               blk.16.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 154/ 363]               blk.16.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 155/ 363]               blk.16.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 156/ 363]                 blk.16.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 157/ 363]                 blk.17.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 158/ 363]              blk.17.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 159/ 363]            blk.17.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 160/ 363]                 blk.17.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 161/ 363]                 blk.17.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 162/ 363]               blk.17.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 163/ 363]               blk.17.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 164/ 363]               blk.17.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 165/ 363]                 blk.17.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 166/ 363]                 blk.18.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 167/ 363]              blk.18.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 168/ 363]            blk.18.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 169/ 363]                 blk.18.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 170/ 363]                 blk.18.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 171/ 363]               blk.18.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 172/ 363]               blk.18.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 173/ 363]               blk.18.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 174/ 363]                 blk.18.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 175/ 363]                 blk.19.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 176/ 363]              blk.19.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 177/ 363]            blk.19.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 178/ 363]                 blk.19.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 179/ 363]                 blk.19.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 180/ 363]               blk.19.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 181/ 363]               blk.19.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 182/ 363]               blk.19.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 183/ 363]                 blk.19.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 184/ 363]                 blk.20.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 185/ 363]              blk.20.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 186/ 363]            blk.20.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 187/ 363]                 blk.20.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 188/ 363]                 blk.20.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 189/ 363]               blk.20.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 190/ 363]               blk.20.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 191/ 363]               blk.20.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 192/ 363]                 blk.20.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 193/ 363]                 blk.21.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 194/ 363]              blk.21.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 195/ 363]            blk.21.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 196/ 363]                 blk.21.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 197/ 363]                 blk.21.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 198/ 363]               blk.21.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 199/ 363]               blk.21.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 200/ 363]               blk.21.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 201/ 363]                 blk.21.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 202/ 363]                 blk.22.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 203/ 363]              blk.22.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 204/ 363]            blk.22.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 205/ 363]                 blk.22.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 206/ 363]                 blk.22.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 207/ 363]               blk.22.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 208/ 363]               blk.22.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 209/ 363]               blk.22.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 210/ 363]                 blk.22.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 211/ 363]                 blk.23.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 212/ 363]              blk.23.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 213/ 363]            blk.23.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 214/ 363]                 blk.23.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 215/ 363]                 blk.23.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 216/ 363]               blk.23.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 217/ 363]               blk.23.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 218/ 363]               blk.23.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 219/ 363]                 blk.23.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 220/ 363]                 blk.24.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 221/ 363]              blk.24.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 222/ 363]            blk.24.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 223/ 363]                 blk.24.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 224/ 363]                 blk.24.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 225/ 363]               blk.24.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 226/ 363]               blk.24.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 227/ 363]               blk.24.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 228/ 363]                 blk.24.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 229/ 363]                 blk.25.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 230/ 363]              blk.25.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 231/ 363]            blk.25.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 232/ 363]                 blk.25.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 233/ 363]                 blk.25.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 234/ 363]               blk.25.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 235/ 363]               blk.25.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 236/ 363]               blk.25.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 237/ 363]                 blk.25.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 238/ 363]                 blk.26.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 239/ 363]              blk.26.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 240/ 363]            blk.26.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 241/ 363]                 blk.26.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 242/ 363]                 blk.26.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 243/ 363]               blk.26.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 244/ 363]               blk.26.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 245/ 363]               blk.26.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 246/ 363]                 blk.26.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 247/ 363]                 blk.27.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 248/ 363]              blk.27.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 249/ 363]            blk.27.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 250/ 363]                 blk.27.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 251/ 363]                 blk.27.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 252/ 363]               blk.27.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 253/ 363]               blk.27.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 254/ 363]               blk.27.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 255/ 363]                 blk.27.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 256/ 363]                 blk.28.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 257/ 363]              blk.28.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 258/ 363]            blk.28.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 259/ 363]                 blk.28.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 260/ 363]                 blk.28.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 261/ 363]               blk.28.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 262/ 363]               blk.28.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 263/ 363]               blk.28.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 264/ 363]                 blk.28.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 265/ 363]                 blk.29.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 266/ 363]              blk.29.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 267/ 363]            blk.29.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 268/ 363]                 blk.29.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 269/ 363]                 blk.29.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 270/ 363]               blk.29.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 271/ 363]               blk.29.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 272/ 363]               blk.29.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 273/ 363]                 blk.29.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 274/ 363]                 blk.30.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 275/ 363]              blk.30.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 276/ 363]            blk.30.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 277/ 363]                 blk.30.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 278/ 363]                 blk.30.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 279/ 363]               blk.30.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 280/ 363]               blk.30.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 281/ 363]               blk.30.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 282/ 363]                 blk.30.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 283/ 363]                 blk.31.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 284/ 363]              blk.31.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 285/ 363]            blk.31.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 286/ 363]                 blk.31.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 287/ 363]                 blk.31.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 288/ 363]               blk.31.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 289/ 363]               blk.31.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 290/ 363]               blk.31.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 291/ 363]                 blk.31.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 292/ 363]                 blk.32.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 293/ 363]              blk.32.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 294/ 363]            blk.32.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 295/ 363]                 blk.32.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 296/ 363]                 blk.32.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 297/ 363]               blk.32.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 298/ 363]               blk.32.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 299/ 363]               blk.32.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 300/ 363]                 blk.32.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 301/ 363]                 blk.33.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 302/ 363]              blk.33.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 303/ 363]            blk.33.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 304/ 363]                 blk.33.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 305/ 363]                 blk.33.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 306/ 363]               blk.33.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 307/ 363]               blk.33.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 308/ 363]               blk.33.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 309/ 363]                 blk.33.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 310/ 363]                 blk.34.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 311/ 363]              blk.34.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 312/ 363]            blk.34.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 313/ 363]                 blk.34.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 314/ 363]                 blk.34.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 315/ 363]               blk.34.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 316/ 363]               blk.34.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 317/ 363]               blk.34.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 318/ 363]                 blk.34.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 319/ 363]                 blk.35.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 320/ 363]              blk.35.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 321/ 363]            blk.35.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 322/ 363]                 blk.35.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 323/ 363]                 blk.35.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 324/ 363]               blk.35.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 325/ 363]               blk.35.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 326/ 363]               blk.35.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 327/ 363]                 blk.35.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 328/ 363]                 blk.36.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 329/ 363]              blk.36.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 330/ 363]            blk.36.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 331/ 363]                 blk.36.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 332/ 363]                 blk.36.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 333/ 363]               blk.36.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 334/ 363]               blk.36.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 335/ 363]               blk.36.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 336/ 363]                 blk.36.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 337/ 363]                 blk.37.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 338/ 363]              blk.37.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 339/ 363]            blk.37.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 340/ 363]                 blk.37.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 341/ 363]                 blk.37.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 342/ 363]               blk.37.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 343/ 363]               blk.37.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 344/ 363]               blk.37.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 345/ 363]                 blk.37.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 346/ 363]                 blk.38.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 347/ 363]              blk.38.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 348/ 363]            blk.38.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 349/ 363]                 blk.38.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 350/ 363]                 blk.38.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 351/ 363]               blk.38.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 352/ 363]               blk.38.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 353/ 363]               blk.38.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 354/ 363]                 blk.38.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 355/ 363]                 blk.39.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 356/ 363]              blk.39.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 357/ 363]            blk.39.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 358/ 363]                 blk.39.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 359/ 363]                 blk.39.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 360/ 363]               blk.39.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 361/ 363]               blk.39.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 362/ 363]               blk.39.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 363/ 363]                 blk.39.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "llama_model_quantize_impl: model size  = 27961.58 MB\n",
            "llama_model_quantize_impl: quant size  =  8475.06 MB\n",
            "\n",
            "main: quantize time = 370157.07 ms\n",
            "main:    total time = 370157.07 ms\n",
            "Unsloth: Conversion completed! Output location: /content/fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/unsloth.Q4_K_M.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q6_k. This might take 20 minutes...\n",
            "main: build = 5409 (6aa892ec)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/unsloth.F16.gguf' to '/content/fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/unsloth.Q6_K.gguf' as Q6_K using 24 threads\n",
            "llama_model_loader: loaded meta data with 29 key-value pairs and 363 tensors from /content/fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Loadable\n",
            "llama_model_loader: - kv   3:                         general.size_label str              = 15B\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
            "llama_model_loader: - kv   5:                       llama.context_length u32              = 16384\n",
            "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 5120\n",
            "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 17920\n",
            "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 40\n",
            "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 10\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 250000.000000\n",
            "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128\n",
            "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128\n",
            "llama_model_loader: - kv  14:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  15:                           llama.vocab_size u32              = 100352\n",
            "llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  17:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = dbrx\n",
            "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,100352]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,100352]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,100000]  = [\"Ä  Ä \", \"Ä Ä  Ä Ä \", \"i n\", \"Ä  t\",...\n",
            "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 100257\n",
            "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 100265\n",
            "llama_model_loader: - kv  25:            tokenizer.ggml.unknown_token_id u32              = 5809\n",
            "llama_model_loader: - kv  26:            tokenizer.ggml.padding_token_id u32              = 100265\n",
            "llama_model_loader: - kv  27:                    tokenizer.chat_template str              = {% for message in messages %}{% if (m...\n",
            "llama_model_loader: - kv  28:            tokenizer.ggml.add_space_prefix bool             = false\n",
            "llama_model_loader: - type  f32:   81 tensors\n",
            "llama_model_loader: - type  f16:  282 tensors\n",
            "[   1/ 363]                        output.weight - [ 5120, 100352,     1,     1], type =    f16, converting to q6_K .. size =   980.00 MiB ->   401.95 MiB\n",
            "[   2/ 363]                   output_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[   3/ 363]                    token_embd.weight - [ 5120, 100352,     1,     1], type =    f16, converting to q6_K .. size =   980.00 MiB ->   401.95 MiB\n",
            "[   4/ 363]                  blk.0.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[   5/ 363]               blk.0.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[   6/ 363]             blk.0.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[   7/ 363]                  blk.0.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[   8/ 363]                  blk.0.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[   9/ 363]                blk.0.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  10/ 363]                blk.0.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  11/ 363]                blk.0.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  12/ 363]                  blk.0.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  13/ 363]                  blk.1.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  14/ 363]               blk.1.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  15/ 363]             blk.1.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  16/ 363]                  blk.1.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  17/ 363]                  blk.1.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  18/ 363]                blk.1.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  19/ 363]                blk.1.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  20/ 363]                blk.1.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  21/ 363]                  blk.1.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  22/ 363]                  blk.2.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  23/ 363]               blk.2.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  24/ 363]             blk.2.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  25/ 363]                  blk.2.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  26/ 363]                  blk.2.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  27/ 363]                blk.2.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  28/ 363]                blk.2.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  29/ 363]                blk.2.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  30/ 363]                  blk.2.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  31/ 363]                  blk.3.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  32/ 363]               blk.3.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  33/ 363]             blk.3.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  34/ 363]                  blk.3.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  35/ 363]                  blk.3.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  36/ 363]                blk.3.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  37/ 363]                blk.3.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  38/ 363]                blk.3.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  39/ 363]                  blk.3.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  40/ 363]                  blk.4.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  41/ 363]               blk.4.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  42/ 363]             blk.4.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  43/ 363]                  blk.4.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  44/ 363]                  blk.4.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  45/ 363]                blk.4.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  46/ 363]                blk.4.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  47/ 363]                blk.4.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  48/ 363]                  blk.4.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  49/ 363]                  blk.5.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  50/ 363]               blk.5.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  51/ 363]             blk.5.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  52/ 363]                  blk.5.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  53/ 363]                  blk.5.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  54/ 363]                blk.5.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  55/ 363]                blk.5.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  56/ 363]                blk.5.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  57/ 363]                  blk.5.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  58/ 363]                  blk.6.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  59/ 363]               blk.6.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  60/ 363]             blk.6.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  61/ 363]                  blk.6.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  62/ 363]                  blk.6.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  63/ 363]                blk.6.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  64/ 363]                blk.6.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  65/ 363]                blk.6.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  66/ 363]                  blk.6.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  67/ 363]                  blk.7.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  68/ 363]               blk.7.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  69/ 363]             blk.7.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  70/ 363]                  blk.7.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  71/ 363]                  blk.7.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  72/ 363]                blk.7.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  73/ 363]                blk.7.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  74/ 363]                blk.7.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  75/ 363]                  blk.7.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  76/ 363]                  blk.8.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  77/ 363]               blk.8.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  78/ 363]             blk.8.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  79/ 363]                  blk.8.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  80/ 363]                  blk.8.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  81/ 363]                blk.8.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  82/ 363]                blk.8.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  83/ 363]                blk.8.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  84/ 363]                  blk.8.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  85/ 363]                  blk.9.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  86/ 363]               blk.9.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  87/ 363]             blk.9.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  88/ 363]                  blk.9.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  89/ 363]                  blk.9.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  90/ 363]                blk.9.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  91/ 363]                blk.9.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  92/ 363]                blk.9.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  93/ 363]                  blk.9.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  94/ 363]                 blk.10.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  95/ 363]              blk.10.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  96/ 363]            blk.10.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  97/ 363]                 blk.10.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  98/ 363]                 blk.10.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  99/ 363]               blk.10.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 100/ 363]               blk.10.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 101/ 363]               blk.10.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 102/ 363]                 blk.10.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 103/ 363]                 blk.11.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 104/ 363]              blk.11.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 105/ 363]            blk.11.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 106/ 363]                 blk.11.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 107/ 363]                 blk.11.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 108/ 363]               blk.11.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 109/ 363]               blk.11.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 110/ 363]               blk.11.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 111/ 363]                 blk.11.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 112/ 363]                 blk.12.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 113/ 363]              blk.12.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 114/ 363]            blk.12.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 115/ 363]                 blk.12.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 116/ 363]                 blk.12.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 117/ 363]               blk.12.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 118/ 363]               blk.12.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 119/ 363]               blk.12.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 120/ 363]                 blk.12.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 121/ 363]                 blk.13.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 122/ 363]              blk.13.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 123/ 363]            blk.13.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 124/ 363]                 blk.13.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 125/ 363]                 blk.13.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 126/ 363]               blk.13.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 127/ 363]               blk.13.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 128/ 363]               blk.13.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 129/ 363]                 blk.13.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 130/ 363]                 blk.14.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 131/ 363]              blk.14.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 132/ 363]            blk.14.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 133/ 363]                 blk.14.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 134/ 363]                 blk.14.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 135/ 363]               blk.14.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 136/ 363]               blk.14.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 137/ 363]               blk.14.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 138/ 363]                 blk.14.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 139/ 363]                 blk.15.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 140/ 363]              blk.15.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 141/ 363]            blk.15.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 142/ 363]                 blk.15.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 143/ 363]                 blk.15.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 144/ 363]               blk.15.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 145/ 363]               blk.15.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 146/ 363]               blk.15.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 147/ 363]                 blk.15.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 148/ 363]                 blk.16.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 149/ 363]              blk.16.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 150/ 363]            blk.16.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 151/ 363]                 blk.16.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 152/ 363]                 blk.16.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 153/ 363]               blk.16.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 154/ 363]               blk.16.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 155/ 363]               blk.16.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 156/ 363]                 blk.16.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 157/ 363]                 blk.17.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 158/ 363]              blk.17.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 159/ 363]            blk.17.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 160/ 363]                 blk.17.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 161/ 363]                 blk.17.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 162/ 363]               blk.17.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 163/ 363]               blk.17.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 164/ 363]               blk.17.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 165/ 363]                 blk.17.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 166/ 363]                 blk.18.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 167/ 363]              blk.18.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 168/ 363]            blk.18.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 169/ 363]                 blk.18.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 170/ 363]                 blk.18.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 171/ 363]               blk.18.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 172/ 363]               blk.18.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 173/ 363]               blk.18.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 174/ 363]                 blk.18.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 175/ 363]                 blk.19.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 176/ 363]              blk.19.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 177/ 363]            blk.19.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 178/ 363]                 blk.19.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 179/ 363]                 blk.19.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 180/ 363]               blk.19.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 181/ 363]               blk.19.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 182/ 363]               blk.19.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 183/ 363]                 blk.19.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 184/ 363]                 blk.20.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 185/ 363]              blk.20.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 186/ 363]            blk.20.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 187/ 363]                 blk.20.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 188/ 363]                 blk.20.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 189/ 363]               blk.20.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 190/ 363]               blk.20.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 191/ 363]               blk.20.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 192/ 363]                 blk.20.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 193/ 363]                 blk.21.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 194/ 363]              blk.21.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 195/ 363]            blk.21.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 196/ 363]                 blk.21.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 197/ 363]                 blk.21.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 198/ 363]               blk.21.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 199/ 363]               blk.21.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 200/ 363]               blk.21.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 201/ 363]                 blk.21.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 202/ 363]                 blk.22.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 203/ 363]              blk.22.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 204/ 363]            blk.22.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 205/ 363]                 blk.22.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 206/ 363]                 blk.22.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 207/ 363]               blk.22.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 208/ 363]               blk.22.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 209/ 363]               blk.22.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 210/ 363]                 blk.22.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 211/ 363]                 blk.23.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 212/ 363]              blk.23.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 213/ 363]            blk.23.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 214/ 363]                 blk.23.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 215/ 363]                 blk.23.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 216/ 363]               blk.23.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 217/ 363]               blk.23.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 218/ 363]               blk.23.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 219/ 363]                 blk.23.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 220/ 363]                 blk.24.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 221/ 363]              blk.24.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 222/ 363]            blk.24.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 223/ 363]                 blk.24.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 224/ 363]                 blk.24.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 225/ 363]               blk.24.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 226/ 363]               blk.24.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 227/ 363]               blk.24.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 228/ 363]                 blk.24.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 229/ 363]                 blk.25.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 230/ 363]              blk.25.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 231/ 363]            blk.25.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 232/ 363]                 blk.25.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 233/ 363]                 blk.25.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 234/ 363]               blk.25.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 235/ 363]               blk.25.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 236/ 363]               blk.25.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 237/ 363]                 blk.25.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 238/ 363]                 blk.26.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 239/ 363]              blk.26.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 240/ 363]            blk.26.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 241/ 363]                 blk.26.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 242/ 363]                 blk.26.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 243/ 363]               blk.26.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 244/ 363]               blk.26.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 245/ 363]               blk.26.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 246/ 363]                 blk.26.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 247/ 363]                 blk.27.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 248/ 363]              blk.27.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 249/ 363]            blk.27.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 250/ 363]                 blk.27.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 251/ 363]                 blk.27.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 252/ 363]               blk.27.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 253/ 363]               blk.27.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 254/ 363]               blk.27.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 255/ 363]                 blk.27.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 256/ 363]                 blk.28.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 257/ 363]              blk.28.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 258/ 363]            blk.28.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 259/ 363]                 blk.28.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 260/ 363]                 blk.28.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 261/ 363]               blk.28.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 262/ 363]               blk.28.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 263/ 363]               blk.28.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 264/ 363]                 blk.28.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 265/ 363]                 blk.29.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 266/ 363]              blk.29.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 267/ 363]            blk.29.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 268/ 363]                 blk.29.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 269/ 363]                 blk.29.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 270/ 363]               blk.29.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 271/ 363]               blk.29.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 272/ 363]               blk.29.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 273/ 363]                 blk.29.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 274/ 363]                 blk.30.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 275/ 363]              blk.30.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 276/ 363]            blk.30.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 277/ 363]                 blk.30.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 278/ 363]                 blk.30.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 279/ 363]               blk.30.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 280/ 363]               blk.30.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 281/ 363]               blk.30.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 282/ 363]                 blk.30.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 283/ 363]                 blk.31.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 284/ 363]              blk.31.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 285/ 363]            blk.31.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 286/ 363]                 blk.31.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 287/ 363]                 blk.31.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 288/ 363]               blk.31.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 289/ 363]               blk.31.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 290/ 363]               blk.31.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 291/ 363]                 blk.31.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 292/ 363]                 blk.32.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 293/ 363]              blk.32.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 294/ 363]            blk.32.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 295/ 363]                 blk.32.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 296/ 363]                 blk.32.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 297/ 363]               blk.32.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 298/ 363]               blk.32.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 299/ 363]               blk.32.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 300/ 363]                 blk.32.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 301/ 363]                 blk.33.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 302/ 363]              blk.33.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 303/ 363]            blk.33.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 304/ 363]                 blk.33.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 305/ 363]                 blk.33.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 306/ 363]               blk.33.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 307/ 363]               blk.33.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 308/ 363]               blk.33.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 309/ 363]                 blk.33.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 310/ 363]                 blk.34.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 311/ 363]              blk.34.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 312/ 363]            blk.34.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 313/ 363]                 blk.34.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 314/ 363]                 blk.34.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 315/ 363]               blk.34.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 316/ 363]               blk.34.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 317/ 363]               blk.34.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 318/ 363]                 blk.34.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 319/ 363]                 blk.35.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 320/ 363]              blk.35.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 321/ 363]            blk.35.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 322/ 363]                 blk.35.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 323/ 363]                 blk.35.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 324/ 363]               blk.35.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 325/ 363]               blk.35.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 326/ 363]               blk.35.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 327/ 363]                 blk.35.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 328/ 363]                 blk.36.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 329/ 363]              blk.36.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 330/ 363]            blk.36.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 331/ 363]                 blk.36.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 332/ 363]                 blk.36.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 333/ 363]               blk.36.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 334/ 363]               blk.36.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 335/ 363]               blk.36.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 336/ 363]                 blk.36.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 337/ 363]                 blk.37.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 338/ 363]              blk.37.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 339/ 363]            blk.37.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 340/ 363]                 blk.37.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 341/ 363]                 blk.37.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 342/ 363]               blk.37.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 343/ 363]               blk.37.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 344/ 363]               blk.37.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 345/ 363]                 blk.37.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 346/ 363]                 blk.38.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 347/ 363]              blk.38.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 348/ 363]            blk.38.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 349/ 363]                 blk.38.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 350/ 363]                 blk.38.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 351/ 363]               blk.38.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 352/ 363]               blk.38.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 353/ 363]               blk.38.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 354/ 363]                 blk.38.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 355/ 363]                 blk.39.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 356/ 363]              blk.39.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 357/ 363]            blk.39.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 358/ 363]                 blk.39.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 359/ 363]                 blk.39.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 360/ 363]               blk.39.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 361/ 363]               blk.39.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 362/ 363]               blk.39.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 363/ 363]                 blk.39.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "llama_model_quantize_impl: model size  = 27961.58 MB\n",
            "llama_model_quantize_impl: quant size  = 11469.55 MB\n",
            "\n",
            "main: quantize time = 216236.73 ms\n",
            "main:    total time = 216236.73 ms\n",
            "Unsloth: Conversion completed! Output location: /content/fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/unsloth.Q6_K.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rsync -HPrz --mkpath \\\n",
        "  fine-tuned \\\n",
        "  result-pusher@kb.tfm.codigoparallevar.com:fine-tuning"
      ],
      "metadata": {
        "id": "N_5qJL52iP1h",
        "outputId": "9bcba334-7b35-42e9-ad0e-255b3fc359fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "N_5qJL52iP1h",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sending incremental file list\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/README.md\n",
            "          5,087 100%    4.18MB/s    0:00:00 (xfr#1, to-chk=445/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/adapter_config.json\n",
            "            843 100%  823.24kB/s    0:00:00 (xfr#2, to-chk=444/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/adapter_model.safetensors\n",
            "    262,219,392 100%  118.97MB/s    0:00:02 (xfr#3, to-chk=443/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/merges.txt\n",
            "        916,646 100%    7.81MB/s    0:00:00 (xfr#4, to-chk=442/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/optimizer.pt\n",
            "    133,784,532 100%  156.36MB/s    0:00:00 (xfr#5, to-chk=441/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/rng_state.pth\n",
            "         14,244 100%   17.03kB/s    0:00:00 (xfr#6, to-chk=440/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/scheduler.pt\n",
            "          1,064 100%    1.27kB/s    0:00:00 (xfr#7, to-chk=439/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/special_tokens_map.json\n",
            "            456 100%    0.55kB/s    0:00:00 (xfr#8, to-chk=438/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/tokenizer.json\n",
            "      7,153,264 100%    7.98MB/s    0:00:00 (xfr#9, to-chk=437/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/tokenizer_config.json\n",
            "         17,987 100%   20.54kB/s    0:00:00 (xfr#10, to-chk=436/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/trainer_state.json\n",
            "          1,791 100%    2.05kB/s    0:00:00 (xfr#11, to-chk=435/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/training_args.bin\n",
            "          5,304 100%    6.06kB/s    0:00:00 (xfr#12, to-chk=434/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-100/vocab.json\n",
            "      1,612,637 100%    1.78MB/s    0:00:00 (xfr#13, to-chk=433/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/README.md\n",
            "          5,087 100%    5.73kB/s    0:00:00 (xfr#14, to-chk=432/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/adapter_config.json\n",
            "            843 100%    0.95kB/s    0:00:00 (xfr#15, to-chk=431/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/adapter_model.safetensors\n",
            "    262,219,392 100%  103.85MB/s    0:00:02 (xfr#16, to-chk=430/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/merges.txt\n",
            "        916,646 100%    2.10MB/s    0:00:00 (xfr#17, to-chk=429/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/optimizer.pt\n",
            "    133,785,108 100%  110.75MB/s    0:00:01 (xfr#18, to-chk=428/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/rng_state.pth\n",
            "         14,244 100%   90.92kB/s    0:00:00 (xfr#19, to-chk=427/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/scheduler.pt\n",
            "          1,064 100%    6.79kB/s    0:00:00 (xfr#20, to-chk=426/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/special_tokens_map.json\n",
            "            456 100%    2.91kB/s    0:00:00 (xfr#21, to-chk=425/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/tokenizer.json\n",
            "      7,153,264 100%   35.90MB/s    0:00:00 (xfr#22, to-chk=424/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/tokenizer_config.json\n",
            "         17,987 100%   92.45kB/s    0:00:00 (xfr#23, to-chk=423/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/trainer_state.json\n",
            "          9,974 100%   51.26kB/s    0:00:00 (xfr#24, to-chk=422/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/training_args.bin\n",
            "          5,304 100%   27.26kB/s    0:00:00 (xfr#25, to-chk=421/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1000/vocab.json\n",
            "      1,612,637 100%    7.69MB/s    0:00:00 (xfr#26, to-chk=420/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/README.md\n",
            "          5,087 100%   24.59kB/s    0:00:00 (xfr#27, to-chk=419/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/adapter_config.json\n",
            "            843 100%    4.08kB/s    0:00:00 (xfr#28, to-chk=418/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/adapter_model.safetensors\n",
            "    262,219,392 100%  132.38MB/s    0:00:01 (xfr#29, to-chk=417/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/merges.txt\n",
            "        916,646 100% 1001.30kB/s    0:00:00 (xfr#30, to-chk=416/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/optimizer.pt\n",
            "    133,785,108 100%   77.47MB/s    0:00:01 (xfr#31, to-chk=415/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/rng_state.pth\n",
            "         14,244 100%   21.47kB/s    0:00:00 (xfr#32, to-chk=414/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/scheduler.pt\n",
            "          1,064 100%    1.60kB/s    0:00:00 (xfr#33, to-chk=413/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/special_tokens_map.json\n",
            "            456 100%    0.69kB/s    0:00:00 (xfr#34, to-chk=412/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/tokenizer.json\n",
            "      7,153,264 100%    9.93MB/s    0:00:00 (xfr#35, to-chk=411/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/tokenizer_config.json\n",
            "         17,987 100%   25.53kB/s    0:00:00 (xfr#36, to-chk=410/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/trainer_state.json\n",
            "         10,885 100%   15.45kB/s    0:00:00 (xfr#37, to-chk=409/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/training_args.bin\n",
            "          5,304 100%    7.53kB/s    0:00:00 (xfr#38, to-chk=408/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1100/vocab.json\n",
            "      1,612,637 100%    2.20MB/s    0:00:00 (xfr#39, to-chk=407/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/README.md\n",
            "          5,087 100%    7.11kB/s    0:00:00 (xfr#40, to-chk=406/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/adapter_config.json\n",
            "            843 100%    1.18kB/s    0:00:00 (xfr#41, to-chk=405/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/adapter_model.safetensors\n",
            "    262,219,392 100%  114.82MB/s    0:00:02 (xfr#42, to-chk=404/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/merges.txt\n",
            "        916,646 100%    4.60MB/s    0:00:00 (xfr#43, to-chk=403/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/optimizer.pt\n",
            "    133,785,108 100%  136.02MB/s    0:00:00 (xfr#44, to-chk=402/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/rng_state.pth\n",
            "         14,244 100%   14.81kB/s    0:00:00 (xfr#45, to-chk=401/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/scheduler.pt\n",
            "          1,064 100%    1.11kB/s    0:00:00 (xfr#46, to-chk=400/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/special_tokens_map.json\n",
            "            456 100%    0.47kB/s    0:00:00 (xfr#47, to-chk=399/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/tokenizer.json\n",
            "      7,153,264 100%    6.99MB/s    0:00:00 (xfr#48, to-chk=398/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/tokenizer_config.json\n",
            "         17,987 100%   18.00kB/s    0:00:00 (xfr#49, to-chk=397/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/trainer_state.json\n",
            "         11,801 100%   11.81kB/s    0:00:00 (xfr#50, to-chk=396/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/training_args.bin\n",
            "          5,304 100%    5.31kB/s    0:00:00 (xfr#51, to-chk=395/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1200/vocab.json\n",
            "      1,612,637 100%    1.56MB/s    0:00:00 (xfr#52, to-chk=394/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/README.md\n",
            "          5,087 100%    5.02kB/s    0:00:00 (xfr#53, to-chk=393/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/adapter_config.json\n",
            "            843 100%    0.83kB/s    0:00:00 (xfr#54, to-chk=392/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/adapter_model.safetensors\n",
            "    262,219,392 100%   94.33MB/s    0:00:02 (xfr#55, to-chk=391/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/merges.txt\n",
            "        916,646 100%    1.33MB/s    0:00:00 (xfr#56, to-chk=390/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/optimizer.pt\n",
            "    133,785,108 100%   90.17MB/s    0:00:01 (xfr#57, to-chk=389/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/rng_state.pth\n",
            "         14,244 100%   33.52kB/s    0:00:00 (xfr#58, to-chk=388/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/scheduler.pt\n",
            "          1,064 100%    2.50kB/s    0:00:00 (xfr#59, to-chk=387/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/special_tokens_map.json\n",
            "            456 100%    1.07kB/s    0:00:00 (xfr#60, to-chk=386/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/tokenizer.json\n",
            "      7,153,264 100%   15.03MB/s    0:00:00 (xfr#61, to-chk=385/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/tokenizer_config.json\n",
            "         17,987 100%   38.69kB/s    0:00:00 (xfr#62, to-chk=384/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/trainer_state.json\n",
            "         12,712 100%   27.34kB/s    0:00:00 (xfr#63, to-chk=383/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/training_args.bin\n",
            "          5,304 100%   11.41kB/s    0:00:00 (xfr#64, to-chk=382/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1300/vocab.json\n",
            "      1,612,637 100%    3.29MB/s    0:00:00 (xfr#65, to-chk=381/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/README.md\n",
            "          5,087 100%   10.61kB/s    0:00:00 (xfr#66, to-chk=380/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/adapter_config.json\n",
            "            843 100%    1.76kB/s    0:00:00 (xfr#67, to-chk=379/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/adapter_model.safetensors\n",
            "    262,219,392 100%  128.70MB/s    0:00:01 (xfr#68, to-chk=378/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/merges.txt\n",
            "        916,646 100%  948.26kB/s    0:00:00 (xfr#69, to-chk=377/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/optimizer.pt\n",
            "    133,785,108 100%   72.87MB/s    0:00:01 (xfr#70, to-chk=376/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/rng_state.pth\n",
            "         14,244 100%   18.47kB/s    0:00:00 (xfr#71, to-chk=375/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/scheduler.pt\n",
            "          1,064 100%    1.38kB/s    0:00:00 (xfr#72, to-chk=374/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/special_tokens_map.json\n",
            "            456 100%    0.59kB/s    0:00:00 (xfr#73, to-chk=373/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/tokenizer.json\n",
            "      7,153,264 100%    8.66MB/s    0:00:00 (xfr#74, to-chk=372/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/tokenizer_config.json\n",
            "         17,987 100%   22.26kB/s    0:00:00 (xfr#75, to-chk=371/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/trainer_state.json\n",
            "         13,629 100%   16.85kB/s    0:00:00 (xfr#76, to-chk=370/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/training_args.bin\n",
            "          5,304 100%    6.55kB/s    0:00:00 (xfr#77, to-chk=369/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1400/vocab.json\n",
            "      1,612,637 100%    1.92MB/s    0:00:00 (xfr#78, to-chk=368/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/README.md\n",
            "          5,087 100%    6.19kB/s    0:00:00 (xfr#79, to-chk=367/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/adapter_config.json\n",
            "            843 100%    1.03kB/s    0:00:00 (xfr#80, to-chk=366/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/adapter_model.safetensors\n",
            "    262,219,392 100%  109.58MB/s    0:00:02 (xfr#81, to-chk=365/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/merges.txt\n",
            "        916,646 100%    3.01MB/s    0:00:00 (xfr#82, to-chk=364/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/optimizer.pt\n",
            "    133,785,108 100%  124.11MB/s    0:00:01 (xfr#83, to-chk=363/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/rng_state.pth\n",
            "         14,244 100%  496.79kB/s    0:00:00 (xfr#84, to-chk=362/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/scheduler.pt\n",
            "          1,064 100%   35.83kB/s    0:00:00 (xfr#85, to-chk=361/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/special_tokens_map.json\n",
            "            456 100%   15.36kB/s    0:00:00 (xfr#86, to-chk=360/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/tokenizer.json\n",
            "      7,153,264 100%   98.87MB/s    0:00:00 (xfr#87, to-chk=359/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/tokenizer_config.json\n",
            "         17,987 100%  250.93kB/s    0:00:00 (xfr#88, to-chk=358/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/trainer_state.json\n",
            "         14,545 100%  202.92kB/s    0:00:00 (xfr#89, to-chk=357/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/training_args.bin\n",
            "          5,304 100%   74.00kB/s    0:00:00 (xfr#90, to-chk=356/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1500/vocab.json\n",
            "      1,612,637 100%   19.72MB/s    0:00:00 (xfr#91, to-chk=355/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/README.md\n",
            "          5,087 100%   62.88kB/s    0:00:00 (xfr#92, to-chk=354/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/adapter_config.json\n",
            "            843 100%   10.42kB/s    0:00:00 (xfr#93, to-chk=353/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/adapter_model.safetensors\n",
            "    262,219,392 100%  158.27MB/s    0:00:01 (xfr#94, to-chk=352/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/merges.txt\n",
            "        916,646 100%    1.49MB/s    0:00:00 (xfr#95, to-chk=351/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/optimizer.pt\n",
            "    133,785,108 100%   91.72MB/s    0:00:01 (xfr#96, to-chk=350/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/rng_state.pth\n",
            "         14,244 100%   35.49kB/s    0:00:00 (xfr#97, to-chk=349/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/scheduler.pt\n",
            "          1,064 100%    2.65kB/s    0:00:00 (xfr#98, to-chk=348/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/special_tokens_map.json\n",
            "            456 100%    1.14kB/s    0:00:00 (xfr#99, to-chk=347/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/tokenizer.json\n",
            "      7,153,264 100%   15.90MB/s    0:00:00 (xfr#100, to-chk=346/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/tokenizer_config.json\n",
            "         17,987 100%   40.95kB/s    0:00:00 (xfr#101, to-chk=345/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/trainer_state.json\n",
            "         15,456 100%   35.18kB/s    0:00:00 (xfr#102, to-chk=344/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/training_args.bin\n",
            "          5,304 100%   12.07kB/s    0:00:00 (xfr#103, to-chk=343/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1600/vocab.json\n",
            "      1,612,637 100%    3.49MB/s    0:00:00 (xfr#104, to-chk=342/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/README.md\n",
            "          5,087 100%   11.26kB/s    0:00:00 (xfr#105, to-chk=341/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/adapter_config.json\n",
            "            843 100%    1.87kB/s    0:00:00 (xfr#106, to-chk=340/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/adapter_model.safetensors\n",
            "    262,219,392 100%   87.10MB/s    0:00:02 (xfr#107, to-chk=339/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/merges.txt\n",
            "        916,646 100% 1014.92kB/s    0:00:00 (xfr#108, to-chk=338/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/optimizer.pt\n",
            "    133,785,108 100%   58.96MB/s    0:00:02 (xfr#109, to-chk=337/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/rng_state.pth\n",
            "         14,244 100%   84.82kB/s    0:00:00 (xfr#110, to-chk=336/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/scheduler.pt\n",
            "          1,064 100%    6.30kB/s    0:00:00 (xfr#111, to-chk=335/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/special_tokens_map.json\n",
            "            456 100%    2.70kB/s    0:00:00 (xfr#112, to-chk=334/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/tokenizer.json\n",
            "      7,153,264 100%   30.87MB/s    0:00:00 (xfr#113, to-chk=333/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/tokenizer_config.json\n",
            "         17,987 100%   79.48kB/s    0:00:00 (xfr#114, to-chk=332/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/trainer_state.json\n",
            "         16,369 100%   72.33kB/s    0:00:00 (xfr#115, to-chk=331/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/training_args.bin\n",
            "          5,304 100%   23.33kB/s    0:00:00 (xfr#116, to-chk=330/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1700/vocab.json\n",
            "      1,612,637 100%    6.38MB/s    0:00:00 (xfr#117, to-chk=329/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/README.md\n",
            "          5,087 100%   20.61kB/s    0:00:00 (xfr#118, to-chk=328/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/adapter_config.json\n",
            "            843 100%    3.42kB/s    0:00:00 (xfr#119, to-chk=327/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/adapter_model.safetensors\n",
            "    262,219,392 100%   99.47MB/s    0:00:02 (xfr#120, to-chk=326/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/merges.txt\n",
            "        916,646 100%    1.70MB/s    0:00:00 (xfr#121, to-chk=325/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/optimizer.pt\n",
            "    133,785,108 100%  124.84MB/s    0:00:01 (xfr#122, to-chk=324/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/rng_state.pth\n",
            "         14,244 100%  604.79kB/s    0:00:00 (xfr#123, to-chk=323/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/scheduler.pt\n",
            "          1,064 100%   45.18kB/s    0:00:00 (xfr#124, to-chk=322/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/special_tokens_map.json\n",
            "            456 100%   19.36kB/s    0:00:00 (xfr#125, to-chk=321/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/tokenizer.json\n",
            "      7,153,264 100%  133.76MB/s    0:00:00 (xfr#126, to-chk=320/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/tokenizer_config.json\n",
            "         17,987 100%  344.42kB/s    0:00:00 (xfr#127, to-chk=319/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/trainer_state.json\n",
            "         17,283 100%  330.94kB/s    0:00:00 (xfr#128, to-chk=318/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/training_args.bin\n",
            "          5,304 100%  101.56kB/s    0:00:00 (xfr#129, to-chk=317/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1800/vocab.json\n",
            "      1,612,637 100%   26.98MB/s    0:00:00 (xfr#130, to-chk=316/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/README.md\n",
            "          5,087 100%   85.65kB/s    0:00:00 (xfr#131, to-chk=315/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/adapter_config.json\n",
            "            843 100%   14.19kB/s    0:00:00 (xfr#132, to-chk=314/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/adapter_model.safetensors\n",
            "    262,219,392 100%  149.12MB/s    0:00:01 (xfr#133, to-chk=313/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/merges.txt\n",
            "        916,646 100%    1.29MB/s    0:00:00 (xfr#134, to-chk=312/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/optimizer.pt\n",
            "    133,785,108 100%   93.54MB/s    0:00:01 (xfr#135, to-chk=311/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/rng_state.pth\n",
            "         14,244 100%   37.90kB/s    0:00:00 (xfr#136, to-chk=310/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/scheduler.pt\n",
            "          1,064 100%    2.82kB/s    0:00:00 (xfr#137, to-chk=309/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/special_tokens_map.json\n",
            "            456 100%    1.21kB/s    0:00:00 (xfr#138, to-chk=308/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/tokenizer.json\n",
            "      7,153,264 100%   17.14MB/s    0:00:00 (xfr#139, to-chk=307/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/tokenizer_config.json\n",
            "         17,987 100%   44.13kB/s    0:00:00 (xfr#140, to-chk=306/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/trainer_state.json\n",
            "         18,193 100%   44.64kB/s    0:00:00 (xfr#141, to-chk=305/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/training_args.bin\n",
            "          5,304 100%   13.01kB/s    0:00:00 (xfr#142, to-chk=304/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-1900/vocab.json\n",
            "      1,612,637 100%    3.77MB/s    0:00:00 (xfr#143, to-chk=303/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/README.md\n",
            "          5,087 100%   12.15kB/s    0:00:00 (xfr#144, to-chk=302/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/adapter_config.json\n",
            "            843 100%    2.01kB/s    0:00:00 (xfr#145, to-chk=301/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/adapter_model.safetensors\n",
            "    262,219,392 100%  134.81MB/s    0:00:01 (xfr#146, to-chk=300/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/merges.txt\n",
            "        916,646 100%    1.01MB/s    0:00:00 (xfr#147, to-chk=299/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/optimizer.pt\n",
            "    133,784,532 100%   81.58MB/s    0:00:01 (xfr#148, to-chk=298/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/rng_state.pth\n",
            "         14,244 100%   24.66kB/s    0:00:00 (xfr#149, to-chk=297/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/scheduler.pt\n",
            "          1,064 100%    1.84kB/s    0:00:00 (xfr#150, to-chk=296/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/special_tokens_map.json\n",
            "            456 100%    0.79kB/s    0:00:00 (xfr#151, to-chk=295/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/tokenizer.json\n",
            "      7,153,264 100%   11.35MB/s    0:00:00 (xfr#152, to-chk=294/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/tokenizer_config.json\n",
            "         17,987 100%   29.23kB/s    0:00:00 (xfr#153, to-chk=293/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/trainer_state.json\n",
            "          2,702 100%    4.39kB/s    0:00:00 (xfr#154, to-chk=292/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/training_args.bin\n",
            "          5,304 100%    8.62kB/s    0:00:00 (xfr#155, to-chk=291/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-200/vocab.json\n",
            "      1,612,637 100%    2.51MB/s    0:00:00 (xfr#156, to-chk=290/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/README.md\n",
            "          5,087 100%    8.10kB/s    0:00:00 (xfr#157, to-chk=289/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/adapter_config.json\n",
            "            843 100%    1.34kB/s    0:00:00 (xfr#158, to-chk=288/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/adapter_model.safetensors\n",
            "    262,219,392 100%  112.54MB/s    0:00:02 (xfr#159, to-chk=287/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/merges.txt\n",
            "        916,646 100%    3.64MB/s    0:00:00 (xfr#160, to-chk=286/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/optimizer.pt\n",
            "    133,785,108 100%  137.78MB/s    0:00:00 (xfr#161, to-chk=285/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/rng_state.pth\n",
            "         14,244 100%   15.01kB/s    0:00:00 (xfr#162, to-chk=284/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/scheduler.pt\n",
            "          1,064 100%    1.12kB/s    0:00:00 (xfr#163, to-chk=283/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/special_tokens_map.json\n",
            "            456 100%    0.48kB/s    0:00:00 (xfr#164, to-chk=282/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/tokenizer.json\n",
            "      7,153,264 100%    6.86MB/s    0:00:00 (xfr#165, to-chk=281/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/tokenizer_config.json\n",
            "         17,987 100%   17.65kB/s    0:00:00 (xfr#166, to-chk=280/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/trainer_state.json\n",
            "         19,106 100%   18.75kB/s    0:00:00 (xfr#167, to-chk=279/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/training_args.bin\n",
            "          5,304 100%    5.21kB/s    0:00:00 (xfr#168, to-chk=278/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2000/vocab.json\n",
            "      1,612,637 100%    1.53MB/s    0:00:01 (xfr#169, to-chk=277/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/README.md\n",
            "          5,087 100%  993.55kB/s    0:00:00 (xfr#170, to-chk=276/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/adapter_config.json\n",
            "            843 100%  137.21kB/s    0:00:00 (xfr#171, to-chk=275/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/adapter_model.safetensors\n",
            "    262,219,392 100%  107.93MB/s    0:00:02 (xfr#172, to-chk=274/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/merges.txt\n",
            "        916,646 100%    2.73MB/s    0:00:00 (xfr#173, to-chk=273/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/optimizer.pt\n",
            "    133,785,108 100%   87.39MB/s    0:00:01 (xfr#174, to-chk=272/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/rng_state.pth\n",
            "         14,244 100%   30.24kB/s    0:00:00 (xfr#175, to-chk=271/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/scheduler.pt\n",
            "          1,064 100%    2.25kB/s    0:00:00 (xfr#176, to-chk=270/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/special_tokens_map.json\n",
            "            456 100%    0.97kB/s    0:00:00 (xfr#177, to-chk=269/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/tokenizer.json\n",
            "      7,153,264 100%   13.35MB/s    0:00:00 (xfr#178, to-chk=268/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/tokenizer_config.json\n",
            "         17,987 100%   34.31kB/s    0:00:00 (xfr#179, to-chk=267/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/trainer_state.json\n",
            "         20,015 100%   38.18kB/s    0:00:00 (xfr#180, to-chk=266/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/training_args.bin\n",
            "          5,304 100%   10.12kB/s    0:00:00 (xfr#181, to-chk=265/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2100/vocab.json\n",
            "      1,612,637 100%    2.92MB/s    0:00:00 (xfr#182, to-chk=264/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/README.md\n",
            "          5,087 100%    9.41kB/s    0:00:00 (xfr#183, to-chk=263/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/adapter_config.json\n",
            "            843 100%    1.56kB/s    0:00:00 (xfr#184, to-chk=262/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/adapter_model.safetensors\n",
            "    262,219,392 100%   97.38MB/s    0:00:02 (xfr#185, to-chk=261/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/merges.txt\n",
            "        916,646 100%    1.50MB/s    0:00:00 (xfr#186, to-chk=260/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/optimizer.pt\n",
            "    133,785,108 100%   95.00MB/s    0:00:01 (xfr#187, to-chk=259/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/rng_state.pth\n",
            "         14,244 100%   40.44kB/s    0:00:00 (xfr#188, to-chk=258/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/scheduler.pt\n",
            "          1,064 100%    3.02kB/s    0:00:00 (xfr#189, to-chk=257/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/special_tokens_map.json\n",
            "            456 100%    1.29kB/s    0:00:00 (xfr#190, to-chk=256/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/tokenizer.json\n",
            "      7,153,264 100%   17.45MB/s    0:00:00 (xfr#191, to-chk=255/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/tokenizer_config.json\n",
            "         17,987 100%   44.81kB/s    0:00:00 (xfr#192, to-chk=254/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/trainer_state.json\n",
            "         20,928 100%   52.14kB/s    0:00:00 (xfr#193, to-chk=253/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/training_args.bin\n",
            "          5,304 100%   13.21kB/s    0:00:00 (xfr#194, to-chk=252/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2200/vocab.json\n",
            "      1,612,637 100%    3.83MB/s    0:00:00 (xfr#195, to-chk=251/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/README.md\n",
            "          5,087 100%   12.33kB/s    0:00:00 (xfr#196, to-chk=250/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/adapter_config.json\n",
            "            843 100%    2.04kB/s    0:00:00 (xfr#197, to-chk=249/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/adapter_model.safetensors\n",
            "    262,219,392 100%   94.26MB/s    0:00:02 (xfr#198, to-chk=248/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/merges.txt\n",
            "        916,646 100%    1.34MB/s    0:00:00 (xfr#199, to-chk=247/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/optimizer.pt\n",
            "    133,785,108 100%   83.34MB/s    0:00:01 (xfr#200, to-chk=246/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/rng_state.pth\n",
            "         14,244 100%   26.15kB/s    0:00:00 (xfr#201, to-chk=245/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/scheduler.pt\n",
            "          1,064 100%    1.95kB/s    0:00:00 (xfr#202, to-chk=244/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/special_tokens_map.json\n",
            "            456 100%    0.84kB/s    0:00:00 (xfr#203, to-chk=243/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/tokenizer.json\n",
            "      7,153,264 100%   11.66MB/s    0:00:00 (xfr#204, to-chk=242/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/tokenizer_config.json\n",
            "         17,987 100%   29.98kB/s    0:00:00 (xfr#205, to-chk=241/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/trainer_state.json\n",
            "         21,845 100%   36.34kB/s    0:00:00 (xfr#206, to-chk=240/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/training_args.bin\n",
            "          5,304 100%    8.82kB/s    0:00:00 (xfr#207, to-chk=239/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2300/vocab.json\n",
            "      1,612,637 100%    2.55MB/s    0:00:00 (xfr#208, to-chk=238/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/README.md\n",
            "          5,087 100%    8.24kB/s    0:00:00 (xfr#209, to-chk=237/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/adapter_config.json\n",
            "            843 100%    1.37kB/s    0:00:00 (xfr#210, to-chk=236/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/adapter_model.safetensors\n",
            "    262,219,392 100%   92.41MB/s    0:00:02 (xfr#211, to-chk=235/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/merges.txt\n",
            "        916,646 100%    1.23MB/s    0:00:00 (xfr#212, to-chk=234/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/optimizer.pt\n",
            "    133,785,108 100%  102.48MB/s    0:00:01 (xfr#213, to-chk=233/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/rng_state.pth\n",
            "         14,244 100%   56.32kB/s    0:00:00 (xfr#214, to-chk=232/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/scheduler.pt\n",
            "          1,064 100%    4.21kB/s    0:00:00 (xfr#215, to-chk=231/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/special_tokens_map.json\n",
            "            456 100%    1.80kB/s    0:00:00 (xfr#216, to-chk=230/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/tokenizer.json\n",
            "      7,153,264 100%   23.61MB/s    0:00:00 (xfr#217, to-chk=229/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/tokenizer_config.json\n",
            "         17,987 100%   60.78kB/s    0:00:00 (xfr#218, to-chk=228/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/trainer_state.json\n",
            "         22,760 100%   76.91kB/s    0:00:00 (xfr#219, to-chk=227/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/training_args.bin\n",
            "          5,304 100%   17.86kB/s    0:00:00 (xfr#220, to-chk=226/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2400/vocab.json\n",
            "      1,612,637 100%    5.16MB/s    0:00:00 (xfr#221, to-chk=225/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/README.md\n",
            "          5,087 100%   16.67kB/s    0:00:00 (xfr#222, to-chk=224/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/adapter_config.json\n",
            "            843 100%    2.76kB/s    0:00:00 (xfr#223, to-chk=223/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/adapter_model.safetensors\n",
            "    262,219,392 100%  105.83MB/s    0:00:02 (xfr#224, to-chk=222/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/merges.txt\n",
            "        916,646 100%    2.36MB/s    0:00:00 (xfr#225, to-chk=221/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/optimizer.pt\n",
            "    133,785,108 100%  112.81MB/s    0:00:01 (xfr#226, to-chk=220/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/rng_state.pth\n",
            "         14,244 100%  105.38kB/s    0:00:00 (xfr#227, to-chk=219/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/scheduler.pt\n",
            "          1,064 100%    7.87kB/s    0:00:00 (xfr#228, to-chk=218/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/special_tokens_map.json\n",
            "            456 100%    3.37kB/s    0:00:00 (xfr#229, to-chk=217/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/tokenizer.json\n",
            "      7,153,264 100%   39.43MB/s    0:00:00 (xfr#230, to-chk=216/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/tokenizer_config.json\n",
            "         17,987 100%  101.53kB/s    0:00:00 (xfr#231, to-chk=215/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/trainer_state.json\n",
            "         23,674 100%  133.64kB/s    0:00:00 (xfr#232, to-chk=214/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/training_args.bin\n",
            "          5,304 100%   29.94kB/s    0:00:00 (xfr#233, to-chk=213/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2500/vocab.json\n",
            "      1,612,637 100%    8.40MB/s    0:00:00 (xfr#234, to-chk=212/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/README.md\n",
            "          5,087 100%   27.15kB/s    0:00:00 (xfr#235, to-chk=211/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/adapter_config.json\n",
            "            843 100%    4.47kB/s    0:00:00 (xfr#236, to-chk=210/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/adapter_model.safetensors\n",
            "    262,219,392 100%  125.41MB/s    0:00:01 (xfr#237, to-chk=209/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/merges.txt\n",
            "        916,646 100%  893.38kB/s    0:00:01 (xfr#238, to-chk=208/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/optimizer.pt\n",
            "    133,785,108 100%  197.50MB/s    0:00:00 (xfr#239, to-chk=207/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/rng_state.pth\n",
            "         14,244 100%   21.47kB/s    0:00:00 (xfr#240, to-chk=206/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/scheduler.pt\n",
            "          1,064 100%    1.60kB/s    0:00:00 (xfr#241, to-chk=205/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/special_tokens_map.json\n",
            "            456 100%    0.69kB/s    0:00:00 (xfr#242, to-chk=204/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/tokenizer.json\n",
            "      7,153,264 100%    9.96MB/s    0:00:00 (xfr#243, to-chk=203/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/tokenizer_config.json\n",
            "         17,987 100%   25.61kB/s    0:00:00 (xfr#244, to-chk=202/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/trainer_state.json\n",
            "         24,583 100%   35.00kB/s    0:00:00 (xfr#245, to-chk=201/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/training_args.bin\n",
            "          5,304 100%    7.55kB/s    0:00:00 (xfr#246, to-chk=200/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2600/vocab.json\n",
            "      1,612,637 100%    2.22MB/s    0:00:00 (xfr#247, to-chk=199/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/README.md\n",
            "          5,087 100%    7.15kB/s    0:00:00 (xfr#248, to-chk=198/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/adapter_config.json\n",
            "            843 100%    1.18kB/s    0:00:00 (xfr#249, to-chk=197/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/adapter_model.safetensors\n",
            "    262,219,392 100%  102.87MB/s    0:00:02 (xfr#250, to-chk=196/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/merges.txt\n",
            "        916,646 100%    2.00MB/s    0:00:00 (xfr#251, to-chk=195/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/optimizer.pt\n",
            "    133,785,108 100%  109.42MB/s    0:00:01 (xfr#252, to-chk=194/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/rng_state.pth\n",
            "         14,244 100%   82.31kB/s    0:00:00 (xfr#253, to-chk=193/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/scheduler.pt\n",
            "          1,064 100%    6.11kB/s    0:00:00 (xfr#254, to-chk=192/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/special_tokens_map.json\n",
            "            456 100%    2.62kB/s    0:00:00 (xfr#255, to-chk=191/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/tokenizer.json\n",
            "      7,153,264 100%   32.96MB/s    0:00:00 (xfr#256, to-chk=190/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/tokenizer_config.json\n",
            "         17,987 100%   84.05kB/s    0:00:00 (xfr#257, to-chk=189/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/trainer_state.json\n",
            "         25,496 100%  119.13kB/s    0:00:00 (xfr#258, to-chk=188/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/training_args.bin\n",
            "          5,304 100%   24.78kB/s    0:00:00 (xfr#259, to-chk=187/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2700/vocab.json\n",
            "      1,612,637 100%    6.93MB/s    0:00:00 (xfr#260, to-chk=186/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/README.md\n",
            "          5,087 100%   22.18kB/s    0:00:00 (xfr#261, to-chk=185/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/adapter_config.json\n",
            "            843 100%    3.68kB/s    0:00:00 (xfr#262, to-chk=184/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/adapter_model.safetensors\n",
            "    262,219,392 100%  141.12MB/s    0:00:01 (xfr#263, to-chk=183/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/merges.txt\n",
            "        916,646 100%    1.13MB/s    0:00:00 (xfr#264, to-chk=182/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/optimizer.pt\n",
            "    133,785,108 100%   87.69MB/s    0:00:01 (xfr#265, to-chk=181/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/rng_state.pth\n",
            "         14,244 100%   30.50kB/s    0:00:00 (xfr#266, to-chk=180/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/scheduler.pt\n",
            "          1,064 100%    2.28kB/s    0:00:00 (xfr#267, to-chk=179/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/special_tokens_map.json\n",
            "            456 100%    0.98kB/s    0:00:00 (xfr#268, to-chk=178/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/tokenizer.json\n",
            "      7,153,264 100%   13.89MB/s    0:00:00 (xfr#269, to-chk=177/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/tokenizer_config.json\n",
            "         17,987 100%   35.77kB/s    0:00:00 (xfr#270, to-chk=176/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/trainer_state.json\n",
            "         26,409 100%   52.53kB/s    0:00:00 (xfr#271, to-chk=175/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/training_args.bin\n",
            "          5,304 100%   10.55kB/s    0:00:00 (xfr#272, to-chk=174/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2800/vocab.json\n",
            "      1,612,637 100%    3.08MB/s    0:00:00 (xfr#273, to-chk=173/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/README.md\n",
            "          5,087 100%    9.92kB/s    0:00:00 (xfr#274, to-chk=172/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/adapter_config.json\n",
            "            843 100%    1.64kB/s    0:00:00 (xfr#275, to-chk=171/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/adapter_model.safetensors\n",
            "    262,219,392 100%  123.43MB/s    0:00:02 (xfr#276, to-chk=170/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/merges.txt\n",
            "        916,646 100%   27.32MB/s    0:00:00 (xfr#277, to-chk=169/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/optimizer.pt\n",
            "    133,785,108 100%  167.88MB/s    0:00:00 (xfr#278, to-chk=168/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/rng_state.pth\n",
            "         14,244 100%   18.30kB/s    0:00:00 (xfr#279, to-chk=167/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/scheduler.pt\n",
            "          1,064 100%    1.37kB/s    0:00:00 (xfr#280, to-chk=166/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/special_tokens_map.json\n",
            "            456 100%    0.59kB/s    0:00:00 (xfr#281, to-chk=165/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/tokenizer.json\n",
            "      7,153,264 100%    8.60MB/s    0:00:00 (xfr#282, to-chk=164/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/tokenizer_config.json\n",
            "         17,987 100%   22.15kB/s    0:00:00 (xfr#283, to-chk=163/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/trainer_state.json\n",
            "         27,322 100%   33.60kB/s    0:00:00 (xfr#284, to-chk=162/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/training_args.bin\n",
            "          5,304 100%    6.52kB/s    0:00:00 (xfr#285, to-chk=161/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-2900/vocab.json\n",
            "      1,612,637 100%    1.91MB/s    0:00:00 (xfr#286, to-chk=160/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/README.md\n",
            "          5,087 100%    6.18kB/s    0:00:00 (xfr#287, to-chk=159/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/adapter_config.json\n",
            "            843 100%    1.02kB/s    0:00:00 (xfr#288, to-chk=158/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/adapter_model.safetensors\n",
            "    262,219,392 100%  113.36MB/s    0:00:02 (xfr#289, to-chk=157/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/merges.txt\n",
            "        916,646 100%    4.10MB/s    0:00:00 (xfr#290, to-chk=156/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/optimizer.pt\n",
            "    133,785,108 100%  133.46MB/s    0:00:00 (xfr#291, to-chk=155/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/rng_state.pth\n",
            "         14,244 100%   14.55kB/s    0:00:00 (xfr#292, to-chk=154/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/scheduler.pt\n",
            "          1,064 100%    1.09kB/s    0:00:00 (xfr#293, to-chk=153/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/special_tokens_map.json\n",
            "            456 100%    0.47kB/s    0:00:00 (xfr#294, to-chk=152/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/tokenizer.json\n",
            "      7,153,264 100%    6.87MB/s    0:00:00 (xfr#295, to-chk=151/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/tokenizer_config.json\n",
            "         17,987 100%   17.69kB/s    0:00:00 (xfr#296, to-chk=150/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/trainer_state.json\n",
            "          3,613 100%    3.55kB/s    0:00:00 (xfr#297, to-chk=149/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/training_args.bin\n",
            "          5,304 100%    5.22kB/s    0:00:00 (xfr#298, to-chk=148/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-300/vocab.json\n",
            "      1,612,637 100%    1.53MB/s    0:00:01 (xfr#299, to-chk=147/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/README.md\n",
            "          5,087 100%  993.55kB/s    0:00:00 (xfr#300, to-chk=146/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/adapter_config.json\n",
            "            843 100%  164.65kB/s    0:00:00 (xfr#301, to-chk=145/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/adapter_model.safetensors\n",
            "    262,219,392 100%  159.99MB/s    0:00:01 (xfr#302, to-chk=144/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/merges.txt\n",
            "        916,646 100%    1.54MB/s    0:00:00 (xfr#303, to-chk=143/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/optimizer.pt\n",
            "    133,785,108 100%  103.31MB/s    0:00:01 (xfr#304, to-chk=142/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/rng_state.pth\n",
            "         14,244 100%   58.69kB/s    0:00:00 (xfr#305, to-chk=141/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/scheduler.pt\n",
            "          1,064 100%    4.38kB/s    0:00:00 (xfr#306, to-chk=140/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/special_tokens_map.json\n",
            "            456 100%    1.88kB/s    0:00:00 (xfr#307, to-chk=139/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/tokenizer.json\n",
            "      7,153,264 100%   25.36MB/s    0:00:00 (xfr#308, to-chk=138/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/tokenizer_config.json\n",
            "         17,987 100%   65.30kB/s    0:00:00 (xfr#309, to-chk=137/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/trainer_state.json\n",
            "         28,231 100%  102.11kB/s    0:00:00 (xfr#310, to-chk=136/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/training_args.bin\n",
            "          5,304 100%   19.18kB/s    0:00:00 (xfr#311, to-chk=135/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3000/vocab.json\n",
            "      1,612,637 100%    5.51MB/s    0:00:00 (xfr#312, to-chk=134/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/README.md\n",
            "          5,087 100%   17.81kB/s    0:00:00 (xfr#313, to-chk=133/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/adapter_config.json\n",
            "            843 100%    2.95kB/s    0:00:00 (xfr#314, to-chk=132/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/adapter_model.safetensors\n",
            "    262,219,392 100%  154.18MB/s    0:00:01 (xfr#315, to-chk=131/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/merges.txt\n",
            "        916,646 100%    1.39MB/s    0:00:00 (xfr#316, to-chk=130/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/optimizer.pt\n",
            "    133,785,108 100%   93.40MB/s    0:00:01 (xfr#317, to-chk=129/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/rng_state.pth\n",
            "         14,244 100%   37.80kB/s    0:00:00 (xfr#318, to-chk=128/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/scheduler.pt\n",
            "          1,064 100%    2.82kB/s    0:00:00 (xfr#319, to-chk=127/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/special_tokens_map.json\n",
            "            456 100%    1.21kB/s    0:00:00 (xfr#320, to-chk=126/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/tokenizer.json\n",
            "      7,153,264 100%   16.68MB/s    0:00:00 (xfr#321, to-chk=125/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/tokenizer_config.json\n",
            "         17,987 100%   42.95kB/s    0:00:00 (xfr#322, to-chk=124/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/trainer_state.json\n",
            "         29,148 100%   69.60kB/s    0:00:00 (xfr#323, to-chk=123/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/training_args.bin\n",
            "          5,304 100%   12.66kB/s    0:00:00 (xfr#324, to-chk=122/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3100/vocab.json\n",
            "      1,612,637 100%    3.67MB/s    0:00:00 (xfr#325, to-chk=121/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/README.md\n",
            "          5,087 100%   11.86kB/s    0:00:00 (xfr#326, to-chk=120/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/adapter_config.json\n",
            "            843 100%    1.96kB/s    0:00:00 (xfr#327, to-chk=119/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/adapter_model.safetensors\n",
            "    262,219,392 100%  124.41MB/s    0:00:02 (xfr#328, to-chk=118/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/merges.txt\n",
            "        916,646 100%   62.44MB/s    0:00:00 (xfr#329, to-chk=117/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/optimizer.pt\n",
            "    133,785,108 100%  189.58MB/s    0:00:00 (xfr#330, to-chk=116/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/rng_state.pth\n",
            "         14,244 100%   20.61kB/s    0:00:00 (xfr#331, to-chk=115/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/scheduler.pt\n",
            "          1,064 100%    1.54kB/s    0:00:00 (xfr#332, to-chk=114/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/special_tokens_map.json\n",
            "            456 100%    0.66kB/s    0:00:00 (xfr#333, to-chk=113/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/tokenizer.json\n",
            "      7,153,264 100%    9.61MB/s    0:00:00 (xfr#334, to-chk=112/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/tokenizer_config.json\n",
            "         17,987 100%   24.74kB/s    0:00:00 (xfr#335, to-chk=111/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/trainer_state.json\n",
            "         30,062 100%   41.29kB/s    0:00:00 (xfr#336, to-chk=110/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/training_args.bin\n",
            "          5,304 100%    7.27kB/s    0:00:00 (xfr#337, to-chk=109/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3200/vocab.json\n",
            "      1,612,637 100%    2.13MB/s    0:00:00 (xfr#338, to-chk=108/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/README.md\n",
            "          5,087 100%    6.89kB/s    0:00:00 (xfr#339, to-chk=107/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/adapter_config.json\n",
            "            843 100%    1.14kB/s    0:00:00 (xfr#340, to-chk=106/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/adapter_model.safetensors\n",
            "    262,219,392 100%  114.76MB/s    0:00:02 (xfr#341, to-chk=105/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/merges.txt\n",
            "        916,646 100%    4.65MB/s    0:00:00 (xfr#342, to-chk=104/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/optimizer.pt\n",
            "    133,785,108 100%  144.49MB/s    0:00:00 (xfr#343, to-chk=103/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/rng_state.pth\n",
            "         14,244 100%   15.75kB/s    0:00:00 (xfr#344, to-chk=102/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/scheduler.pt\n",
            "          1,064 100%    1.18kB/s    0:00:00 (xfr#345, to-chk=101/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/special_tokens_map.json\n",
            "            456 100%    0.50kB/s    0:00:00 (xfr#346, to-chk=100/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/tokenizer.json\n",
            "      7,153,264 100%    7.43MB/s    0:00:00 (xfr#347, to-chk=99/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/tokenizer_config.json\n",
            "         17,987 100%   19.13kB/s    0:00:00 (xfr#348, to-chk=98/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/trainer_state.json\n",
            "         30,397 100%   32.34kB/s    0:00:00 (xfr#349, to-chk=97/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/training_args.bin\n",
            "          5,304 100%    5.64kB/s    0:00:00 (xfr#350, to-chk=96/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-3270/vocab.json\n",
            "      1,612,637 100%    1.65MB/s    0:00:00 (xfr#351, to-chk=95/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/README.md\n",
            "          5,087 100%    5.33kB/s    0:00:00 (xfr#352, to-chk=94/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/adapter_config.json\n",
            "            843 100%    0.88kB/s    0:00:00 (xfr#353, to-chk=93/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/adapter_model.safetensors\n",
            "    262,219,392 100%  107.84MB/s    0:00:02 (xfr#354, to-chk=92/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/merges.txt\n",
            "        916,646 100%    2.68MB/s    0:00:00 (xfr#355, to-chk=91/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/optimizer.pt\n",
            "    133,785,108 100%  123.75MB/s    0:00:01 (xfr#356, to-chk=90/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/rng_state.pth\n",
            "         14,244 100%  421.52kB/s    0:00:00 (xfr#357, to-chk=89/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/scheduler.pt\n",
            "          1,064 100%   31.49kB/s    0:00:00 (xfr#358, to-chk=88/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/special_tokens_map.json\n",
            "            456 100%   13.49kB/s    0:00:00 (xfr#359, to-chk=87/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/tokenizer.json\n",
            "      7,153,264 100%   97.46MB/s    0:00:00 (xfr#360, to-chk=86/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/tokenizer_config.json\n",
            "         17,987 100%  250.93kB/s    0:00:00 (xfr#361, to-chk=85/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/trainer_state.json\n",
            "          4,526 100%   63.14kB/s    0:00:00 (xfr#362, to-chk=84/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/training_args.bin\n",
            "          5,304 100%   74.00kB/s    0:00:00 (xfr#363, to-chk=83/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-400/vocab.json\n",
            "      1,612,637 100%   18.76MB/s    0:00:00 (xfr#364, to-chk=82/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/README.md\n",
            "          5,087 100%   59.14kB/s    0:00:00 (xfr#365, to-chk=81/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/adapter_config.json\n",
            "            843 100%    9.80kB/s    0:00:00 (xfr#366, to-chk=80/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/adapter_model.safetensors\n",
            "    262,219,392 100%  170.23MB/s    0:00:01 (xfr#367, to-chk=79/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/merges.txt\n",
            "        916,646 100%    1.83MB/s    0:00:00 (xfr#368, to-chk=78/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/optimizer.pt\n",
            "    133,785,108 100%  108.68MB/s    0:00:01 (xfr#369, to-chk=77/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/rng_state.pth\n",
            "         14,244 100%   79.03kB/s    0:00:00 (xfr#370, to-chk=76/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/scheduler.pt\n",
            "          1,064 100%    5.90kB/s    0:00:00 (xfr#371, to-chk=75/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/special_tokens_map.json\n",
            "            456 100%    2.53kB/s    0:00:00 (xfr#372, to-chk=74/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/tokenizer.json\n",
            "      7,153,264 100%   32.03MB/s    0:00:00 (xfr#373, to-chk=73/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/tokenizer_config.json\n",
            "         17,987 100%   82.47kB/s    0:00:00 (xfr#374, to-chk=72/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/trainer_state.json\n",
            "          5,430 100%   24.90kB/s    0:00:00 (xfr#375, to-chk=71/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/training_args.bin\n",
            "          5,304 100%   24.32kB/s    0:00:00 (xfr#376, to-chk=70/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-500/vocab.json\n",
            "      1,612,637 100%    6.87MB/s    0:00:00 (xfr#377, to-chk=69/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/README.md\n",
            "          5,087 100%   22.18kB/s    0:00:00 (xfr#378, to-chk=68/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/adapter_config.json\n",
            "            843 100%    3.68kB/s    0:00:00 (xfr#379, to-chk=67/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/adapter_model.safetensors\n",
            "    262,219,392 100%  156.10MB/s    0:00:01 (xfr#380, to-chk=66/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/merges.txt\n",
            "        916,646 100%    1.44MB/s    0:00:00 (xfr#381, to-chk=65/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/optimizer.pt\n",
            "    133,785,108 100%   97.17MB/s    0:00:01 (xfr#382, to-chk=64/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/rng_state.pth\n",
            "         14,244 100%   44.30kB/s    0:00:00 (xfr#383, to-chk=63/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/scheduler.pt\n",
            "          1,064 100%    3.31kB/s    0:00:00 (xfr#384, to-chk=62/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/special_tokens_map.json\n",
            "            456 100%    1.42kB/s    0:00:00 (xfr#385, to-chk=61/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/tokenizer.json\n",
            "      7,153,264 100%   19.49MB/s    0:00:00 (xfr#386, to-chk=60/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/tokenizer_config.json\n",
            "         17,987 100%   50.19kB/s    0:00:00 (xfr#387, to-chk=59/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/trainer_state.json\n",
            "          6,338 100%   17.68kB/s    0:00:00 (xfr#388, to-chk=58/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/training_args.bin\n",
            "          5,304 100%   14.80kB/s    0:00:00 (xfr#389, to-chk=57/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-600/vocab.json\n",
            "      1,612,637 100%    4.26MB/s    0:00:00 (xfr#390, to-chk=56/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/README.md\n",
            "          5,087 100%   13.76kB/s    0:00:00 (xfr#391, to-chk=55/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/adapter_config.json\n",
            "            843 100%    2.28kB/s    0:00:00 (xfr#392, to-chk=54/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/adapter_model.safetensors\n",
            "    262,219,392 100%  143.06MB/s    0:00:01 (xfr#393, to-chk=53/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/merges.txt\n",
            "        916,646 100%    1.16MB/s    0:00:00 (xfr#394, to-chk=52/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/optimizer.pt\n",
            "    133,785,108 100%   86.15MB/s    0:00:01 (xfr#395, to-chk=51/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/rng_state.pth\n",
            "         14,244 100%   28.92kB/s    0:00:00 (xfr#396, to-chk=50/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/scheduler.pt\n",
            "          1,064 100%    2.16kB/s    0:00:00 (xfr#397, to-chk=49/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/special_tokens_map.json\n",
            "            456 100%    0.93kB/s    0:00:00 (xfr#398, to-chk=48/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/tokenizer.json\n",
            "      7,153,264 100%   13.17MB/s    0:00:00 (xfr#399, to-chk=47/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/tokenizer_config.json\n",
            "         17,987 100%   33.91kB/s    0:00:00 (xfr#400, to-chk=46/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/trainer_state.json\n",
            "          7,248 100%   13.66kB/s    0:00:00 (xfr#401, to-chk=45/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/training_args.bin\n",
            "          5,304 100%   10.00kB/s    0:00:00 (xfr#402, to-chk=44/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-700/vocab.json\n",
            "      1,612,637 100%    2.91MB/s    0:00:00 (xfr#403, to-chk=43/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/README.md\n",
            "          5,087 100%    9.37kB/s    0:00:00 (xfr#404, to-chk=42/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/adapter_config.json\n",
            "            843 100%    1.55kB/s    0:00:00 (xfr#405, to-chk=41/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/adapter_model.safetensors\n",
            "    262,219,392 100%  130.38MB/s    0:00:01 (xfr#406, to-chk=40/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/merges.txt\n",
            "        916,646 100%  969.84kB/s    0:00:00 (xfr#407, to-chk=39/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/optimizer.pt\n",
            "    133,785,108 100%   76.68MB/s    0:00:01 (xfr#408, to-chk=38/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/rng_state.pth\n",
            "         14,244 100%   20.89kB/s    0:00:00 (xfr#409, to-chk=37/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/scheduler.pt\n",
            "          1,064 100%    1.56kB/s    0:00:00 (xfr#410, to-chk=36/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/special_tokens_map.json\n",
            "            456 100%    0.67kB/s    0:00:00 (xfr#411, to-chk=35/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/tokenizer.json\n",
            "      7,153,264 100%    9.70MB/s    0:00:00 (xfr#412, to-chk=34/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/tokenizer_config.json\n",
            "         17,987 100%   24.95kB/s    0:00:00 (xfr#413, to-chk=33/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/trainer_state.json\n",
            "          8,158 100%   11.32kB/s    0:00:00 (xfr#414, to-chk=32/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/training_args.bin\n",
            "          5,304 100%    7.36kB/s    0:00:00 (xfr#415, to-chk=31/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-800/vocab.json\n",
            "      1,612,637 100%    2.14MB/s    0:00:00 (xfr#416, to-chk=30/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/README.md\n",
            "          5,087 100%    6.92kB/s    0:00:00 (xfr#417, to-chk=29/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/adapter_config.json\n",
            "            843 100%    1.14kB/s    0:00:00 (xfr#418, to-chk=28/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/adapter_model.safetensors\n",
            "    262,219,392 100%  120.52MB/s    0:00:02 (xfr#419, to-chk=27/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/merges.txt\n",
            "        916,646 100%   10.93MB/s    0:00:00 (xfr#420, to-chk=26/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/optimizer.pt\n",
            "    133,785,108 100%  160.29MB/s    0:00:00 (xfr#421, to-chk=25/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/rng_state.pth\n",
            "         14,244 100%   17.43kB/s    0:00:00 (xfr#422, to-chk=24/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/scheduler.pt\n",
            "          1,064 100%    1.30kB/s    0:00:00 (xfr#423, to-chk=23/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/special_tokens_map.json\n",
            "            456 100%    0.56kB/s    0:00:00 (xfr#424, to-chk=22/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/tokenizer.json\n",
            "      7,153,264 100%    8.17MB/s    0:00:00 (xfr#425, to-chk=21/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/tokenizer_config.json\n",
            "         17,987 100%   21.01kB/s    0:00:00 (xfr#426, to-chk=20/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/trainer_state.json\n",
            "          9,063 100%   10.59kB/s    0:00:00 (xfr#427, to-chk=19/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/training_args.bin\n",
            "          5,304 100%    6.20kB/s    0:00:00 (xfr#428, to-chk=18/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/checkpoint-900/vocab.json\n",
            "      1,612,637 100%    1.81MB/s    0:00:00 (xfr#429, to-chk=17/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/config.json\n",
            "            794 100%    0.91kB/s    0:00:00 (xfr#430, to-chk=16/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/generation_config.json\n",
            "            170 100%    0.20kB/s    0:00:00 (xfr#431, to-chk=15/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/merges.txt\n",
            "        916,646 100%    1.01MB/s    0:00:00 (xfr#432, to-chk=14/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/model-00001-of-00006.safetensors\n",
            "  4,933,658,528 100%   16.62MB/s    0:04:43 (xfr#433, to-chk=13/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/model-00002-of-00006.safetensors\n",
            "  4,954,693,112 100%   19.53MB/s    0:04:01 (xfr#434, to-chk=12/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/model-00003-of-00006.safetensors\n",
            "  4,902,243,992 100%   19.52MB/s    0:03:59 (xfr#435, to-chk=11/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/model-00004-of-00006.safetensors\n",
            "  4,954,672,440 100%   19.55MB/s    0:04:01 (xfr#436, to-chk=10/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/model-00005-of-00006.safetensors\n",
            "  4,954,672,432 100%   19.53MB/s    0:04:01 (xfr#437, to-chk=9/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/model-00006-of-00006.safetensors\n",
            "  4,619,116,224 100%   19.50MB/s    0:03:45 (xfr#438, to-chk=8/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/model.safetensors.index.json\n",
            "         29,894 100%    1.90MB/s    0:00:00 (xfr#439, to-chk=7/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/special_tokens_map.json\n",
            "            456 100%   23.44kB/s    0:00:00 (xfr#440, to-chk=6/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/tokenizer.json\n",
            "      7,153,264 100%   46.41MB/s    0:00:00 (xfr#441, to-chk=5/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/tokenizer_config.json\n",
            "         17,987 100%  118.69kB/s    0:00:00 (xfr#442, to-chk=4/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/unsloth.F16.gguf\n",
            " 29,323,406,208 100%   19.92MB/s    0:23:24 (xfr#443, to-chk=3/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/unsloth.Q4_K_M.gguf\n",
            "  8,890,305,408 100%   15.54MB/s    0:09:05 (xfr#444, to-chk=2/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/unsloth.Q6_K.gguf\n",
            " 12,030,258,048 100%   15.24MB/s    0:12:32 (xfr#445, to-chk=1/484)\n",
            "fine-tuned/r16_a16_s0_d0_bnone_l0.0001_4bFalse_20250516_1601/loadable/vocab.json\n",
            "      1,612,637 100%    1.95MB/s    0:00:00 (xfr#446, to-chk=0/484)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdf303a7-cb4f-4bbe-96c8-e0f881eb1812",
      "metadata": {
        "id": "cdf303a7-cb4f-4bbe-96c8-e0f881eb1812"
      },
      "source": [
        "## Cleanup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finish time\n",
        "!date"
      ],
      "metadata": {
        "id": "y1ducQOZhKIm",
        "outputId": "29b77fdc-21fd-411b-fb14-63afc3f2ddc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "y1ducQOZhKIm",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri May 16 09:22:35 PM UTC 2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fceb9694-7dd1-4086-b87f-e449cb612682",
      "metadata": {
        "id": "fceb9694-7dd1-4086-b87f-e449cb612682"
      },
      "source": [
        "### Stop kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "999aeb16-d251-4c00-93e6-977bc73ae1c1",
      "metadata": {
        "id": "999aeb16-d251-4c00-93e6-977bc73ae1c1"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f2ae0fc01f144e5abb61ee4f07da543c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d7cecb4c23b4938beca8ca49b916857",
              "IPY_MODEL_8572b231e9d740169f41b3cc5ecfbbb5",
              "IPY_MODEL_cbec1310a9d74e81b4f27d0a65a89579"
            ],
            "layout": "IPY_MODEL_f18650ee034f412e96e1614787230e6c"
          }
        },
        "0d7cecb4c23b4938beca8ca49b916857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8ee243a77cb42439e6f7211ab16a715",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_63684edfd26246bfa692b49052f8c3a2",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "8572b231e9d740169f41b3cc5ecfbbb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5942188f8db24f6a88841efe36279726",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_044af4bec7dc4d598639f015ad5b48d6",
            "value": 6
          }
        },
        "cbec1310a9d74e81b4f27d0a65a89579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acf0da2f3ad34aa5b2acff691eebc6df",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_732aab9b26d04312b52d76b3cee8b47e",
            "value": "â€‡6/6â€‡[00:08&lt;00:00,â€‡â€‡1.35s/it]"
          }
        },
        "f18650ee034f412e96e1614787230e6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8ee243a77cb42439e6f7211ab16a715": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63684edfd26246bfa692b49052f8c3a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5942188f8db24f6a88841efe36279726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "044af4bec7dc4d598639f015ad5b48d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "acf0da2f3ad34aa5b2acff691eebc6df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "732aab9b26d04312b52d76b3cee8b47e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf41a0b9066a4bd8a0e4ab1e47f4e94c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4f2051325db4bfdbf5fda2ad96a67b6",
              "IPY_MODEL_35d580a4df68436b9df9a769013013b0",
              "IPY_MODEL_757ead5323f74a19913dbbe9668f58b5"
            ],
            "layout": "IPY_MODEL_0eaaf95da5934438aa5c280f9e63107f"
          }
        },
        "f479cb3fd0e74156b0918d8562a47731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e3bb4e9ef0e44c5ba2de9376d41301f",
              "IPY_MODEL_67797f951f0d4b4eab16d5699b000386",
              "IPY_MODEL_8152c3d5f3244db287153bff581a8622"
            ],
            "layout": "IPY_MODEL_cc45141440ca46adabe3a6916cd14de0"
          }
        },
        "a4f2051325db4bfdbf5fda2ad96a67b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4d21809fb164bc1ad46bc3eee3065d8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_47070c2def2f48c9aa3b2308ccc42849",
            "value": "Generatingâ€‡testâ€‡split:â€‡"
          }
        },
        "35d580a4df68436b9df9a769013013b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae3af0b4c5ff42c1b3a975d6147f2a4b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed96aeb46651497f9fe075d29d2daaa7",
            "value": 1
          }
        },
        "757ead5323f74a19913dbbe9668f58b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e42f91116b248a4b8c026b234626c80",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_831e25ad067e4e0190747ab8d5313424",
            "value": "â€‡10/0â€‡[00:00&lt;00:00,â€‡705.32â€‡examples/s]"
          }
        },
        "0eaaf95da5934438aa5c280f9e63107f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4d21809fb164bc1ad46bc3eee3065d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47070c2def2f48c9aa3b2308ccc42849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae3af0b4c5ff42c1b3a975d6147f2a4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ed96aeb46651497f9fe075d29d2daaa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e42f91116b248a4b8c026b234626c80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "831e25ad067e4e0190747ab8d5313424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e3bb4e9ef0e44c5ba2de9376d41301f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b91a038fde144336bb7ce9f099286d95",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6f93859797074e8985d01c2cc9367a47",
            "value": "Generatingâ€‡trainâ€‡split:â€‡"
          }
        },
        "67797f951f0d4b4eab16d5699b000386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ab38593c5474022a0c0d866393f6dcd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce1aba6870f2421d8dae830e899abbf6",
            "value": 1
          }
        },
        "8152c3d5f3244db287153bff581a8622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_094f46266bb846e192a5dc3c1ff9fe4d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b9345cf940484a9bb400fa811eba39ce",
            "value": "â€‡2200/0â€‡[00:00&lt;00:00,â€‡7887.01â€‡examples/s]"
          }
        },
        "cc45141440ca46adabe3a6916cd14de0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b91a038fde144336bb7ce9f099286d95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f93859797074e8985d01c2cc9367a47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ab38593c5474022a0c0d866393f6dcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ce1aba6870f2421d8dae830e899abbf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "094f46266bb846e192a5dc3c1ff9fe4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9345cf940484a9bb400fa811eba39ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33dd891cbd664755b6ecd27e928f8cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_faf3c584b400404ea51a2941abdf386e",
              "IPY_MODEL_8ce6567801f64e67a983a924d703e29c",
              "IPY_MODEL_84a652b31cb5494d85474ab3540cc495"
            ],
            "layout": "IPY_MODEL_4b13ffe8270d424f989508dc4c970771"
          }
        },
        "faf3c584b400404ea51a2941abdf386e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edfe38cdfc4f47bebcdfcc80028280a6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a7c6a0e7ce004c05a32ac74a0d01a0d9",
            "value": "Map:â€‡100%"
          }
        },
        "8ce6567801f64e67a983a924d703e29c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce8853d2d3b9432eae29f6b53873382c",
            "max": 2200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e656ac76c93841ab885440c20446b8e2",
            "value": 2200
          }
        },
        "84a652b31cb5494d85474ab3540cc495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad32bba0912442d0b060e77eb112941a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c2d1ce316e1a41e4ab3908435b89a2e2",
            "value": "â€‡2200/2200â€‡[00:01&lt;00:00,â€‡2092.15â€‡examples/s]"
          }
        },
        "4b13ffe8270d424f989508dc4c970771": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edfe38cdfc4f47bebcdfcc80028280a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7c6a0e7ce004c05a32ac74a0d01a0d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce8853d2d3b9432eae29f6b53873382c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e656ac76c93841ab885440c20446b8e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad32bba0912442d0b060e77eb112941a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2d1ce316e1a41e4ab3908435b89a2e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c37b6993ecc446db2dc5d746740afdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15344078c7884086aa8e2d02dc84ad99",
              "IPY_MODEL_a604fdbb0f73499a82ff7dd5cded6a94",
              "IPY_MODEL_6e380d56244a4f3182f5184d61f48c6c"
            ],
            "layout": "IPY_MODEL_b216049803e34e4da8658cb73541d9e2"
          }
        },
        "15344078c7884086aa8e2d02dc84ad99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec1bc30bc07c421ba907067e76af1468",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1b2ac1f103e2468dad395f89b422c295",
            "value": "Map:â€‡100%"
          }
        },
        "a604fdbb0f73499a82ff7dd5cded6a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d99a03c1870432fa51673562575afc9",
            "max": 2200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5bec0d13e6c044f89edf5fd6ec4f48b5",
            "value": 2200
          }
        },
        "6e380d56244a4f3182f5184d61f48c6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5585d52d1b7b4c878d2758f890de720d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_eeaafd0cc7c24593bf3c082abcaec67c",
            "value": "â€‡2200/2200â€‡[00:22&lt;00:00,â€‡98.09â€‡examples/s]"
          }
        },
        "b216049803e34e4da8658cb73541d9e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec1bc30bc07c421ba907067e76af1468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b2ac1f103e2468dad395f89b422c295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d99a03c1870432fa51673562575afc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bec0d13e6c044f89edf5fd6ec4f48b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5585d52d1b7b4c878d2758f890de720d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeaafd0cc7c24593bf3c082abcaec67c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e60a5dcb2b54f65b8a8b8a21b5351c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b07bc3f29d9f4b009e55676da5255b28",
              "IPY_MODEL_8ca404ca254a4ee89d5b11f90b8c25df",
              "IPY_MODEL_b08098d580fc417f8c2e03b7b4151a16"
            ],
            "layout": "IPY_MODEL_e67dc36f9bc346c8b3496df486844318"
          }
        },
        "b07bc3f29d9f4b009e55676da5255b28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebf81f588de4427e840f915f76899904",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a5460fb158dd466891b68ef227e05137",
            "value": "Filter:â€‡100%"
          }
        },
        "8ca404ca254a4ee89d5b11f90b8c25df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3532daa9ad84be5bb739cb05e44978f",
            "max": 2200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f25d0b5631949a3b36cafd59f9e9696",
            "value": 2200
          }
        },
        "b08098d580fc417f8c2e03b7b4151a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_902b043560ee49068cc1a2c124abf0e4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d7c732fd4bf44bd18eb15a85e9362075",
            "value": "â€‡2200/2200â€‡[00:29&lt;00:00,â€‡76.18â€‡examples/s]"
          }
        },
        "e67dc36f9bc346c8b3496df486844318": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebf81f588de4427e840f915f76899904": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5460fb158dd466891b68ef227e05137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3532daa9ad84be5bb739cb05e44978f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f25d0b5631949a3b36cafd59f9e9696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "902b043560ee49068cc1a2c124abf0e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7c732fd4bf44bd18eb15a85e9362075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e550b537515446a898ed4486c66e802f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f325849bbfd422aa6042ad90bb33f62",
              "IPY_MODEL_1f726dd291a04598aadf70ad01a533eb",
              "IPY_MODEL_1b3a9d74e0714994b47729e364a73fb9"
            ],
            "layout": "IPY_MODEL_5e037ad3ea9d43eea24b4a3da0b1562d"
          }
        },
        "7f325849bbfd422aa6042ad90bb33f62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23082ccbb3514e20bde3bae0b816c45a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_134b255f433540b9ad29756548865eb4",
            "value": "Map:â€‡100%"
          }
        },
        "1f726dd291a04598aadf70ad01a533eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4cf457752d847a4b4e49e1c5e84505e",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfbb2a4e7c6547c7b2f68d614ab4d3a8",
            "value": 10
          }
        },
        "1b3a9d74e0714994b47729e364a73fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e1183f49ae04988ae061d0442cc6ba6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f6cdd7c1e28b485d8fc6bbf7034eb4f4",
            "value": "â€‡10/10â€‡[00:00&lt;00:00,â€‡696.74â€‡examples/s]"
          }
        },
        "5e037ad3ea9d43eea24b4a3da0b1562d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23082ccbb3514e20bde3bae0b816c45a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "134b255f433540b9ad29756548865eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4cf457752d847a4b4e49e1c5e84505e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfbb2a4e7c6547c7b2f68d614ab4d3a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e1183f49ae04988ae061d0442cc6ba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6cdd7c1e28b485d8fc6bbf7034eb4f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fafb116911f44c5a903c74b669d4de18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e1b76f88ffd49ed92eb936896b4faa4",
              "IPY_MODEL_cf68ad9049bd46018262af06ec08a703",
              "IPY_MODEL_344098131b3d4feaa41c36e93a18c26d"
            ],
            "layout": "IPY_MODEL_a1f226ab8ff643d79484ef24575c4ac1"
          }
        },
        "0e1b76f88ffd49ed92eb936896b4faa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8483b62b218b4771bd910257be6c54ba",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_68ebb47f46484c33bd6c0567b69297e8",
            "value": "Map:â€‡100%"
          }
        },
        "cf68ad9049bd46018262af06ec08a703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05032c967be64a0b98d64235b2fc00ff",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_674f46ff32d94a588db46a82f172ce5f",
            "value": 10
          }
        },
        "344098131b3d4feaa41c36e93a18c26d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5da0a147c4f64077b304f2c8ce483a43",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9997a3198a6d42389082196ba5901445",
            "value": "â€‡10/10â€‡[00:00&lt;00:00,â€‡152.25â€‡examples/s]"
          }
        },
        "a1f226ab8ff643d79484ef24575c4ac1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8483b62b218b4771bd910257be6c54ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68ebb47f46484c33bd6c0567b69297e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05032c967be64a0b98d64235b2fc00ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "674f46ff32d94a588db46a82f172ce5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5da0a147c4f64077b304f2c8ce483a43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9997a3198a6d42389082196ba5901445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d3c46b3ee954c17aa570bab9e414663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4900dd6397524ec38bb3974f9d6e7bdd",
              "IPY_MODEL_040a096bf83c4a6094301547c4223c5b",
              "IPY_MODEL_df7fcb3cd9a0440892fb21bddff646de"
            ],
            "layout": "IPY_MODEL_0055b6e3fa114511b5f40f0bb4340744"
          }
        },
        "4900dd6397524ec38bb3974f9d6e7bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_274c449c40a4407194849347c5908063",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0a3534d1e7c64ed997a83c8963244b4d",
            "value": "Filter:â€‡100%"
          }
        },
        "040a096bf83c4a6094301547c4223c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6667f9868a66486eba943d39d4fc0c9e",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6efbd171c2164e64b01870dbe9b21c3e",
            "value": 10
          }
        },
        "df7fcb3cd9a0440892fb21bddff646de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_154a1affbf204fbc8e9ee324678d3c94",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9a176c27c3454cf4b5b9fab6f8bbfe60",
            "value": "â€‡10/10â€‡[00:00&lt;00:00,â€‡185.62â€‡examples/s]"
          }
        },
        "0055b6e3fa114511b5f40f0bb4340744": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "274c449c40a4407194849347c5908063": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a3534d1e7c64ed997a83c8963244b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6667f9868a66486eba943d39d4fc0c9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6efbd171c2164e64b01870dbe9b21c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "154a1affbf204fbc8e9ee324678d3c94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a176c27c3454cf4b5b9fab6f8bbfe60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}