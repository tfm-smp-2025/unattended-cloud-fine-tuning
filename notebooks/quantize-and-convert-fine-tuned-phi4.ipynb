{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a3406b7d",
      "metadata": {
        "id": "a3406b7d"
      },
      "source": [
        "# Model conversion to GGUF notebook"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start time\n",
        "!date"
      ],
      "metadata": {
        "id": "1sQhHMM3hH56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2015437d-58ce-4e32-b971-4df0fa57f490"
      },
      "id": "1sQhHMM3hH56",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat May  3 06:11:07 PM UTC 2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = \"1746028477\"\n",
        "checkpoint = \"300\""
      ],
      "metadata": {
        "id": "alEj6AtEVZpq"
      },
      "id": "alEj6AtEVZpq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "_xDYWzO-Yayb"
      },
      "id": "_xDYWzO-Yayb"
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "def get_secret(prompt, secret_name, secret_input=True):\n",
        "  try:\n",
        "    from google.colab import userdata\n",
        "    result = userdata.get(secret_name)\n",
        "    assert result is not None\n",
        "  except:\n",
        "    if secret_input:\n",
        "      result = getpass(prompt)\n",
        "    else:\n",
        "      result = input(prompt)\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "oXM0JQXeWrlv"
      },
      "id": "oXM0JQXeWrlv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth\n",
        "    !pip install -U transformers\n",
        "\n",
        "from unsloth import FastLanguageModel  # Load unsloth ASAP"
      ],
      "metadata": {
        "id": "YAkKPixLWuZA"
      },
      "id": "YAkKPixLWuZA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download pre-trained checkpoint"
      ],
      "metadata": {
        "id": "3oyvCKsOXCbq"
      },
      "id": "3oyvCKsOXCbq"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if (\n",
        "    (not os.path.exists(os.path.expanduser(\"~/.ssh/id_rsa\")))\n",
        "    or (not os.path.exists(os.path.expanduser(\"~/.ssh/known_hosts\")))\n",
        "):\n",
        "  SSHKEY = get_secret('Result pusher SSH key: ', 'TFM_SSH_PUSHER_KEY')\n",
        "\n",
        "  !mkdir ~/.ssh\n",
        "\n",
        "  # Read locally with `cat ~/.ssh/result-pusher|tr '\\n' '$';echo`\n",
        "  with open(os.path.expanduser(\"~/.ssh/id_rsa\"), 'wt') as f:\n",
        "    f.write(SSHKEY.replace('$', '\\n'))\n",
        "\n",
        "  !chmod 0600 ~/.ssh/id_rsa\n",
        "  !ssh-keygen -y -f ~/.ssh/id_rsa > ~/.ssh/id_rsa.pub\n",
        "  !chmod 0600 ~/.ssh/id_rsa.pub\n",
        "\n",
        "  # This won't copy the client key (not needed), but it will initialize the server's on the client\n",
        "  !ssh-copy-id -i ~/.ssh/id_rsa -o StrictHostKeyChecking=accept-new result-pusher@kb.tfm.codigoparallevar.com\n",
        "\n",
        "  del SSHKEY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owXoATDXXJD5",
        "outputId": "44c9f448-2bde-4fba-caa7-863843b5b579"
      },
      "id": "owXoATDXXJD5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: \"/root/.ssh/id_rsa.pub\"\n",
            "/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n",
            "\n",
            "/usr/bin/ssh-copy-id: WARNING: All keys were skipped because they already exist on the remote system.\n",
            "\t\t(if you think this is a mistake, you may want to use -f option)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rsync -HPrz --mkpath \\\n",
        "  result-pusher@kb.tfm.codigoparallevar.com:fine-tuning/fine-tuned/peft-kbs-summary-training-\"$trainset\"/checkpoint-\"$checkpoint\"/ \\\n",
        "    fine-tune"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEbcZ6xaXEmk",
        "outputId": "ffc5e837-b634-45de-a07a-4d669b640e59"
      },
      "id": "vEbcZ6xaXEmk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "receiving incremental file list\n",
            "created 1 directory for fine-tune\n",
            "README.md\n",
            "          5,104 100%    4.87MB/s    0:00:00 (xfr#1, to-chk=12/14)\n",
            "adapter_config.json\n",
            "            860 100%  839.84kB/s    0:00:00 (xfr#2, to-chk=11/14)\n",
            "adapter_model.safetensors\n",
            "    262,219,392 100%   10.80MB/s    0:00:23 (xfr#3, to-chk=10/14)\n",
            "merges.txt\n",
            "        916,646 100%    1.47MB/s    0:00:00 (xfr#4, to-chk=9/14)\n",
            "optimizer.pt\n",
            "    133,785,108 100%   10.75MB/s    0:00:11 (xfr#5, to-chk=8/14)\n",
            "rng_state.pth\n",
            "         14,244 100%   24.23kB/s    0:00:00 (xfr#6, to-chk=7/14)\n",
            "scheduler.pt\n",
            "          1,064 100%    1.81kB/s    0:00:00 (xfr#7, to-chk=6/14)\n",
            "special_tokens_map.json\n",
            "            456 100%    0.78kB/s    0:00:00 (xfr#8, to-chk=5/14)\n",
            "tokenizer.json\n",
            "      7,153,264 100%    8.92MB/s    0:00:00 (xfr#9, to-chk=4/14)\n",
            "tokenizer_config.json\n",
            "         17,987 100%   22.96kB/s    0:00:00 (xfr#10, to-chk=3/14)\n",
            "trainer_state.json\n",
            "          3,599 100%    4.59kB/s    0:00:00 (xfr#11, to-chk=2/14)\n",
            "training_args.bin\n",
            "          5,304 100%    6.77kB/s    0:00:00 (xfr#12, to-chk=1/14)\n",
            "vocab.json\n",
            "      1,612,637 100%    1.95MB/s    0:00:00 (xfr#13, to-chk=0/14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load pre-trained model"
      ],
      "metadata": {
        "id": "T6lQKiO2XAyX"
      },
      "id": "T6lQKiO2XAyX"
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "device_map = {\"\": 0}\n",
        "\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Phi-4\",\n",
        "    max_seq_length = 16384, # max_seq_length,\n",
        "    load_in_4bit = True, # load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")\n",
        "\n",
        "ft_model = PeftModel.from_pretrained(model, \"fine-tune\",torch_dtype=torch.float16,is_trainable=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473,
          "referenced_widgets": [
            "da1e0e96aa144a798541d7021de8ee2d",
            "789a211d73294223aae6a93f0b2ad666",
            "14a6bf0fd57c4a1dafb3ce8afa487a11",
            "7cb1e33c186540baa76b73f0f27a1444",
            "1b64006bfb094535a5d8f507d38e926d",
            "e16ebd0ceb244e2999f8b45b1d6a5d4a",
            "0171dd8e02f94f3c9770159fe77c0ae1",
            "348366bfedfd4d38b5b1e0efb4c15f99",
            "9d35fcc00c6048c79eec9f701e827cdd",
            "ea3663b893b140bebef9f215c3d7222e",
            "3a7b80fc3d63473f807d72c703d8c8bc",
            "52d3d7c09351476bada7aa6309f9b700",
            "5c966294dcc040ffb47fff17ee1e7794",
            "57ccf366c7e54fb89857af6c61ee062b",
            "bedfe1b58d84435982c5ccc5e882c2ec",
            "1c90046f66c04f548ec21e581dbb65d5",
            "c3c28a57266444ea97c8307d3938e754",
            "d11fd59f2de4493ba5774523b8d1f892",
            "0f8d184bfe0340f9a71c57fd24eb089a",
            "48b13710f3bd44fbb19c776f28230d6b",
            "ff810debb7dd41e4bfd70c98bd6a5b6d",
            "f7fcd4d09f47491bb842d953c59a8b07",
            "6bb15c3ee8bf41518c581f4aa945942c",
            "bbb79041d24c4b00af46d290bacb64e9",
            "cfb668fa2d324b89b20a8a0ac0c1e106",
            "85b1535c3c5848d594351f2ebf56949c",
            "cc5bcdb355794491b288be225e199434",
            "a19a78ed043c445fa120747f3c26c0f0",
            "f2f0e23380b545b799213fef18f9fd35",
            "ab87765f60d74fba945c9f4ce0719065",
            "421bf6807b2d48169d7b79a060ab6502",
            "f4e2cd70e0b84798a6bdc93e09eb32bf",
            "c8f8bc6c46f042eebb8cbcb5a361412e",
            "d475f308822c4f3b8d2597ea60afa27f",
            "a999356802c047e8bbb332d195e3f7c7",
            "91cb3960cfd1498ca0e8a3e1f75e05f5",
            "a9983e9a1423410abe45511207257f90",
            "9cc3fda2bde4454f8388e996104b86eb",
            "916bb57105a441bfbab0f97495300a7b",
            "07eee58de85c48909665e2c8e68368b6",
            "636ba33657e14b3dbcfd1b877a95faa4",
            "ae82803af26f470a93443320805243a7",
            "0dca66594c194d159859bfb256910f45",
            "5a1254419652497fbef549edcc5483bf",
            "e9c85391c41d47b781e191f463f312ef",
            "53dbdef7d954414eaf68367d90f1ffe5",
            "e02a6b3fb16a4a0c90df8e7d3bcaaf86",
            "61826767fc4541b1919e762060762a31",
            "0739a022a06341c995917b34b4de5430",
            "aaa5446c1dea46edb364dd5f759c9155",
            "e09bb7fecb7c491a93666c63fb16c771",
            "f6575e35ae99423aa75fd2159e8aa259",
            "f4b0583e06254dbe8c547ed96ed9f4d4",
            "9d9cb77857374142a14f55b7d0343a49",
            "f0eec27cba9e495ea75d1359f126da07",
            "faaec21ce05646fa85eb95b56ecd51b1",
            "d34eee80557b4d809b5b83e80bbdf5f8",
            "2371c31abc4841339cdebe98f05a8cc6",
            "961fe80e396541fe968b297db1b94bac",
            "1a9c71254e2044028f12a897d3ea560a",
            "6fc06a83fcbe49089d2190c75cdc48b1",
            "c43508f87bc34ac1ad543b7f6f298dc3",
            "b88f3349a3ee4d71a737794d173d1dd1",
            "7daa3d0f0fb042f1bab9fc749099020f",
            "29387149dd6d45569308a909f31839fb",
            "f990c940b1f84af78c250913e9363470",
            "e0531140310c4f3db2faaf3bd4db9901",
            "152c245035fc4eeeab040365202fda0d",
            "423d4c6f85dc4157a9a90fccb1fc0e50",
            "e25baa59a3994baa81783440a6d2c415",
            "7dead343cc6542e99286f885606b48cf",
            "2ecd0a59215149d2bd75bfdb17bede1d",
            "ab4fe048057c47d386d622adbd8a4847",
            "1d5d54e2754f4c5e822b4e50dd4b7338",
            "88ebc276d3d348ea94d4af3251f08df6",
            "61250ee2c54b49ffbcb75cb58183184f",
            "17bc05b207454d76912e263982ae08ee",
            "17f1e76373754a91b035afe61d03f789",
            "d7eed0475371497c8cf7ff40d9a7b69c",
            "8dd035d740b043a581679123856f482d",
            "06011da2d7f84281b19efe87749c2106",
            "4a6d97fd49594eae8a61e460d3e82abf",
            "c038657e1c11442ca47d1a3b5ebdaf5e",
            "361ce585e6ed4167b37b2e8c79f45055",
            "48b282bde0814d8a8af4b72ade5597f1",
            "327db717bdaa4c648458844c7ed7d740",
            "1f5f741df9cc446883e8f4e83e467406",
            "b8fb4d89eb354abd80268556e9625388",
            "82f7734abb8f4cc69d3bf06e6c1c543f",
            "b95c7a029d1c4e4c90fdd26c0884d7a9",
            "b5900a10ff574ccdb407e7d975a87081",
            "d9b516a068384619b1c83801291d6bb1",
            "4b7e818addb7455886809b9cffbccc57",
            "58f64fda00df451e9f7ce6e2dc58b30d",
            "6f2bb29a23124ad7b9061491a92074b0",
            "c031a61d2f5948ed864796219c76ff3f",
            "e58b3bdd86764b218ed376dc40505217",
            "89c3a3adc8794600b98811c6b2f91351",
            "3f3931ef0b3d4ae7a149ecb406040fc5",
            "df2c1e3e6c1143a1ae63ffba330fed27",
            "9e3abfc70080433ebb87d178f8ac03e8",
            "bf4bdb6ac0014327ab2671c59fb9f144",
            "e8c94702f9bf4f4b8c3d7b01f1600a6c",
            "399e2fa79cbd42fb989d50320d301792",
            "48f6cf07cadf4b86a27f4d6be9925772",
            "c3e66565e11f4fde8af1a2a669941a1a",
            "37da0ca70a554cf49f74c42802a362b9",
            "08b892f93c424477842416e3710c327b",
            "8bb525bb27d64502b69f788b182b5156",
            "2c2547ef6ed642adbb765e22f55a6305",
            "cfb70ee962774999af63ef72cd71fb67",
            "eb2084ded735469da694dcc98512d46e",
            "29b5131dbb3a4d0d9eb77ef10052160d",
            "6e6a6c07b8964da6bc5afa2640fee35c",
            "06e59b9399dc4aa6beefa422f2c95222",
            "d30cfccffe774021bc00dddb200f9bf0",
            "076475346ca44828805fd32b30359e65",
            "bc8a0bc571ff4a8dbd2bff029f3c9c3f",
            "5d6b94e831c541a48ad062fe1eaa3c3a",
            "1fd1ef2431dd4ec997c0b088d6eac2fa",
            "dfe5b4c1914b42e8879780cd403a5bf1"
          ]
        },
        "id": "w8D_JMuYXE-Q",
        "outputId": "ff656656-0267-41b5-8a53-51c68f60c1b6"
      },
      "id": "w8D_JMuYXE-Q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.4.7: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/160k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da1e0e96aa144a798541d7021de8ee2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52d3d7c09351476bada7aa6309f9b700"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/4.39G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6bb15c3ee8bf41518c581f4aa945942c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/1.03G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d475f308822c4f3b8d2597ea60afa27f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9c85391c41d47b781e191f463f312ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/170 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "faaec21ce05646fa85eb95b56ecd51b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/18.0k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0531140310c4f3db2faaf3bd4db9901"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.61M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17f1e76373754a91b035afe61d03f789"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/917k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82f7734abb8f4cc69d3bf06e6c1c543f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df2c1e3e6c1143a1ae63ffba330fed27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/7.15M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfb70ee962774999af63ef72cd71fb67"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save to GGUF"
      ],
      "metadata": {
        "id": "XTLWpEVmXr_l"
      },
      "id": "XTLWpEVmXr_l"
    },
    {
      "cell_type": "code",
      "source": [
        "outname = f\"phi-4-{trainset}-cp-{checkpoint}\""
      ],
      "metadata": {
        "id": "WJ36yQ1wUgri"
      },
      "id": "WJ36yQ1wUgri",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model.save_pretrained_gguf(outname, tokenizer, quantization_method = [ \"f16\" ]) # , \"q4_k_m\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ4C_IfgXraP",
        "outputId": "ce0628d1-b199-4801-cd40-ceb727ed52e0"
      },
      "id": "yJ4C_IfgXraP",
      "execution_count": 12,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 37.37 out of 52.96 RAM for saving.\n",
            "Unsloth: Saving model... This might take 5 minutes ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:48<00:00,  1.20s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Done.\n",
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['f16', 'q4_k_m', 'q6_k'] might take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
            "Unsloth: [1] Converting model at phi-4-1746474294-cp-855 into f16 GGUF format.\n",
            "The output location will be /content/phi-4-1746474294-cp-855/unsloth.F16.gguf\n",
            "This might take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: phi-4-1746474294-cp-855\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 16384\n",
            "INFO:hf-to-gguf:gguf: embedding length = 5120\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 17920\n",
            "INFO:hf-to-gguf:gguf: head count = 40\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 10\n",
            "INFO:hf-to-gguf:gguf: rope theta = 250000\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
            "INFO:hf-to-gguf:gguf: file type = 1\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:numexpr.utils:NumExpr defaulting to 12 threads.\n",
            "INFO:gguf.vocab:Adding 100000 merge(s).\n",
            "INFO:gguf.vocab:Setting special token type bos to 100257\n",
            "INFO:gguf.vocab:Setting special token type eos to 100265\n",
            "INFO:gguf.vocab:Setting special token type unk to 5809\n",
            "INFO:gguf.vocab:Setting special token type pad to 100351\n",
            "INFO:gguf.vocab:Setting chat_template to {% for message in messages %}{% if (message['role'] == 'system') %}{{'<|im_start|>system<|im_sep|>' + message['content'] + '<|im_end|>'}}{% elif (message['role'] == 'user') %}{{'<|im_start|>user<|im_sep|>' + message['content'] + '<|im_end|>'}}{% elif (message['role'] == 'assistant') %}{{'<|im_start|>assistant<|im_sep|>' + message['content'] + '<|im_end|>'}}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant<|im_sep|>' }}{% endif %}\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00006.safetensors'\n",
            "INFO:hf-to-gguf:token_embd.weight,           torch.bfloat16 --> F16, shape = {5120, 100352}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00006.safetensors'\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00006.safetensors'\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00004-of-00006.safetensors'\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00005-of-00006.safetensors'\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.32.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.32.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.32.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.32.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.32.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.32.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.32.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.32.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.32.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.33.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.33.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.33.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.33.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.33.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.33.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.33.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.33.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.33.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.34.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.34.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.34.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.34.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.34.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.34.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00006-of-00006.safetensors'\n",
            "INFO:hf-to-gguf:output.weight,               torch.bfloat16 --> F16, shape = {5120, 100352}\n",
            "INFO:hf-to-gguf:blk.34.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.34.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.34.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.35.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.35.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.35.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.35.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.35.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.35.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.35.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.35.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.35.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.36.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.36.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.36.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.36.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.36.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.36.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.36.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.36.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.36.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.37.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.37.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.37.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.37.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.37.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.37.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.37.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.37.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.37.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.38.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.38.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.38.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.38.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.38.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.38.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.38.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.38.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.38.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.39.attn_norm.weight,     torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.39.ffn_down.weight,      torch.bfloat16 --> F16, shape = {17920, 5120}\n",
            "INFO:hf-to-gguf:blk.39.ffn_gate.weight,      torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.39.ffn_up.weight,        torch.bfloat16 --> F16, shape = {5120, 17920}\n",
            "INFO:hf-to-gguf:blk.39.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:hf-to-gguf:blk.39.attn_k.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:blk.39.attn_output.weight,   torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.39.attn_q.weight,        torch.bfloat16 --> F16, shape = {5120, 5120}\n",
            "INFO:hf-to-gguf:blk.39.attn_v.weight,        torch.bfloat16 --> F16, shape = {5120, 1280}\n",
            "INFO:hf-to-gguf:output_norm.weight,          torch.bfloat16 --> F32, shape = {5120}\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/content/phi-4-1746474294-cp-855/unsloth.F16.gguf: n_tensors = 363, total_size = 29.3G\n",
            "Writing: 100%|██████████| 29.3G/29.3G [04:00<00:00, 122Mbyte/s] \n",
            "INFO:hf-to-gguf:Model successfully exported to /content/phi-4-1746474294-cp-855/unsloth.F16.gguf\n",
            "Unsloth: Conversion completed! Output location: /content/phi-4-1746474294-cp-855/unsloth.F16.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This might take 20 minutes...\n",
            "main: build = 3345 (2ee44c9a)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/phi-4-1746474294-cp-855/unsloth.F16.gguf' to '/content/phi-4-1746474294-cp-855/unsloth.Q4_K_M.gguf' as Q4_K_M using 24 threads\n",
            "llama_model_loader: loaded meta data with 25 key-value pairs and 363 tensors from /content/phi-4-1746474294-cp-855/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = phi-4-1746474294-cp-855\n",
            "llama_model_loader: - kv   2:                          llama.block_count u32              = 40\n",
            "llama_model_loader: - kv   3:                       llama.context_length u32              = 16384\n",
            "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 5120\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 17920\n",
            "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 40\n",
            "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 10\n",
            "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 250000.000000\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 100352\n",
            "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  13:            tokenizer.ggml.add_space_prefix bool             = false\n",
            "llama_model_loader: - kv  14:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  15:                         tokenizer.ggml.pre str              = dbrx\n",
            "llama_model_loader: - kv  16:                      tokenizer.ggml.tokens arr[str,100352]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,100352]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  18:                      tokenizer.ggml.merges arr[str,100000]  = [\"Ġ Ġ\", \"ĠĠ ĠĠ\", \"i n\", \"Ġ t\",...\n",
            "llama_model_loader: - kv  19:                tokenizer.ggml.bos_token_id u32              = 100257\n",
            "llama_model_loader: - kv  20:                tokenizer.ggml.eos_token_id u32              = 100265\n",
            "llama_model_loader: - kv  21:            tokenizer.ggml.unknown_token_id u32              = 5809\n",
            "llama_model_loader: - kv  22:            tokenizer.ggml.padding_token_id u32              = 100351\n",
            "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {% for message in messages %}{% if (m...\n",
            "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   81 tensors\n",
            "llama_model_loader: - type  f16:  282 tensors\n",
            "[   1/ 363]                    token_embd.weight - [ 5120, 100352,     1,     1], type =    f16, converting to q4_K .. size =   980.00 MiB ->   275.62 MiB\n",
            "[   2/ 363]               blk.0.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[   3/ 363]                blk.0.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[   4/ 363]                blk.0.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[   5/ 363]                  blk.0.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[   6/ 363]                blk.0.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[   7/ 363]                  blk.0.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[   8/ 363]             blk.0.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[   9/ 363]                  blk.0.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  10/ 363]                  blk.0.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  11/ 363]               blk.1.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  12/ 363]                blk.1.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  13/ 363]                blk.1.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  14/ 363]                  blk.1.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  15/ 363]                blk.1.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  16/ 363]                  blk.1.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  17/ 363]             blk.1.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  18/ 363]                  blk.1.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  19/ 363]                  blk.1.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  20/ 363]               blk.2.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  21/ 363]                blk.2.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  22/ 363]                blk.2.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  23/ 363]                  blk.2.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  24/ 363]                blk.2.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  25/ 363]                  blk.2.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  26/ 363]             blk.2.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  27/ 363]                  blk.2.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  28/ 363]                  blk.2.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  29/ 363]               blk.3.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  30/ 363]                blk.3.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  31/ 363]                blk.3.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  32/ 363]                  blk.3.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  33/ 363]                blk.3.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  34/ 363]                  blk.3.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  35/ 363]             blk.3.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  36/ 363]                  blk.3.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  37/ 363]                  blk.3.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  38/ 363]               blk.4.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  39/ 363]                blk.4.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  40/ 363]                blk.4.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  41/ 363]                  blk.4.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  42/ 363]                blk.4.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  43/ 363]                  blk.4.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  44/ 363]             blk.4.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  45/ 363]                  blk.4.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  46/ 363]                  blk.4.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  47/ 363]                blk.5.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  48/ 363]                  blk.5.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  49/ 363]                  blk.5.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  50/ 363]             blk.5.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  51/ 363]                  blk.5.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  52/ 363]                  blk.5.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  53/ 363]              blk.10.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  54/ 363]               blk.10.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  55/ 363]               blk.10.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  56/ 363]                 blk.10.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  57/ 363]               blk.10.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  58/ 363]                 blk.10.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  59/ 363]            blk.10.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  60/ 363]                 blk.10.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  61/ 363]                 blk.10.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  62/ 363]              blk.11.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  63/ 363]               blk.11.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  64/ 363]               blk.11.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  65/ 363]                 blk.11.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  66/ 363]               blk.11.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  67/ 363]                 blk.11.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  68/ 363]            blk.11.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  69/ 363]                 blk.11.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  70/ 363]                 blk.11.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  71/ 363]              blk.12.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  72/ 363]               blk.12.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  73/ 363]               blk.12.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  74/ 363]                 blk.12.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  75/ 363]               blk.12.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  76/ 363]                 blk.12.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  77/ 363]            blk.12.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  78/ 363]                 blk.12.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  79/ 363]                 blk.12.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  80/ 363]               blk.5.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  81/ 363]                blk.5.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  82/ 363]                blk.5.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  83/ 363]               blk.6.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  84/ 363]                blk.6.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  85/ 363]                blk.6.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  86/ 363]                  blk.6.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  87/ 363]                blk.6.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  88/ 363]                  blk.6.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  89/ 363]             blk.6.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  90/ 363]                  blk.6.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  91/ 363]                  blk.6.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  92/ 363]               blk.7.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  93/ 363]                blk.7.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  94/ 363]                blk.7.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  95/ 363]                  blk.7.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[  96/ 363]                blk.7.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  97/ 363]                  blk.7.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  98/ 363]             blk.7.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  99/ 363]                  blk.7.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 100/ 363]                  blk.7.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 101/ 363]               blk.8.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 102/ 363]                blk.8.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 103/ 363]                blk.8.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 104/ 363]                  blk.8.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 105/ 363]                blk.8.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 106/ 363]                  blk.8.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 107/ 363]             blk.8.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 108/ 363]                  blk.8.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 109/ 363]                  blk.8.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 110/ 363]               blk.9.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 111/ 363]                blk.9.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 112/ 363]                blk.9.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 113/ 363]                  blk.9.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 114/ 363]                blk.9.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 115/ 363]                  blk.9.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 116/ 363]             blk.9.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 117/ 363]                  blk.9.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 118/ 363]                  blk.9.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 119/ 363]              blk.13.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 120/ 363]               blk.13.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 121/ 363]               blk.13.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 122/ 363]                 blk.13.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 123/ 363]               blk.13.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 124/ 363]                 blk.13.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 125/ 363]            blk.13.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 126/ 363]                 blk.13.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 127/ 363]                 blk.13.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 128/ 363]              blk.14.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 129/ 363]               blk.14.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 130/ 363]               blk.14.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 131/ 363]                 blk.14.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 132/ 363]               blk.14.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 133/ 363]                 blk.14.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 134/ 363]            blk.14.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 135/ 363]                 blk.14.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 136/ 363]                 blk.14.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 137/ 363]              blk.15.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 138/ 363]               blk.15.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 139/ 363]               blk.15.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 140/ 363]                 blk.15.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 141/ 363]               blk.15.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 142/ 363]                 blk.15.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 143/ 363]            blk.15.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 144/ 363]                 blk.15.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 145/ 363]                 blk.15.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 146/ 363]              blk.16.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 147/ 363]               blk.16.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 148/ 363]               blk.16.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 149/ 363]                 blk.16.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 150/ 363]               blk.16.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 151/ 363]                 blk.16.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 152/ 363]            blk.16.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 153/ 363]                 blk.16.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 154/ 363]                 blk.16.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 155/ 363]              blk.17.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 156/ 363]               blk.17.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 157/ 363]               blk.17.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 158/ 363]                 blk.17.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 159/ 363]               blk.17.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 160/ 363]                 blk.17.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 161/ 363]            blk.17.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 162/ 363]                 blk.17.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 163/ 363]                 blk.17.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 164/ 363]              blk.18.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 165/ 363]               blk.18.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 166/ 363]               blk.18.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 167/ 363]                 blk.18.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 168/ 363]               blk.18.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 169/ 363]                 blk.18.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 170/ 363]            blk.18.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 171/ 363]                 blk.18.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 172/ 363]                 blk.18.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 173/ 363]              blk.19.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 174/ 363]               blk.19.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 175/ 363]               blk.19.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 176/ 363]                 blk.19.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 177/ 363]               blk.19.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 178/ 363]                 blk.19.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 179/ 363]            blk.19.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 180/ 363]                 blk.19.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 181/ 363]                 blk.19.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 182/ 363]                 blk.20.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 183/ 363]            blk.20.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 184/ 363]                 blk.20.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 185/ 363]                 blk.20.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 186/ 363]              blk.20.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 187/ 363]               blk.20.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 188/ 363]               blk.20.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 189/ 363]                 blk.20.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 190/ 363]               blk.20.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 191/ 363]              blk.21.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 192/ 363]               blk.21.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 193/ 363]               blk.21.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 194/ 363]                 blk.21.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 195/ 363]               blk.21.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 196/ 363]                 blk.21.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 197/ 363]            blk.21.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 198/ 363]                 blk.21.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 199/ 363]                 blk.21.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 200/ 363]              blk.22.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 201/ 363]               blk.22.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 202/ 363]               blk.22.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 203/ 363]                 blk.22.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 204/ 363]               blk.22.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 205/ 363]                 blk.22.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 206/ 363]            blk.22.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 207/ 363]                 blk.22.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 208/ 363]                 blk.22.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 209/ 363]              blk.23.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 210/ 363]               blk.23.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 211/ 363]               blk.23.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 212/ 363]                 blk.23.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 213/ 363]               blk.23.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 214/ 363]                 blk.23.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 215/ 363]            blk.23.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 216/ 363]                 blk.23.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 217/ 363]                 blk.23.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 218/ 363]              blk.24.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 219/ 363]               blk.24.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 220/ 363]               blk.24.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 221/ 363]                 blk.24.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 222/ 363]               blk.24.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 223/ 363]                 blk.24.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 224/ 363]            blk.24.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 225/ 363]                 blk.24.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 226/ 363]                 blk.24.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 227/ 363]              blk.25.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 228/ 363]               blk.25.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 229/ 363]               blk.25.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 230/ 363]                 blk.25.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 231/ 363]               blk.25.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 232/ 363]                 blk.25.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 233/ 363]            blk.25.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 234/ 363]                 blk.25.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 235/ 363]                 blk.25.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 236/ 363]              blk.26.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 237/ 363]               blk.26.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 238/ 363]               blk.26.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 239/ 363]                 blk.26.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 240/ 363]               blk.26.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 241/ 363]                 blk.26.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 242/ 363]            blk.26.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 243/ 363]                 blk.26.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 244/ 363]                 blk.26.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 245/ 363]               blk.27.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 246/ 363]                 blk.27.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 247/ 363]            blk.27.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 248/ 363]                 blk.27.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 249/ 363]                 blk.27.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 250/ 363]              blk.27.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 251/ 363]               blk.27.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 252/ 363]                 blk.27.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 253/ 363]               blk.27.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 254/ 363]              blk.28.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 255/ 363]               blk.28.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 256/ 363]               blk.28.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 257/ 363]                 blk.28.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 258/ 363]               blk.28.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 259/ 363]                 blk.28.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 260/ 363]            blk.28.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 261/ 363]                 blk.28.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 262/ 363]                 blk.28.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 263/ 363]              blk.29.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 264/ 363]               blk.29.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 265/ 363]               blk.29.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 266/ 363]                 blk.29.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 267/ 363]               blk.29.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 268/ 363]                 blk.29.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 269/ 363]            blk.29.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 270/ 363]                 blk.29.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 271/ 363]                 blk.29.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 272/ 363]              blk.30.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 273/ 363]               blk.30.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 274/ 363]               blk.30.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 275/ 363]                 blk.30.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 276/ 363]               blk.30.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 277/ 363]                 blk.30.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 278/ 363]            blk.30.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 279/ 363]                 blk.30.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 280/ 363]                 blk.30.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 281/ 363]              blk.31.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 282/ 363]               blk.31.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 283/ 363]               blk.31.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 284/ 363]                 blk.31.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 285/ 363]               blk.31.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 286/ 363]                 blk.31.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 287/ 363]            blk.31.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 288/ 363]                 blk.31.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 289/ 363]                 blk.31.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 290/ 363]              blk.32.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 291/ 363]               blk.32.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 292/ 363]               blk.32.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 293/ 363]                 blk.32.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 294/ 363]               blk.32.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 295/ 363]                 blk.32.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 296/ 363]            blk.32.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 297/ 363]                 blk.32.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 298/ 363]                 blk.32.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 299/ 363]              blk.33.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 300/ 363]               blk.33.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 301/ 363]               blk.33.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 302/ 363]                 blk.33.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 303/ 363]               blk.33.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 304/ 363]                 blk.33.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 305/ 363]            blk.33.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 306/ 363]                 blk.33.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 307/ 363]                 blk.33.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 308/ 363]               blk.34.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 309/ 363]                 blk.34.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 310/ 363]                 blk.34.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 311/ 363]            blk.34.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 312/ 363]                 blk.34.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 313/ 363]                 blk.34.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 314/ 363]                        output.weight - [ 5120, 100352,     1,     1], type =    f16, converting to q6_K .. size =   980.00 MiB ->   401.95 MiB\n",
            "[ 315/ 363]              blk.34.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 316/ 363]               blk.34.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 317/ 363]               blk.34.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 318/ 363]              blk.35.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 319/ 363]               blk.35.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 320/ 363]               blk.35.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 321/ 363]                 blk.35.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 322/ 363]               blk.35.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 323/ 363]                 blk.35.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 324/ 363]            blk.35.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 325/ 363]                 blk.35.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 326/ 363]                 blk.35.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 327/ 363]              blk.36.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 328/ 363]               blk.36.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 329/ 363]               blk.36.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 330/ 363]                 blk.36.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 331/ 363]               blk.36.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 332/ 363]                 blk.36.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 333/ 363]            blk.36.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 334/ 363]                 blk.36.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 335/ 363]                 blk.36.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 336/ 363]              blk.37.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 337/ 363]               blk.37.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 338/ 363]               blk.37.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 339/ 363]                 blk.37.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 340/ 363]               blk.37.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 341/ 363]                 blk.37.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 342/ 363]            blk.37.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 343/ 363]                 blk.37.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 344/ 363]                 blk.37.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 345/ 363]              blk.38.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 346/ 363]               blk.38.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 347/ 363]               blk.38.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 348/ 363]                 blk.38.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 349/ 363]               blk.38.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 350/ 363]                 blk.38.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 351/ 363]            blk.38.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 352/ 363]                 blk.38.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 353/ 363]                 blk.38.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 354/ 363]              blk.39.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 355/ 363]               blk.39.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 356/ 363]               blk.39.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 357/ 363]                 blk.39.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q4_K .. size =   175.00 MiB ->    49.22 MiB\n",
            "[ 358/ 363]               blk.39.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 359/ 363]                 blk.39.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q4_K .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 360/ 363]            blk.39.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 361/ 363]                 blk.39.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 362/ 363]                 blk.39.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 363/ 363]                   output_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "llama_model_quantize_internal: model size  = 27961.58 MB\n",
            "llama_model_quantize_internal: quant size  =  8475.06 MB\n",
            "\n",
            "main: quantize time = 386040.38 ms\n",
            "main:    total time = 386040.38 ms\n",
            "Unsloth: Conversion completed! Output location: /content/phi-4-1746474294-cp-855/unsloth.Q4_K_M.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q6_k. This might take 20 minutes...\n",
            "main: build = 3345 (2ee44c9a)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/phi-4-1746474294-cp-855/unsloth.F16.gguf' to '/content/phi-4-1746474294-cp-855/unsloth.Q6_K.gguf' as Q6_K using 24 threads\n",
            "llama_model_loader: loaded meta data with 25 key-value pairs and 363 tensors from /content/phi-4-1746474294-cp-855/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = phi-4-1746474294-cp-855\n",
            "llama_model_loader: - kv   2:                          llama.block_count u32              = 40\n",
            "llama_model_loader: - kv   3:                       llama.context_length u32              = 16384\n",
            "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 5120\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 17920\n",
            "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 40\n",
            "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 10\n",
            "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 250000.000000\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 100352\n",
            "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  13:            tokenizer.ggml.add_space_prefix bool             = false\n",
            "llama_model_loader: - kv  14:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  15:                         tokenizer.ggml.pre str              = dbrx\n",
            "llama_model_loader: - kv  16:                      tokenizer.ggml.tokens arr[str,100352]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,100352]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  18:                      tokenizer.ggml.merges arr[str,100000]  = [\"Ġ Ġ\", \"ĠĠ ĠĠ\", \"i n\", \"Ġ t\",...\n",
            "llama_model_loader: - kv  19:                tokenizer.ggml.bos_token_id u32              = 100257\n",
            "llama_model_loader: - kv  20:                tokenizer.ggml.eos_token_id u32              = 100265\n",
            "llama_model_loader: - kv  21:            tokenizer.ggml.unknown_token_id u32              = 5809\n",
            "llama_model_loader: - kv  22:            tokenizer.ggml.padding_token_id u32              = 100351\n",
            "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {% for message in messages %}{% if (m...\n",
            "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   81 tensors\n",
            "llama_model_loader: - type  f16:  282 tensors\n",
            "[   1/ 363]                    token_embd.weight - [ 5120, 100352,     1,     1], type =    f16, converting to q6_K .. size =   980.00 MiB ->   401.95 MiB\n",
            "[   2/ 363]               blk.0.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[   3/ 363]                blk.0.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[   4/ 363]                blk.0.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[   5/ 363]                  blk.0.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[   6/ 363]                blk.0.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[   7/ 363]                  blk.0.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[   8/ 363]             blk.0.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[   9/ 363]                  blk.0.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  10/ 363]                  blk.0.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  11/ 363]               blk.1.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  12/ 363]                blk.1.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  13/ 363]                blk.1.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  14/ 363]                  blk.1.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  15/ 363]                blk.1.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  16/ 363]                  blk.1.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  17/ 363]             blk.1.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  18/ 363]                  blk.1.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  19/ 363]                  blk.1.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  20/ 363]               blk.2.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  21/ 363]                blk.2.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  22/ 363]                blk.2.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  23/ 363]                  blk.2.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  24/ 363]                blk.2.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  25/ 363]                  blk.2.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  26/ 363]             blk.2.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  27/ 363]                  blk.2.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  28/ 363]                  blk.2.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  29/ 363]               blk.3.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  30/ 363]                blk.3.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  31/ 363]                blk.3.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  32/ 363]                  blk.3.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  33/ 363]                blk.3.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  34/ 363]                  blk.3.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  35/ 363]             blk.3.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  36/ 363]                  blk.3.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  37/ 363]                  blk.3.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  38/ 363]               blk.4.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  39/ 363]                blk.4.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  40/ 363]                blk.4.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  41/ 363]                  blk.4.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  42/ 363]                blk.4.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  43/ 363]                  blk.4.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  44/ 363]             blk.4.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  45/ 363]                  blk.4.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  46/ 363]                  blk.4.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  47/ 363]                blk.5.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  48/ 363]                  blk.5.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  49/ 363]                  blk.5.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  50/ 363]             blk.5.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  51/ 363]                  blk.5.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  52/ 363]                  blk.5.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  53/ 363]              blk.10.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  54/ 363]               blk.10.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  55/ 363]               blk.10.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  56/ 363]                 blk.10.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  57/ 363]               blk.10.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  58/ 363]                 blk.10.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  59/ 363]            blk.10.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  60/ 363]                 blk.10.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  61/ 363]                 blk.10.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  62/ 363]              blk.11.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  63/ 363]               blk.11.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  64/ 363]               blk.11.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  65/ 363]                 blk.11.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  66/ 363]               blk.11.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  67/ 363]                 blk.11.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  68/ 363]            blk.11.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  69/ 363]                 blk.11.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  70/ 363]                 blk.11.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  71/ 363]              blk.12.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  72/ 363]               blk.12.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  73/ 363]               blk.12.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  74/ 363]                 blk.12.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  75/ 363]               blk.12.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  76/ 363]                 blk.12.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  77/ 363]            blk.12.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  78/ 363]                 blk.12.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  79/ 363]                 blk.12.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  80/ 363]               blk.5.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  81/ 363]                blk.5.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  82/ 363]                blk.5.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  83/ 363]               blk.6.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  84/ 363]                blk.6.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  85/ 363]                blk.6.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  86/ 363]                  blk.6.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  87/ 363]                blk.6.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  88/ 363]                  blk.6.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  89/ 363]             blk.6.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  90/ 363]                  blk.6.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  91/ 363]                  blk.6.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  92/ 363]               blk.7.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  93/ 363]                blk.7.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  94/ 363]                blk.7.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  95/ 363]                  blk.7.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[  96/ 363]                blk.7.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[  97/ 363]                  blk.7.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  98/ 363]             blk.7.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  99/ 363]                  blk.7.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 100/ 363]                  blk.7.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 101/ 363]               blk.8.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 102/ 363]                blk.8.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 103/ 363]                blk.8.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 104/ 363]                  blk.8.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 105/ 363]                blk.8.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 106/ 363]                  blk.8.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 107/ 363]             blk.8.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 108/ 363]                  blk.8.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 109/ 363]                  blk.8.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 110/ 363]               blk.9.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 111/ 363]                blk.9.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 112/ 363]                blk.9.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 113/ 363]                  blk.9.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 114/ 363]                blk.9.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 115/ 363]                  blk.9.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 116/ 363]             blk.9.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 117/ 363]                  blk.9.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 118/ 363]                  blk.9.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 119/ 363]              blk.13.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 120/ 363]               blk.13.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 121/ 363]               blk.13.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 122/ 363]                 blk.13.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 123/ 363]               blk.13.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 124/ 363]                 blk.13.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 125/ 363]            blk.13.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 126/ 363]                 blk.13.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 127/ 363]                 blk.13.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 128/ 363]              blk.14.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 129/ 363]               blk.14.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 130/ 363]               blk.14.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 131/ 363]                 blk.14.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 132/ 363]               blk.14.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 133/ 363]                 blk.14.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 134/ 363]            blk.14.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 135/ 363]                 blk.14.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 136/ 363]                 blk.14.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 137/ 363]              blk.15.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 138/ 363]               blk.15.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 139/ 363]               blk.15.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 140/ 363]                 blk.15.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 141/ 363]               blk.15.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 142/ 363]                 blk.15.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 143/ 363]            blk.15.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 144/ 363]                 blk.15.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 145/ 363]                 blk.15.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 146/ 363]              blk.16.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 147/ 363]               blk.16.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 148/ 363]               blk.16.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 149/ 363]                 blk.16.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 150/ 363]               blk.16.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 151/ 363]                 blk.16.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 152/ 363]            blk.16.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 153/ 363]                 blk.16.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 154/ 363]                 blk.16.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 155/ 363]              blk.17.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 156/ 363]               blk.17.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 157/ 363]               blk.17.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 158/ 363]                 blk.17.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 159/ 363]               blk.17.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 160/ 363]                 blk.17.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 161/ 363]            blk.17.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 162/ 363]                 blk.17.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 163/ 363]                 blk.17.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 164/ 363]              blk.18.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 165/ 363]               blk.18.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 166/ 363]               blk.18.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 167/ 363]                 blk.18.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 168/ 363]               blk.18.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 169/ 363]                 blk.18.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 170/ 363]            blk.18.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 171/ 363]                 blk.18.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 172/ 363]                 blk.18.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 173/ 363]              blk.19.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 174/ 363]               blk.19.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 175/ 363]               blk.19.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 176/ 363]                 blk.19.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 177/ 363]               blk.19.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 178/ 363]                 blk.19.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 179/ 363]            blk.19.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 180/ 363]                 blk.19.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 181/ 363]                 blk.19.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 182/ 363]                 blk.20.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 183/ 363]            blk.20.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 184/ 363]                 blk.20.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 185/ 363]                 blk.20.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 186/ 363]              blk.20.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 187/ 363]               blk.20.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 188/ 363]               blk.20.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 189/ 363]                 blk.20.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 190/ 363]               blk.20.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 191/ 363]              blk.21.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 192/ 363]               blk.21.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 193/ 363]               blk.21.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 194/ 363]                 blk.21.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 195/ 363]               blk.21.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 196/ 363]                 blk.21.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 197/ 363]            blk.21.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 198/ 363]                 blk.21.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 199/ 363]                 blk.21.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 200/ 363]              blk.22.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 201/ 363]               blk.22.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 202/ 363]               blk.22.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 203/ 363]                 blk.22.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 204/ 363]               blk.22.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 205/ 363]                 blk.22.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 206/ 363]            blk.22.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 207/ 363]                 blk.22.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 208/ 363]                 blk.22.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 209/ 363]              blk.23.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 210/ 363]               blk.23.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 211/ 363]               blk.23.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 212/ 363]                 blk.23.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 213/ 363]               blk.23.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 214/ 363]                 blk.23.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 215/ 363]            blk.23.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 216/ 363]                 blk.23.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 217/ 363]                 blk.23.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 218/ 363]              blk.24.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 219/ 363]               blk.24.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 220/ 363]               blk.24.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 221/ 363]                 blk.24.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 222/ 363]               blk.24.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 223/ 363]                 blk.24.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 224/ 363]            blk.24.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 225/ 363]                 blk.24.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 226/ 363]                 blk.24.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 227/ 363]              blk.25.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 228/ 363]               blk.25.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 229/ 363]               blk.25.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 230/ 363]                 blk.25.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 231/ 363]               blk.25.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 232/ 363]                 blk.25.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 233/ 363]            blk.25.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 234/ 363]                 blk.25.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 235/ 363]                 blk.25.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 236/ 363]              blk.26.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 237/ 363]               blk.26.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 238/ 363]               blk.26.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 239/ 363]                 blk.26.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 240/ 363]               blk.26.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 241/ 363]                 blk.26.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 242/ 363]            blk.26.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 243/ 363]                 blk.26.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 244/ 363]                 blk.26.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 245/ 363]               blk.27.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 246/ 363]                 blk.27.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 247/ 363]            blk.27.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 248/ 363]                 blk.27.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 249/ 363]                 blk.27.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 250/ 363]              blk.27.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 251/ 363]               blk.27.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 252/ 363]                 blk.27.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 253/ 363]               blk.27.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 254/ 363]              blk.28.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 255/ 363]               blk.28.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 256/ 363]               blk.28.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 257/ 363]                 blk.28.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 258/ 363]               blk.28.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 259/ 363]                 blk.28.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 260/ 363]            blk.28.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 261/ 363]                 blk.28.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 262/ 363]                 blk.28.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 263/ 363]              blk.29.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 264/ 363]               blk.29.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 265/ 363]               blk.29.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 266/ 363]                 blk.29.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 267/ 363]               blk.29.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 268/ 363]                 blk.29.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 269/ 363]            blk.29.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 270/ 363]                 blk.29.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 271/ 363]                 blk.29.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 272/ 363]              blk.30.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 273/ 363]               blk.30.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 274/ 363]               blk.30.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 275/ 363]                 blk.30.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 276/ 363]               blk.30.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 277/ 363]                 blk.30.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 278/ 363]            blk.30.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 279/ 363]                 blk.30.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 280/ 363]                 blk.30.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 281/ 363]              blk.31.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 282/ 363]               blk.31.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 283/ 363]               blk.31.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 284/ 363]                 blk.31.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 285/ 363]               blk.31.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 286/ 363]                 blk.31.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 287/ 363]            blk.31.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 288/ 363]                 blk.31.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 289/ 363]                 blk.31.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 290/ 363]              blk.32.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 291/ 363]               blk.32.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 292/ 363]               blk.32.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 293/ 363]                 blk.32.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 294/ 363]               blk.32.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 295/ 363]                 blk.32.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 296/ 363]            blk.32.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 297/ 363]                 blk.32.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 298/ 363]                 blk.32.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 299/ 363]              blk.33.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 300/ 363]               blk.33.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 301/ 363]               blk.33.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 302/ 363]                 blk.33.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 303/ 363]               blk.33.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 304/ 363]                 blk.33.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 305/ 363]            blk.33.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 306/ 363]                 blk.33.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 307/ 363]                 blk.33.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 308/ 363]               blk.34.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 309/ 363]                 blk.34.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 310/ 363]                 blk.34.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 311/ 363]            blk.34.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 312/ 363]                 blk.34.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 313/ 363]                 blk.34.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 314/ 363]                        output.weight - [ 5120, 100352,     1,     1], type =    f16, converting to q6_K .. size =   980.00 MiB ->   401.95 MiB\n",
            "[ 315/ 363]              blk.34.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 316/ 363]               blk.34.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 317/ 363]               blk.34.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 318/ 363]              blk.35.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 319/ 363]               blk.35.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 320/ 363]               blk.35.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 321/ 363]                 blk.35.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 322/ 363]               blk.35.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 323/ 363]                 blk.35.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 324/ 363]            blk.35.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 325/ 363]                 blk.35.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 326/ 363]                 blk.35.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 327/ 363]              blk.36.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 328/ 363]               blk.36.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 329/ 363]               blk.36.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 330/ 363]                 blk.36.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 331/ 363]               blk.36.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 332/ 363]                 blk.36.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 333/ 363]            blk.36.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 334/ 363]                 blk.36.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 335/ 363]                 blk.36.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 336/ 363]              blk.37.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 337/ 363]               blk.37.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 338/ 363]               blk.37.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 339/ 363]                 blk.37.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 340/ 363]               blk.37.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 341/ 363]                 blk.37.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 342/ 363]            blk.37.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 343/ 363]                 blk.37.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 344/ 363]                 blk.37.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 345/ 363]              blk.38.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 346/ 363]               blk.38.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 347/ 363]               blk.38.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 348/ 363]                 blk.38.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 349/ 363]               blk.38.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 350/ 363]                 blk.38.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 351/ 363]            blk.38.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 352/ 363]                 blk.38.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 353/ 363]                 blk.38.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 354/ 363]              blk.39.attn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 355/ 363]               blk.39.ffn_down.weight - [17920,  5120,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 356/ 363]               blk.39.ffn_gate.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 357/ 363]                 blk.39.ffn_up.weight - [ 5120, 17920,     1,     1], type =    f16, converting to q6_K .. size =   175.00 MiB ->    71.78 MiB\n",
            "[ 358/ 363]               blk.39.ffn_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "[ 359/ 363]                 blk.39.attn_k.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 360/ 363]            blk.39.attn_output.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 361/ 363]                 blk.39.attn_q.weight - [ 5120,  5120,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 362/ 363]                 blk.39.attn_v.weight - [ 5120,  1280,     1,     1], type =    f16, converting to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 363/ 363]                   output_norm.weight - [ 5120,     1,     1,     1], type =    f32, size =    0.020 MB\n",
            "llama_model_quantize_internal: model size  = 27961.58 MB\n",
            "llama_model_quantize_internal: quant size  = 11469.55 MB\n",
            "\n",
            "main: quantize time = 235744.80 ms\n",
            "main:    total time = 235744.80 ms\n",
            "Unsloth: Conversion completed! Output location: /content/phi-4-1746474294-cp-855/unsloth.Q6_K.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload data back"
      ],
      "metadata": {
        "id": "h18Ppwg6bab_"
      },
      "id": "h18Ppwg6bab_"
    },
    {
      "cell_type": "code",
      "source": [
        "rsyncto=\"result-pusher@kb.tfm.codigoparallevar.com:fine-tuning/fine-tuned/peft-kbs-summary-training-\" + trainset + \"/checkpoint-\" + checkpoint + \"/loadable\""
      ],
      "metadata": {
        "id": "baoxIvLPcnh-"
      },
      "id": "baoxIvLPcnh-",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rsync -HPrz --mkpath \"$outname\"/ \"$rsyncto\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7hpcFivbWpE",
        "outputId": "80686843-1374-4937-f638-333aedc7ee6a"
      },
      "id": "p7hpcFivbWpE",
      "execution_count": 14,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sending incremental file list\n",
            "config.json\n",
            "            818 100%    0.00kB/s    0:00:00 (xfr#1, to-chk=16/18)\n",
            "generation_config.json\n",
            "            170 100%  166.02kB/s    0:00:00 (xfr#2, to-chk=15/18)\n",
            "merges.txt\n",
            "        916,646 100%   72.85MB/s    0:00:00 (xfr#3, to-chk=14/18)\n",
            "model-00001-of-00006.safetensors\n",
            "  4,933,658,528 100%   13.39MB/s    0:05:51 (xfr#4, to-chk=13/18)\n",
            "model-00002-of-00006.safetensors\n",
            "  4,954,693,112 100%   13.45MB/s    0:05:51 (xfr#5, to-chk=12/18)\n",
            "model-00003-of-00006.safetensors\n",
            "  4,902,243,992 100%   13.44MB/s    0:05:47 (xfr#6, to-chk=11/18)\n",
            "model-00004-of-00006.safetensors\n",
            "  4,954,672,440 100%   13.40MB/s    0:05:52 (xfr#7, to-chk=10/18)\n",
            "model-00005-of-00006.safetensors\n",
            "  4,954,672,432 100%   13.35MB/s    0:05:53 (xfr#8, to-chk=9/18)\n",
            "model-00006-of-00006.safetensors\n",
            "  4,619,116,224 100%   13.28MB/s    0:05:31 (xfr#9, to-chk=8/18)\n",
            "model.safetensors.index.json\n",
            "         29,894 100%  789.01kB/s    0:00:00 (xfr#10, to-chk=7/18)\n",
            "special_tokens_map.json\n",
            "            570 100%   15.04kB/s    0:00:00 (xfr#11, to-chk=6/18)\n",
            "tokenizer.json\n",
            "      7,153,264 100%   31.73MB/s    0:00:00 (xfr#12, to-chk=5/18)\n",
            "tokenizer_config.json\n",
            "         17,989 100%   81.71kB/s    0:00:00 (xfr#13, to-chk=4/18)\n",
            "unsloth.F16.gguf\n",
            " 29,323,406,048 100%   13.49MB/s    0:34:32 (xfr#14, to-chk=3/18)\n",
            "unsloth.Q4_K_M.gguf\n",
            "  8,890,305,248 100%   10.63MB/s    0:13:17 (xfr#15, to-chk=2/18)\n",
            "unsloth.Q6_K.gguf\n",
            " 12,030,257,888 100%   10.47MB/s    0:18:16 (xfr#16, to-chk=1/18)\n",
            "vocab.json\n",
            "      1,612,637 100%    2.60MB/s    0:00:00 (xfr#17, to-chk=0/18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Completed"
      ],
      "metadata": {
        "id": "H4xIePTwVUb5"
      },
      "id": "H4xIePTwVUb5"
    },
    {
      "cell_type": "code",
      "source": [
        "!date"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYxnGdunVWCC",
        "outputId": "2d8b4911-cc06-4936-99fb-1d0e3b7e4a41"
      },
      "id": "tYxnGdunVWCC",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May  6 12:22:18 PM UTC 2025\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "da1e0e96aa144a798541d7021de8ee2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_789a211d73294223aae6a93f0b2ad666",
              "IPY_MODEL_14a6bf0fd57c4a1dafb3ce8afa487a11",
              "IPY_MODEL_7cb1e33c186540baa76b73f0f27a1444"
            ],
            "layout": "IPY_MODEL_1b64006bfb094535a5d8f507d38e926d"
          }
        },
        "789a211d73294223aae6a93f0b2ad666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e16ebd0ceb244e2999f8b45b1d6a5d4a",
            "placeholder": "​",
            "style": "IPY_MODEL_0171dd8e02f94f3c9770159fe77c0ae1",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "14a6bf0fd57c4a1dafb3ce8afa487a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_348366bfedfd4d38b5b1e0efb4c15f99",
            "max": 160171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d35fcc00c6048c79eec9f701e827cdd",
            "value": 160171
          }
        },
        "7cb1e33c186540baa76b73f0f27a1444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea3663b893b140bebef9f215c3d7222e",
            "placeholder": "​",
            "style": "IPY_MODEL_3a7b80fc3d63473f807d72c703d8c8bc",
            "value": " 160k/160k [00:00&lt;00:00, 748kB/s]"
          }
        },
        "1b64006bfb094535a5d8f507d38e926d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e16ebd0ceb244e2999f8b45b1d6a5d4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0171dd8e02f94f3c9770159fe77c0ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "348366bfedfd4d38b5b1e0efb4c15f99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d35fcc00c6048c79eec9f701e827cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea3663b893b140bebef9f215c3d7222e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a7b80fc3d63473f807d72c703d8c8bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52d3d7c09351476bada7aa6309f9b700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c966294dcc040ffb47fff17ee1e7794",
              "IPY_MODEL_57ccf366c7e54fb89857af6c61ee062b",
              "IPY_MODEL_bedfe1b58d84435982c5ccc5e882c2ec"
            ],
            "layout": "IPY_MODEL_1c90046f66c04f548ec21e581dbb65d5"
          }
        },
        "5c966294dcc040ffb47fff17ee1e7794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3c28a57266444ea97c8307d3938e754",
            "placeholder": "​",
            "style": "IPY_MODEL_d11fd59f2de4493ba5774523b8d1f892",
            "value": "model-00001-of-00003.safetensors: 100%"
          }
        },
        "57ccf366c7e54fb89857af6c61ee062b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f8d184bfe0340f9a71c57fd24eb089a",
            "max": 4971805503,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48b13710f3bd44fbb19c776f28230d6b",
            "value": 4971805029
          }
        },
        "bedfe1b58d84435982c5ccc5e882c2ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff810debb7dd41e4bfd70c98bd6a5b6d",
            "placeholder": "​",
            "style": "IPY_MODEL_f7fcd4d09f47491bb842d953c59a8b07",
            "value": " 4.97G/4.97G [00:15&lt;00:00, 242MB/s]"
          }
        },
        "1c90046f66c04f548ec21e581dbb65d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3c28a57266444ea97c8307d3938e754": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d11fd59f2de4493ba5774523b8d1f892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f8d184bfe0340f9a71c57fd24eb089a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48b13710f3bd44fbb19c776f28230d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff810debb7dd41e4bfd70c98bd6a5b6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7fcd4d09f47491bb842d953c59a8b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bb15c3ee8bf41518c581f4aa945942c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bbb79041d24c4b00af46d290bacb64e9",
              "IPY_MODEL_cfb668fa2d324b89b20a8a0ac0c1e106",
              "IPY_MODEL_85b1535c3c5848d594351f2ebf56949c"
            ],
            "layout": "IPY_MODEL_cc5bcdb355794491b288be225e199434"
          }
        },
        "bbb79041d24c4b00af46d290bacb64e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a19a78ed043c445fa120747f3c26c0f0",
            "placeholder": "​",
            "style": "IPY_MODEL_f2f0e23380b545b799213fef18f9fd35",
            "value": "model-00002-of-00003.safetensors: 100%"
          }
        },
        "cfb668fa2d324b89b20a8a0ac0c1e106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab87765f60d74fba945c9f4ce0719065",
            "max": 4392572736,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_421bf6807b2d48169d7b79a060ab6502",
            "value": 4392572318
          }
        },
        "85b1535c3c5848d594351f2ebf56949c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4e2cd70e0b84798a6bdc93e09eb32bf",
            "placeholder": "​",
            "style": "IPY_MODEL_c8f8bc6c46f042eebb8cbcb5a361412e",
            "value": " 4.39G/4.39G [00:10&lt;00:00, 617MB/s]"
          }
        },
        "cc5bcdb355794491b288be225e199434": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a19a78ed043c445fa120747f3c26c0f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2f0e23380b545b799213fef18f9fd35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab87765f60d74fba945c9f4ce0719065": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "421bf6807b2d48169d7b79a060ab6502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4e2cd70e0b84798a6bdc93e09eb32bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8f8bc6c46f042eebb8cbcb5a361412e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d475f308822c4f3b8d2597ea60afa27f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a999356802c047e8bbb332d195e3f7c7",
              "IPY_MODEL_91cb3960cfd1498ca0e8a3e1f75e05f5",
              "IPY_MODEL_a9983e9a1423410abe45511207257f90"
            ],
            "layout": "IPY_MODEL_9cc3fda2bde4454f8388e996104b86eb"
          }
        },
        "a999356802c047e8bbb332d195e3f7c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_916bb57105a441bfbab0f97495300a7b",
            "placeholder": "​",
            "style": "IPY_MODEL_07eee58de85c48909665e2c8e68368b6",
            "value": "model-00003-of-00003.safetensors: 100%"
          }
        },
        "91cb3960cfd1498ca0e8a3e1f75e05f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_636ba33657e14b3dbcfd1b877a95faa4",
            "max": 1027604608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae82803af26f470a93443320805243a7",
            "value": 1027604510
          }
        },
        "a9983e9a1423410abe45511207257f90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dca66594c194d159859bfb256910f45",
            "placeholder": "​",
            "style": "IPY_MODEL_5a1254419652497fbef549edcc5483bf",
            "value": " 1.03G/1.03G [00:02&lt;00:00, 485MB/s]"
          }
        },
        "9cc3fda2bde4454f8388e996104b86eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "916bb57105a441bfbab0f97495300a7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07eee58de85c48909665e2c8e68368b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "636ba33657e14b3dbcfd1b877a95faa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae82803af26f470a93443320805243a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0dca66594c194d159859bfb256910f45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a1254419652497fbef549edcc5483bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9c85391c41d47b781e191f463f312ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53dbdef7d954414eaf68367d90f1ffe5",
              "IPY_MODEL_e02a6b3fb16a4a0c90df8e7d3bcaaf86",
              "IPY_MODEL_61826767fc4541b1919e762060762a31"
            ],
            "layout": "IPY_MODEL_0739a022a06341c995917b34b4de5430"
          }
        },
        "53dbdef7d954414eaf68367d90f1ffe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaa5446c1dea46edb364dd5f759c9155",
            "placeholder": "​",
            "style": "IPY_MODEL_e09bb7fecb7c491a93666c63fb16c771",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e02a6b3fb16a4a0c90df8e7d3bcaaf86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6575e35ae99423aa75fd2159e8aa259",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4b0583e06254dbe8c547ed96ed9f4d4",
            "value": 3
          }
        },
        "61826767fc4541b1919e762060762a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d9cb77857374142a14f55b7d0343a49",
            "placeholder": "​",
            "style": "IPY_MODEL_f0eec27cba9e495ea75d1359f126da07",
            "value": " 3/3 [00:03&lt;00:00,  1.02it/s]"
          }
        },
        "0739a022a06341c995917b34b4de5430": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaa5446c1dea46edb364dd5f759c9155": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e09bb7fecb7c491a93666c63fb16c771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6575e35ae99423aa75fd2159e8aa259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4b0583e06254dbe8c547ed96ed9f4d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d9cb77857374142a14f55b7d0343a49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0eec27cba9e495ea75d1359f126da07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "faaec21ce05646fa85eb95b56ecd51b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d34eee80557b4d809b5b83e80bbdf5f8",
              "IPY_MODEL_2371c31abc4841339cdebe98f05a8cc6",
              "IPY_MODEL_961fe80e396541fe968b297db1b94bac"
            ],
            "layout": "IPY_MODEL_1a9c71254e2044028f12a897d3ea560a"
          }
        },
        "d34eee80557b4d809b5b83e80bbdf5f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fc06a83fcbe49089d2190c75cdc48b1",
            "placeholder": "​",
            "style": "IPY_MODEL_c43508f87bc34ac1ad543b7f6f298dc3",
            "value": "generation_config.json: 100%"
          }
        },
        "2371c31abc4841339cdebe98f05a8cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b88f3349a3ee4d71a737794d173d1dd1",
            "max": 170,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7daa3d0f0fb042f1bab9fc749099020f",
            "value": 170
          }
        },
        "961fe80e396541fe968b297db1b94bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29387149dd6d45569308a909f31839fb",
            "placeholder": "​",
            "style": "IPY_MODEL_f990c940b1f84af78c250913e9363470",
            "value": " 170/170 [00:00&lt;00:00, 22.5kB/s]"
          }
        },
        "1a9c71254e2044028f12a897d3ea560a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fc06a83fcbe49089d2190c75cdc48b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c43508f87bc34ac1ad543b7f6f298dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b88f3349a3ee4d71a737794d173d1dd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7daa3d0f0fb042f1bab9fc749099020f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29387149dd6d45569308a909f31839fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f990c940b1f84af78c250913e9363470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0531140310c4f3db2faaf3bd4db9901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_152c245035fc4eeeab040365202fda0d",
              "IPY_MODEL_423d4c6f85dc4157a9a90fccb1fc0e50",
              "IPY_MODEL_e25baa59a3994baa81783440a6d2c415"
            ],
            "layout": "IPY_MODEL_7dead343cc6542e99286f885606b48cf"
          }
        },
        "152c245035fc4eeeab040365202fda0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ecd0a59215149d2bd75bfdb17bede1d",
            "placeholder": "​",
            "style": "IPY_MODEL_ab4fe048057c47d386d622adbd8a4847",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "423d4c6f85dc4157a9a90fccb1fc0e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d5d54e2754f4c5e822b4e50dd4b7338",
            "max": 17989,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88ebc276d3d348ea94d4af3251f08df6",
            "value": 17989
          }
        },
        "e25baa59a3994baa81783440a6d2c415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61250ee2c54b49ffbcb75cb58183184f",
            "placeholder": "​",
            "style": "IPY_MODEL_17bc05b207454d76912e263982ae08ee",
            "value": " 18.0k/18.0k [00:00&lt;00:00, 2.35MB/s]"
          }
        },
        "7dead343cc6542e99286f885606b48cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ecd0a59215149d2bd75bfdb17bede1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab4fe048057c47d386d622adbd8a4847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d5d54e2754f4c5e822b4e50dd4b7338": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88ebc276d3d348ea94d4af3251f08df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61250ee2c54b49ffbcb75cb58183184f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17bc05b207454d76912e263982ae08ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17f1e76373754a91b035afe61d03f789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7eed0475371497c8cf7ff40d9a7b69c",
              "IPY_MODEL_8dd035d740b043a581679123856f482d",
              "IPY_MODEL_06011da2d7f84281b19efe87749c2106"
            ],
            "layout": "IPY_MODEL_4a6d97fd49594eae8a61e460d3e82abf"
          }
        },
        "d7eed0475371497c8cf7ff40d9a7b69c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c038657e1c11442ca47d1a3b5ebdaf5e",
            "placeholder": "​",
            "style": "IPY_MODEL_361ce585e6ed4167b37b2e8c79f45055",
            "value": "vocab.json: 100%"
          }
        },
        "8dd035d740b043a581679123856f482d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48b282bde0814d8a8af4b72ade5597f1",
            "max": 1612637,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_327db717bdaa4c648458844c7ed7d740",
            "value": 1612637
          }
        },
        "06011da2d7f84281b19efe87749c2106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f5f741df9cc446883e8f4e83e467406",
            "placeholder": "​",
            "style": "IPY_MODEL_b8fb4d89eb354abd80268556e9625388",
            "value": " 1.61M/1.61M [00:00&lt;00:00, 6.79MB/s]"
          }
        },
        "4a6d97fd49594eae8a61e460d3e82abf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c038657e1c11442ca47d1a3b5ebdaf5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "361ce585e6ed4167b37b2e8c79f45055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48b282bde0814d8a8af4b72ade5597f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "327db717bdaa4c648458844c7ed7d740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f5f741df9cc446883e8f4e83e467406": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8fb4d89eb354abd80268556e9625388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82f7734abb8f4cc69d3bf06e6c1c543f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b95c7a029d1c4e4c90fdd26c0884d7a9",
              "IPY_MODEL_b5900a10ff574ccdb407e7d975a87081",
              "IPY_MODEL_d9b516a068384619b1c83801291d6bb1"
            ],
            "layout": "IPY_MODEL_4b7e818addb7455886809b9cffbccc57"
          }
        },
        "b95c7a029d1c4e4c90fdd26c0884d7a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58f64fda00df451e9f7ce6e2dc58b30d",
            "placeholder": "​",
            "style": "IPY_MODEL_6f2bb29a23124ad7b9061491a92074b0",
            "value": "merges.txt: 100%"
          }
        },
        "b5900a10ff574ccdb407e7d975a87081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c031a61d2f5948ed864796219c76ff3f",
            "max": 916646,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e58b3bdd86764b218ed376dc40505217",
            "value": 916646
          }
        },
        "d9b516a068384619b1c83801291d6bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89c3a3adc8794600b98811c6b2f91351",
            "placeholder": "​",
            "style": "IPY_MODEL_3f3931ef0b3d4ae7a149ecb406040fc5",
            "value": " 917k/917k [00:01&lt;00:00, 854kB/s]"
          }
        },
        "4b7e818addb7455886809b9cffbccc57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58f64fda00df451e9f7ce6e2dc58b30d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f2bb29a23124ad7b9061491a92074b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c031a61d2f5948ed864796219c76ff3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e58b3bdd86764b218ed376dc40505217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89c3a3adc8794600b98811c6b2f91351": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f3931ef0b3d4ae7a149ecb406040fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df2c1e3e6c1143a1ae63ffba330fed27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e3abfc70080433ebb87d178f8ac03e8",
              "IPY_MODEL_bf4bdb6ac0014327ab2671c59fb9f144",
              "IPY_MODEL_e8c94702f9bf4f4b8c3d7b01f1600a6c"
            ],
            "layout": "IPY_MODEL_399e2fa79cbd42fb989d50320d301792"
          }
        },
        "9e3abfc70080433ebb87d178f8ac03e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48f6cf07cadf4b86a27f4d6be9925772",
            "placeholder": "​",
            "style": "IPY_MODEL_c3e66565e11f4fde8af1a2a669941a1a",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "bf4bdb6ac0014327ab2671c59fb9f144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37da0ca70a554cf49f74c42802a362b9",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08b892f93c424477842416e3710c327b",
            "value": 570
          }
        },
        "e8c94702f9bf4f4b8c3d7b01f1600a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bb525bb27d64502b69f788b182b5156",
            "placeholder": "​",
            "style": "IPY_MODEL_2c2547ef6ed642adbb765e22f55a6305",
            "value": " 570/570 [00:00&lt;00:00, 70.5kB/s]"
          }
        },
        "399e2fa79cbd42fb989d50320d301792": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48f6cf07cadf4b86a27f4d6be9925772": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3e66565e11f4fde8af1a2a669941a1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37da0ca70a554cf49f74c42802a362b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08b892f93c424477842416e3710c327b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8bb525bb27d64502b69f788b182b5156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c2547ef6ed642adbb765e22f55a6305": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfb70ee962774999af63ef72cd71fb67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb2084ded735469da694dcc98512d46e",
              "IPY_MODEL_29b5131dbb3a4d0d9eb77ef10052160d",
              "IPY_MODEL_6e6a6c07b8964da6bc5afa2640fee35c"
            ],
            "layout": "IPY_MODEL_06e59b9399dc4aa6beefa422f2c95222"
          }
        },
        "eb2084ded735469da694dcc98512d46e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d30cfccffe774021bc00dddb200f9bf0",
            "placeholder": "​",
            "style": "IPY_MODEL_076475346ca44828805fd32b30359e65",
            "value": "tokenizer.json: 100%"
          }
        },
        "29b5131dbb3a4d0d9eb77ef10052160d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc8a0bc571ff4a8dbd2bff029f3c9c3f",
            "max": 7153264,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d6b94e831c541a48ad062fe1eaa3c3a",
            "value": 7153264
          }
        },
        "6e6a6c07b8964da6bc5afa2640fee35c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fd1ef2431dd4ec997c0b088d6eac2fa",
            "placeholder": "​",
            "style": "IPY_MODEL_dfe5b4c1914b42e8879780cd403a5bf1",
            "value": " 7.15M/7.15M [00:01&lt;00:00, 5.37MB/s]"
          }
        },
        "06e59b9399dc4aa6beefa422f2c95222": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d30cfccffe774021bc00dddb200f9bf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "076475346ca44828805fd32b30359e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc8a0bc571ff4a8dbd2bff029f3c9c3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d6b94e831c541a48ad062fe1eaa3c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1fd1ef2431dd4ec997c0b088d6eac2fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfe5b4c1914b42e8879780cd403a5bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}